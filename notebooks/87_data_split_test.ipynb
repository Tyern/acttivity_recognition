{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tran/miniconda3/envs/compgan/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchinfo import summary\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import tracemalloc \n",
    "\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "from itertools import combinations\n",
    "import gc\n",
    "import time\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../data/compgan_dataset/train/train_data0.npy', '../data/compgan_dataset/train/train_data1.npy', '../data/compgan_dataset/train/train_data10.npy', '../data/compgan_dataset/train/train_data11.npy', '../data/compgan_dataset/train/train_data12.npy', '../data/compgan_dataset/train/train_data13.npy', '../data/compgan_dataset/train/train_data14.npy', '../data/compgan_dataset/train/train_data15.npy', '../data/compgan_dataset/train/train_data2.npy', '../data/compgan_dataset/train/train_data3.npy', '../data/compgan_dataset/train/train_data4.npy', '../data/compgan_dataset/train/train_data5.npy', '../data/compgan_dataset/train/train_data6.npy', '../data/compgan_dataset/train/train_data7.npy', '../data/compgan_dataset/train/train_data8.npy', '../data/compgan_dataset/train/train_data9.npy']\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "DATA_ROOT = \"../data/compgan_dataset/\"\n",
    "\n",
    "train_data_file_name_ = \"train_data{}.npy\"\n",
    "train_label_file_name_ = \"train_label{}.npy\"\n",
    "test_data_file_name_ = \"test_data{}.npy\"\n",
    "test_label_file_name_ = \"test_label{}.npy\"\n",
    "\n",
    "TRAIN_FOLDER_PATH = os.path.join(DATA_ROOT, \"train\")\n",
    "TEST_FOLDER_PATH = os.path.join(DATA_ROOT, \"test\")\n",
    "RESULT_FOLDER_PATH = os.path.join(DATA_ROOT, \"results\")\n",
    "PREV_CHECKPOINT_FOLDER_PATH = os.path.join(DATA_ROOT, \"prev_checkpoint\")\n",
    "\n",
    "assert os.path.isdir(TRAIN_FOLDER_PATH) and os.path.isdir(TEST_FOLDER_PATH)\n",
    "os.makedirs(RESULT_FOLDER_PATH, exist_ok=True)\n",
    "\n",
    "data_files = sorted(glob.glob(os.path.join(TRAIN_FOLDER_PATH, train_data_file_name_.format(\"*\"))))\n",
    "print(data_files)\n",
    "print(len(data_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_NUM = 16\n",
    "SENSOR_NUM = 7\n",
    "EACH_SENSOR_CHANNEL = 6\n",
    "assert USER_NUM == len(data_files)\n",
    "feature_num = SENSOR_NUM * EACH_SENSOR_CHANNEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# important\n",
    "\n",
    "label_list = ['歩行(平地)',\n",
    " '歩行(階段)',\n",
    " 'ベッド上での起き上がり',\n",
    " 'ベッド椅子間の乗り移り(立つ)',\n",
    " 'ベッド椅子間の乗り移り(立たない)',\n",
    " '立ち座り',\n",
    " '座位保持・座位バランス',\n",
    " '立位保持・立位バランス',\n",
    " '関節可動域増大訓練(肩)',\n",
    " '関節可動域増大訓練(股関節)']\n",
    "\n",
    "label_dict = dict(enumerate(label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# important\n",
    "eng_label_dict = dict(zip(\n",
    "    label_list,\n",
    "    ['Walking', 'Upstair', 'Bed_Standup', 'Change_Bed', 'Change_Bed_Standup', 'Sit_Down', 'Sit', 'Stand', 'Shoulder_Exercise', 'Hip_Exercise']\n",
    "))\n",
    "\n",
    "eng_label_list = [eng_label_dict[i] for i in label_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update after 2023/11/11 houkoku\n",
    "class CustomTrainDataset(Dataset):\n",
    "    TRAIN_MODE = \"train\"\n",
    "    TEST_MODE = \"test\"\n",
    "    \n",
    "    def __init__(self, mode, feature_data, label_data, missing_sensor_numbers=0):\n",
    "        self.mode = mode\n",
    "        assert mode in [self.TRAIN_MODE, self.TEST_MODE]\n",
    "        \n",
    "        self.features = feature_data\n",
    "        self.label = label_data\n",
    "        assert len(self.features) == len(self.label), \"features len is not equal to label len\"\n",
    "        self.missing_sensor_numbers = missing_sensor_numbers\n",
    "\n",
    "        self.missing_index_list = []\n",
    "        for missing_count in range(missing_sensor_numbers + 1):\n",
    "            for missing_index in combinations(range(SENSOR_NUM), missing_count):\n",
    "                self.missing_index_list.append(missing_index)\n",
    "\n",
    "    def transform(self, one_feature, missing_sensor_id_list):\n",
    "        # Make one sensor data become 0\n",
    "        one_feature_cp = one_feature.copy()\n",
    "        \n",
    "        for missing_sensor_id in missing_sensor_id_list:\n",
    "            one_feature_cp[:, missing_sensor_id*6:(missing_sensor_id+1)*6] = 0\n",
    "        return one_feature_cp\n",
    "        \n",
    "    def __len__(self):\n",
    "\n",
    "        # take all available missing pattern * data number\n",
    "        return len(self.features) * len(self.missing_index_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # take all available missing pattern\n",
    "        missing_sensor_id_list = self.missing_index_list[ idx // len(self.features) ]\n",
    "        x = self.transform(self.features[ idx % len(self.features) ], missing_sensor_id_list)\n",
    "        label = self.label[idx % len(self.features)]\n",
    "        return x, int(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule(pl.LightningDataModule):\n",
    "    STANDARDIZE = False\n",
    "    \n",
    "    def __init__(self, test_user, missing_sensor_numbers, batch_size=2048, is_convlstm=False):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        self.test_user = test_user\n",
    "        self.missing_sensor_numbers = missing_sensor_numbers\n",
    "        self.batch_size = batch_size\n",
    "        self.is_convlstm = is_convlstm\n",
    "        self.scaler = None\n",
    "\n",
    "    def load_data(self, mode):\n",
    "        if mode == \"train\":\n",
    "            folder_path = TRAIN_FOLDER_PATH\n",
    "            data_file_name = train_data_file_name_\n",
    "            label_file_name = train_label_file_name_\n",
    "\n",
    "            train_data_file_name = data_file_name.format(self.test_user)\n",
    "            train_label_file_name = label_file_name.format(self.test_user)\n",
    "    \n",
    "            train_data_file_path = os.path.join(folder_path, train_data_file_name)\n",
    "            train_label_file_path = os.path.join(folder_path, train_label_file_name)\n",
    "            train_val_data, train_val_label = np.load(train_data_file_path), np.load(train_label_file_path)\n",
    "            l, s, d, w = train_val_data.shape\n",
    "            # self.scaler = StandardScaler()\n",
    "            # train_val_data = self.scaler.fit_transform(train_val_data.reshape(l, -1)).reshape(l, s, d, w)\n",
    "            \n",
    "        elif mode == \"test\":\n",
    "            folder_path = TEST_FOLDER_PATH\n",
    "            data_file_name = test_data_file_name_\n",
    "            label_file_name = test_label_file_name_\n",
    "    \n",
    "            train_data_file_name = data_file_name.format(self.test_user)\n",
    "            train_label_file_name = label_file_name.format(self.test_user)\n",
    "    \n",
    "            train_data_file_path = os.path.join(folder_path, train_data_file_name)\n",
    "            train_label_file_path = os.path.join(folder_path, train_label_file_name)\n",
    "            train_val_data, train_val_label = np.load(train_data_file_path), np.load(train_label_file_path)\n",
    "            l, s, d, w = train_val_data.shape\n",
    "            # train_val_data = self.scaler.transform(train_val_data.reshape(l, -1)).reshape(l, s, d, w)\n",
    "        \n",
    "        if self.is_convlstm:\n",
    "            train_val_data = train_val_data.reshape(l, s ,d, w).transpose(0, 3, 2, 1)\n",
    "        else:\n",
    "            train_val_data = train_val_data.reshape(l, s * d, w).transpose(0,2,1)\n",
    "    \n",
    "        return train_val_data, train_val_label\n",
    "\n",
    "    def setup(self, stage: str):\n",
    "        # Assign Train/val split(s) for use in Dataloaders\n",
    "        \n",
    "        if stage == \"validate\" or stage == \"fit\":\n",
    "            train_val_data, train_val_label = self.load_data(\"train\")\n",
    "            self.train_data, self.val_data, self.train_label, self.val_label = train_test_split(\n",
    "                train_val_data, train_val_label, test_size=0.05, train_size=0.95, random_state=42, shuffle=True, stratify=train_val_label)\n",
    "\n",
    "            self.train_dataset = CustomTrainDataset(\n",
    "                CustomTrainDataset.TRAIN_MODE, self.train_data, self.train_label, missing_sensor_numbers=self.missing_sensor_numbers)\n",
    "            self.val_dataset = CustomTrainDataset(\n",
    "                CustomTrainDataset.TEST_MODE, self.val_data, self.val_label, missing_sensor_numbers=self.missing_sensor_numbers)\n",
    "\n",
    "        elif stage == \"test\" or stage == \"predict\":\n",
    "            train_val_data, train_val_label = self.load_data(\"test\")\n",
    "            self.test_data = train_val_data\n",
    "            self.test_label = train_val_label\n",
    "\n",
    "            self.test_dataset = CustomTrainDataset(\n",
    "                CustomTrainDataset.TEST_MODE, self.test_data, self.test_label, missing_sensor_numbers=self.missing_sensor_numbers)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, num_workers=4, shuffle=True, pin_memory=True)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size,  num_workers=4, shuffle=False, pin_memory=True)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size,  num_workers=4, shuffle=False, pin_memory=True)\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size,  num_workers=4, shuffle=False, pin_memory=True)\n",
    "\n",
    "    def teardown(self, stage):\n",
    "        print(\"teardown\")\n",
    "        if stage == \"validate\" or stage == \"fit\":\n",
    "            del self.train_data, self.train_label\n",
    "            del self.val_data, self.val_label\n",
    "            del self.train_dataset\n",
    "            del self.val_dataset\n",
    "            \n",
    "        elif stage == \"test\" or stage == \"predict\":\n",
    "            del self.test_data, self.test_label\n",
    "            del self.test_dataset\n",
    "        gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6042, 256, 42)\n",
      "(319, 256, 42)\n",
      "(6042,)\n",
      "(319,)\n"
     ]
    }
   ],
   "source": [
    "if TEST:\n",
    "    data_module = DataModule(test_user=0, missing_sensor_numbers=0)\n",
    "    data_module.setup(\"fit\")\n",
    "\n",
    "    print(data_module.train_data.shape)\n",
    "    print(data_module.val_data.shape)\n",
    "    print(data_module.train_label.shape)\n",
    "    print(data_module.val_label.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_label_freq [400 315 359 622 624 414 843 824 808 833]\n",
      "val_label_freq [21 17 19 33 33 22 44 43 43 44]\n",
      "[19.04761905 18.52941176 18.89473684 18.84848485 18.90909091 18.81818182\n",
      " 19.15909091 19.1627907  18.79069767 18.93181818]\n"
     ]
    }
   ],
   "source": [
    "if TEST:\n",
    "    train_label_freq = np.unique(data_module.train_label, return_counts=True)[1]\n",
    "    val_label_freq = np.unique(data_module.val_label, return_counts=True)[1]\n",
    "    print(\"train_label_freq\", train_label_freq)\n",
    "    print(\"val_label_freq\", val_label_freq)\n",
    "    print(train_label_freq/val_label_freq)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL DEFINITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LSTMModel(pl.LightningModule):\n",
    "    def __init__(self, hidden_size=128, input_size=42, output_size=10, **kwargs):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.example_input_array = torch.Tensor(1024, 256, input_size)\n",
    "        \n",
    "        self.rnn = nn.LSTM(input_size=input_size, \n",
    "                          hidden_size=hidden_size,\n",
    "                          num_layers=3,\n",
    "                          batch_first=True)\n",
    "        \n",
    "        self.seq_1 = nn.Sequential(\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.seq_2 = nn.Sequential(\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Linear(in_features=3 * hidden_size, out_features=output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        activation, _ = self.rnn(x)\n",
    "        \n",
    "        b, _, _ = activation.size()\n",
    "        lstm_output = activation[:,-1,:].view(b,-1)\n",
    "        seq_1_output = self.seq_1(lstm_output)\n",
    "        seq_2_output = self.seq_2(lstm_output)\n",
    "        \n",
    "        output = torch.concat([lstm_output, seq_1_output, seq_2_output], dim=1)\n",
    "        output = self.classifier(output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(params=self.parameters(), lr=0.0005)\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        # 1. Forward pass\n",
    "        y_pred = self.forward(X)\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        \n",
    "        self.log(\"train_loss\", loss)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the test loop\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "    \n",
    "        # 1. Forward pass\n",
    "        test_pred_logits = self.forward(X)\n",
    "\n",
    "        # Calculate and accumulate accuracy\n",
    "        test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "        test_acc = ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "        self.log(\"test_acc\", test_acc)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # this is the validation loop\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        \n",
    "        y_pred = self.forward(X)\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        \n",
    "        test_pred_labels = y_pred.argmax(dim=1)\n",
    "        test_acc = ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "        self.log(\"val_acc\", test_acc)\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        \n",
    "        test_pred_logits = self.forward(X)\n",
    "        test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "        \n",
    "        return test_pred_labels\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMAttentionModel(pl.LightningModule):\n",
    "    def __init__(self, hidden_size=128, input_size=42, output_size=10, **kwargs):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.example_input_array = torch.Tensor(1024, 256, input_size)\n",
    "        \n",
    "        self.rnn1 = nn.LSTM(input_size=input_size, \n",
    "                          hidden_size=hidden_size,\n",
    "                          num_layers=1,\n",
    "                          batch_first=True)\n",
    "        \n",
    "        self.attention1 = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_size,\n",
    "            num_heads=8,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.rnn2 = nn.LSTM(input_size=hidden_size, \n",
    "                          hidden_size=hidden_size,\n",
    "                          num_layers=1,\n",
    "                          batch_first=True)\n",
    "        \n",
    "        self.attention2 = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_size,\n",
    "            num_heads=8,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.rnn3 = nn.LSTM(input_size=hidden_size, \n",
    "                  hidden_size=hidden_size,\n",
    "                  num_layers=1,\n",
    "                  batch_first=True)\n",
    "        \n",
    "        self.seq_1 = nn.Sequential(\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.seq_2 = nn.Sequential(\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Linear(in_features=3 * hidden_size, out_features=output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        activation, _ = self.rnn1(x)\n",
    "        activation, _ = self.attention1(activation, activation, activation)\n",
    "        activation, _ = self.rnn2(activation)\n",
    "        activation, _ = self.attention2(activation, activation, activation)\n",
    "        activation, (h, _) = self.rnn3(activation)\n",
    "\n",
    "        b, _, _ = activation.size()\n",
    "        \n",
    "        lstm_output = activation[:,-1,:].view(b,-1)\n",
    "        \n",
    "        seq_1_output = self.seq_1(lstm_output)\n",
    "        seq_2_output = self.seq_2(lstm_output)\n",
    "        \n",
    "        output = torch.concat([lstm_output, seq_1_output, seq_2_output], dim=1)\n",
    "        output = self.classifier(output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(params=self.parameters(), lr=0.0005)\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        # 1. Forward pass\n",
    "        y_pred = self.forward(X)\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        \n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the test loop\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        y = y\n",
    "    \n",
    "        # 1. Forward pass\n",
    "        test_pred_logits = self.forward(X)\n",
    "\n",
    "        # Calculate and accumulate accuracy\n",
    "        test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "        test_acc = ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "        self.log(\"test_acc\", test_acc)\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # this is the validation loop\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        y = y\n",
    "        \n",
    "        y_pred = self.forward(X)\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        \n",
    "        test_pred_labels = y_pred.argmax(dim=1)\n",
    "        test_acc = ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "        self.log(\"val_acc\", test_acc)\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        \n",
    "        test_pred_logits = self.forward(X)\n",
    "        test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "        \n",
    "        return test_pred_labels\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ConvLSTMCell(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size, bias):\n",
    "        \"\"\"\n",
    "        Initialize ConvLSTM cell.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_dim: int\n",
    "            Number of channels of input tensor.\n",
    "        hidden_dim: int\n",
    "            Number of channels of hidden state.\n",
    "        kernel_size: (int, int)\n",
    "            Size of the convolutional kernel.\n",
    "        bias: bool\n",
    "            Whether or not to add the bias.\n",
    "            \n",
    "        Input: ()\n",
    "        \"\"\"\n",
    "\n",
    "        super(ConvLSTMCell, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = kernel_size[0] // 2, kernel_size[1] // 2\n",
    "        self.bias = bias\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels=self.input_dim + self.hidden_dim,\n",
    "                              out_channels=4 * self.hidden_dim,\n",
    "                              kernel_size=self.kernel_size,\n",
    "                              padding=self.padding,\n",
    "                              bias=self.bias)\n",
    "\n",
    "    def forward(self, input_tensor, cur_state):\n",
    "        h_cur, c_cur = cur_state\n",
    "\n",
    "        combined = torch.cat([input_tensor, h_cur], dim=1)  # concatenate along channel axis\n",
    "\n",
    "        combined_conv = self.conv(combined)\n",
    "        cc_i, cc_f, cc_o, cc_g = torch.split(combined_conv, self.hidden_dim, dim=1)\n",
    "        i = torch.sigmoid(cc_i)\n",
    "        f = torch.sigmoid(cc_f)\n",
    "        o = torch.sigmoid(cc_o)\n",
    "        g = torch.tanh(cc_g)\n",
    "\n",
    "        c_next = f * c_cur + i * g\n",
    "        h_next = o * torch.tanh(c_next)\n",
    "\n",
    "        return h_next, c_next\n",
    "\n",
    "    def init_hidden(self, batch_size, image_size):\n",
    "        height, width = image_size\n",
    "        return (torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device),\n",
    "                torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ConvLSTM(nn.Module):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters:\n",
    "        input_dim: Number of channels in input\n",
    "        hidden_dim: Number of hidden channels\n",
    "        kernel_size: Size of kernel in convolutions\n",
    "        num_layers: Number of LSTM layers stacked on each other\n",
    "        batch_first: Whether or not dimension 0 is the batch or not\n",
    "        bias: Bias or no bias in Convolution\n",
    "        return_all_layers: Return the list of computations for all layers\n",
    "        Note: Will do same padding.\n",
    "\n",
    "    Input:\n",
    "        A tensor of size B, T, C, H, W or T, B, C, H, W\n",
    "    Output:\n",
    "        A tuple of two lists of length num_layers (or length 1 if return_all_layers is False).\n",
    "            0 - layer_output_list is the list of lists of length T of each output\n",
    "            1 - last_state_list is the list of last states\n",
    "                    each element of the list is a tuple (h, c) for hidden state and memory\n",
    "    Example:\n",
    "        >> x = torch.rand((32, 10, 64, 128, 128))\n",
    "        >> convlstm = ConvLSTM(64, 16, 3, 1, True, True, False)\n",
    "        >> _, last_states = convlstm(x)\n",
    "        >> h = last_states[0][0]  # 0 for layer index, 0 for h index\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size, num_layers,\n",
    "                 batch_first=False, bias=True, return_all_layers=False):\n",
    "        super(ConvLSTM, self).__init__()\n",
    "\n",
    "        self._check_kernel_size_consistency(kernel_size)\n",
    "\n",
    "        # Make sure that both `kernel_size` and `hidden_dim` are lists having len == num_layers\n",
    "        kernel_size = self._extend_for_multilayer(kernel_size, num_layers)\n",
    "        hidden_dim = self._extend_for_multilayer(hidden_dim, num_layers)\n",
    "        \n",
    "        if not len(kernel_size) == len(hidden_dim) == num_layers:\n",
    "            raise ValueError('Inconsistent list length.')\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_first = batch_first\n",
    "        self.bias = bias\n",
    "        self.return_all_layers = return_all_layers\n",
    "\n",
    "        cell_list = []\n",
    "        for i in range(0, self.num_layers):\n",
    "            cur_input_dim = self.input_dim if i == 0 else self.hidden_dim[i - 1]\n",
    "\n",
    "            cell_list.append(ConvLSTMCell(input_dim=cur_input_dim,\n",
    "                                          hidden_dim=self.hidden_dim[i],\n",
    "                                          kernel_size=self.kernel_size[i],\n",
    "                                          bias=self.bias))\n",
    "\n",
    "        self.cell_list = nn.ModuleList(cell_list)\n",
    "\n",
    "    def forward(self, input_tensor, hidden_state=None):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_tensor: todo\n",
    "            5-D Tensor either of shape (t, b, c, h, w) or (b, t, c, h, w)\n",
    "        hidden_state: todo\n",
    "            None. todo implement stateful\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        last_state_list, layer_output\n",
    "        \"\"\"\n",
    "        if not self.batch_first:\n",
    "            # (t, b, c, h, w) -> (b, t, c, h, w)\n",
    "            input_tensor = input_tensor.permute(1, 0, 2, 3, 4)\n",
    "\n",
    "        b, _, _, h, w = input_tensor.size()\n",
    "\n",
    "        # Implement stateful ConvLSTM\n",
    "        if hidden_state is not None:\n",
    "            raise NotImplementedError()\n",
    "        else:\n",
    "            # Since the init is done in forward. Can send image size here\n",
    "            hidden_state = self._init_hidden(batch_size=b,\n",
    "                                             image_size=(h, w))\n",
    "\n",
    "        layer_output_list = []\n",
    "        last_state_list = []\n",
    "\n",
    "        seq_len = input_tensor.size(1)\n",
    "        cur_layer_input = input_tensor\n",
    "\n",
    "        for layer_idx in range(self.num_layers):\n",
    "\n",
    "            h, c = hidden_state[layer_idx]\n",
    "            output_inner = []\n",
    "            for t in range(seq_len):\n",
    "                h, c = self.cell_list[layer_idx](input_tensor=cur_layer_input[:, t, :, :, :],\n",
    "                                                 cur_state=[h, c])\n",
    "                output_inner.append(h)\n",
    "\n",
    "            layer_output = torch.stack(output_inner, dim=1)\n",
    "            cur_layer_input = layer_output\n",
    "\n",
    "            layer_output_list.append(layer_output)\n",
    "            last_state_list.append([h, c])\n",
    "\n",
    "        if not self.return_all_layers:\n",
    "            layer_output_list = layer_output_list[-1:]\n",
    "            last_state_list = last_state_list[-1:]\n",
    "\n",
    "        return layer_output_list, last_state_list\n",
    "\n",
    "    def _init_hidden(self, batch_size, image_size):\n",
    "        init_states = []\n",
    "        for i in range(self.num_layers):\n",
    "            init_states.append(self.cell_list[i].init_hidden(batch_size, image_size))\n",
    "        return init_states\n",
    "\n",
    "    @staticmethod\n",
    "    def _check_kernel_size_consistency(kernel_size):\n",
    "        if not (isinstance(kernel_size, tuple) or\n",
    "                (isinstance(kernel_size, list) and all([isinstance(elem, tuple) for elem in kernel_size]))):\n",
    "            raise ValueError('`kernel_size` must be tuple or list of tuples')\n",
    "\n",
    "    @staticmethod\n",
    "    def _extend_for_multilayer(param, num_layers):\n",
    "        if not isinstance(param, list):\n",
    "            param = [param] * num_layers\n",
    "        return param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLSTMModel(pl.LightningModule):\n",
    "    def __init__(self, hidden_size=64, sequence_length=256, cnn_filter_size=64, output_size=10, **kwargs):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.example_input_array = torch.Tensor(10, sequence_length, EACH_SENSOR_CHANNEL, SENSOR_NUM)\n",
    "        \n",
    "        self.conv_lstm = ConvLSTM(input_dim=1, hidden_dim=[cnn_filter_size], kernel_size=(1,3), num_layers=1, batch_first=True,)\n",
    "        self.dropout = nn.Dropout2d(p=0.5)\n",
    "        self.linear1 = nn.Linear(in_features=sequence_length * cnn_filter_size * SENSOR_NUM* EACH_SENSOR_CHANNEL, out_features=hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(in_features=hidden_size, out_features=output_size)\n",
    "        self.softmax = nn.Softmax()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = torch.unsqueeze(x, dim=2)\n",
    "        h, _ = self.conv_lstm(out)\n",
    "        out = self.dropout(h[0])\n",
    "        out = out.view(out.shape[0], self.hparams.sequence_length * self.hparams.cnn_filter_size * SENSOR_NUM * EACH_SENSOR_CHANNEL)\n",
    "        out = self.linear1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.softmax(out)\n",
    "        return out        \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(params=self.parameters(), lr=0.001)\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        # 1. Forward pass\n",
    "        y_pred = self.forward(X)\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        \n",
    "        self.log(\"train_loss\", loss)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the test loop\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "    \n",
    "        # 1. Forward pass\n",
    "        test_pred_logits = self.forward(X)\n",
    "\n",
    "        # Calculate and accumulate accuracy\n",
    "        test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "        test_acc = ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "        self.log(\"test_acc\", test_acc)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # this is the validation loop\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        \n",
    "        y_pred = self.forward(X)\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        \n",
    "        test_pred_labels = y_pred.argmax(dim=1)\n",
    "        test_acc = ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "        self.log(\"val_acc\", test_acc)\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        \n",
    "        test_pred_logits = self.forward(X)\n",
    "        test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "        \n",
    "        return test_pred_labels\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  | Name                | Type       | Params | In sizes            | Out sizes                                                  \n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "0 | conv_lstm           | ConvLSTM   | 50.2 K | [10, 256, 1, 6, 7]  | [[[10, 256, 64, 6, 7]], [[[10, 64, 6, 7], [10, 64, 6, 7]]]]\n",
      "1 | conv_lstm.cell_list | ModuleList | 50.2 K | ?                   | ?                                                          \n",
      "2 | dropout             | Dropout2d  | 0      | [10, 256, 64, 6, 7] | [10, 256, 64, 6, 7]                                        \n",
      "3 | linear1             | Linear     | 44.0 M | [10, 688128]        | [10, 64]                                                   \n",
      "4 | relu                | ReLU       | 0      | [10, 64]            | [10, 64]                                                   \n",
      "5 | linear2             | Linear     | 650    | [10, 64]            | [10, 10]                                                   \n",
      "6 | softmax             | Softmax    | 0      | [10, 10]            | [10, 10]                                                   \n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "44.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "44.1 M    Total params\n",
      "176.364   Total estimated model params size (MB)\n"
     ]
    }
   ],
   "source": [
    "if TEST:\n",
    "    from pytorch_lightning.utilities.model_summary import ModelSummary\n",
    "    model = ConvLSTMModel()\n",
    "    model_summary = ModelSummary(model, max_depth=2)\n",
    "    print(model_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model_class = [LSTMModel, LSTMAttentionModel, ConvLSTMModel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type       | Params | In sizes        | Out sizes                                           \n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "0 | rnn        | LSTM       | 352 K  | [1024, 256, 42] | [[1024, 256, 128], [[3, 1024, 128], [3, 1024, 128]]]\n",
      "1 | seq_1      | Sequential | 33.5 K | [1024, 128]     | [1024, 128]                                         \n",
      "2 | seq_2      | Sequential | 33.5 K | [1024, 128]     | [1024, 128]                                         \n",
      "3 | classifier | Linear     | 3.9 K  | [1024, 384]     | [1024, 10]                                          \n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "423 K     Trainable params\n",
      "0         Non-trainable params\n",
      "423 K     Total params\n",
      "1.693     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for model LSTMModel\n",
      "summary(model) =================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "LSTMModel                                --\n",
      "├─LSTM: 1-1                              352,256\n",
      "├─Sequential: 1-2                        --\n",
      "│    └─Linear: 2-1                       16,512\n",
      "│    └─BatchNorm1d: 2-2                  256\n",
      "│    └─Dropout1d: 2-3                    --\n",
      "│    └─ReLU: 2-4                         --\n",
      "│    └─Linear: 2-5                       16,512\n",
      "│    └─BatchNorm1d: 2-6                  256\n",
      "│    └─Dropout1d: 2-7                    --\n",
      "│    └─ReLU: 2-8                         --\n",
      "├─Sequential: 1-3                        --\n",
      "│    └─Linear: 2-9                       16,512\n",
      "│    └─BatchNorm1d: 2-10                 256\n",
      "│    └─Dropout1d: 2-11                   --\n",
      "│    └─ReLU: 2-12                        --\n",
      "│    └─Linear: 2-13                      16,512\n",
      "│    └─BatchNorm1d: 2-14                 256\n",
      "│    └─Dropout1d: 2-15                   --\n",
      "│    └─ReLU: 2-16                        --\n",
      "├─Linear: 1-4                            3,850\n",
      "=================================================================\n",
      "Total params: 423,178\n",
      "Trainable params: 423,178\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00,  2.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00,  2.22it/s]\n",
      "teardown\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 15.55it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc                0.08203125\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "teardown\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for model LSTMAttentionModel\n",
      "summary(model) ===========================================================================\n",
      "Layer (type:depth-idx)                             Param #\n",
      "===========================================================================\n",
      "LSTMAttentionModel                                 --\n",
      "├─LSTM: 1-1                                        88,064\n",
      "├─MultiheadAttention: 1-2                          49,536\n",
      "│    └─NonDynamicallyQuantizableLinear: 2-1        16,512\n",
      "├─LSTM: 1-3                                        132,096\n",
      "├─MultiheadAttention: 1-4                          49,536\n",
      "│    └─NonDynamicallyQuantizableLinear: 2-2        16,512\n",
      "├─LSTM: 1-5                                        132,096\n",
      "├─Sequential: 1-6                                  --\n",
      "│    └─Linear: 2-3                                 16,512\n",
      "│    └─BatchNorm1d: 2-4                            256\n",
      "│    └─Dropout1d: 2-5                              --\n",
      "│    └─ReLU: 2-6                                   --\n",
      "│    └─Linear: 2-7                                 16,512\n",
      "│    └─BatchNorm1d: 2-8                            256\n",
      "│    └─Dropout1d: 2-9                              --\n",
      "│    └─ReLU: 2-10                                  --\n",
      "├─Sequential: 1-7                                  --\n",
      "│    └─Linear: 2-11                                16,512\n",
      "│    └─BatchNorm1d: 2-12                           256\n",
      "│    └─Dropout1d: 2-13                             --\n",
      "│    └─ReLU: 2-14                                  --\n",
      "│    └─Linear: 2-15                                16,512\n",
      "│    └─BatchNorm1d: 2-16                           256\n",
      "│    └─Dropout1d: 2-17                             --\n",
      "│    └─ReLU: 2-18                                  --\n",
      "├─Linear: 1-8                                      3,850\n",
      "===========================================================================\n",
      "Total params: 555,274\n",
      "Trainable params: 555,274\n",
      "Non-trainable params: 0\n",
      "===========================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type               | Params | In sizes                                               | Out sizes                                           \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0 | rnn1       | LSTM               | 88.1 K | [1024, 256, 42]                                        | [[1024, 256, 128], [[1, 1024, 128], [1, 1024, 128]]]\n",
      "1 | attention1 | MultiheadAttention | 66.0 K | [[1024, 256, 128], [1024, 256, 128], [1024, 256, 128]] | [[1024, 256, 128], [1024, 256, 256]]                \n",
      "2 | rnn2       | LSTM               | 132 K  | [1024, 256, 128]                                       | [[1024, 256, 128], [[1, 1024, 128], [1, 1024, 128]]]\n",
      "3 | attention2 | MultiheadAttention | 66.0 K | [[1024, 256, 128], [1024, 256, 128], [1024, 256, 128]] | [[1024, 256, 128], [1024, 256, 256]]                \n",
      "4 | rnn3       | LSTM               | 132 K  | [1024, 256, 128]                                       | [[1024, 256, 128], [[1, 1024, 128], [1, 1024, 128]]]\n",
      "5 | seq_1      | Sequential         | 33.5 K | [1024, 128]                                            | [1024, 128]                                         \n",
      "6 | seq_2      | Sequential         | 33.5 K | [1024, 128]                                            | [1024, 128]                                         \n",
      "7 | classifier | Linear             | 3.9 K  | [1024, 384]                                            | [1024, 10]                                          \n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "555 K     Trainable params\n",
      "0         Non-trainable params\n",
      "555 K     Total params\n",
      "2.221     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00,  1.88it/s, train_loss=2.300, val_loss=2.300]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00,  1.87it/s, train_loss=2.300, val_loss=2.300]\n",
      "teardown\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 10.25it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc                0.08203125\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "teardown\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for model ConvLSTMModel\n",
      "summary(model) =================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "ConvLSTMModel                            --\n",
      "├─ConvLSTM: 1-1                          --\n",
      "│    └─ModuleList: 2-1                   --\n",
      "│    │    └─ConvLSTMCell: 3-1            50,176\n",
      "├─Dropout2d: 1-2                         --\n",
      "├─Linear: 1-3                            44,040,256\n",
      "├─ReLU: 1-4                              --\n",
      "├─Linear: 1-5                            650\n",
      "├─Softmax: 1-6                           --\n",
      "=================================================================\n",
      "Total params: 44,091,082\n",
      "Trainable params: 44,091,082\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type      | Params | In sizes            | Out sizes                                                  \n",
      "----------------------------------------------------------------------------------------------------------------------------\n",
      "0 | conv_lstm | ConvLSTM  | 50.2 K | [10, 256, 1, 6, 7]  | [[[10, 256, 64, 6, 7]], [[[10, 64, 6, 7], [10, 64, 6, 7]]]]\n",
      "1 | dropout   | Dropout2d | 0      | [10, 256, 64, 6, 7] | [10, 256, 64, 6, 7]                                        \n",
      "2 | linear1   | Linear    | 44.0 M | [10, 688128]        | [10, 64]                                                   \n",
      "3 | relu      | ReLU      | 0      | [10, 64]            | [10, 64]                                                   \n",
      "4 | linear2   | Linear    | 650    | [10, 64]            | [10, 10]                                                   \n",
      "5 | softmax   | Softmax   | 0      | [10, 10]            | [10, 10]                                                   \n",
      "----------------------------------------------------------------------------------------------------------------------------\n",
      "44.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "44.1 M    Total params\n",
      "176.364   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00,  1.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teardown\n",
      "Testing DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 10.02it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc                 0.1640625\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "teardown\n"
     ]
    }
   ],
   "source": [
    "# only for test\n",
    "\n",
    "def test():\n",
    "    patience = 20\n",
    "    missing_sensor_numbers = 4 # no missing sensor\n",
    "    user = 0 # use user2 to test\n",
    "    batch_size_dict = {\"ConvLSTMAttentionModel\":128, \"ConvLSTMModel\":128}\n",
    "    for model_class in train_model_class:\n",
    "        data_module = DataModule(\n",
    "            test_user=user, \n",
    "            missing_sensor_numbers=missing_sensor_numbers, \n",
    "            batch_size=batch_size_dict.get(model_class.__name__, 512),\n",
    "            is_convlstm=model_class.__name__ in [\"ConvLSTMModel\", \"ConvLSTMAttentionModel\"]\n",
    "        )\n",
    "        \n",
    "        model = model_class(input_size=42, output_size=10)\n",
    "        \n",
    "        model_name = model.__class__.__name__\n",
    "        print(\"Running for model\", model_name)\n",
    "        print(\"summary(model)\", summary(model))\n",
    "\n",
    "        tb_logger = TensorBoardLogger(f\"./loggers/{model_name}\")\n",
    "        \n",
    "        trainer = pl.Trainer(\n",
    "            logger=tb_logger,\n",
    "            callbacks=[EarlyStopping(monitor=\"val_loss\", patience=patience, mode=\"min\")],\n",
    "            fast_dev_run = True,\n",
    "            precision=\"16-mixed\"\n",
    "        )\n",
    "        trainer.fit(model, data_module)\n",
    "        trainer.test(model, data_module)\n",
    "if TEST:\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patience = 100\n",
    "# missing_sensor_numbers = 0\n",
    "# all_test_pred = {}\n",
    "batch_size_dict = {\"ConvLSTMAttentionModel\":128, \"ConvLSTMModel\":128}\n",
    "for model_class in train_model_class: \n",
    "    \n",
    "    model = model_class(output_size=10)\n",
    "    model_name = model.__class__.__name__\n",
    "    print(\"Running for model\", model_name)\n",
    "    \n",
    "    for missing_sensor_numbers in [6]: ## Changed for 1 missing sensor\n",
    "        for user in [0, 1, 2]: ## Changed for user 2 only\n",
    "\n",
    "            # Load from exist previous training cpkt for continuous learning & testing\n",
    "            # previous_checkpoint_file = os.path.join(PREV_CHECKPOINT_FOLDER_PATH, f\"{model_name}_{missing_sensor_numbers}missing_user{user}.ckpt\")\n",
    "            \n",
    "            r_path = \"/home/tran/acttivity_recognition/data/compgan_dataset/results/logger87_0missing\"\n",
    "            previous_checkpoint_file_glob = glob.glob(\n",
    "                os.path.join(r_path, model_class.__name__, \"user0\", \"version_0\", \"checkpoints\", \"last-epoch*.ckpt\")\n",
    "            )\n",
    "            previous_checkpoint_file = previous_checkpoint_file_glob[0]\n",
    "            \n",
    "            if os.path.isfile(previous_checkpoint_file):\n",
    "                model = model_class.load_from_checkpoint(previous_checkpoint_file)\n",
    "                print(\"loaded\", model_name, missing_sensor_numbers, user)\n",
    "                \n",
    "            start_timer = time.perf_counter()\n",
    "            print(f\"\\n*************training on User{user}*************\")\n",
    "            \n",
    "            data_module = DataModule(\n",
    "                test_user=user, \n",
    "                missing_sensor_numbers=missing_sensor_numbers, \n",
    "                batch_size=batch_size_dict.get(model_class.__name__, 512),\n",
    "                is_convlstm=model_class.__name__ in [\"ConvLSTMModel\", \"ConvLSTMAttentionModel\"]\n",
    "            )\n",
    "            \n",
    "            save_dir = os.path.join(RESULT_FOLDER_PATH, f\"./logger87_{missing_sensor_numbers}missing/{model_name}\")\n",
    "            save_dir_name = f\"user{user}\"\n",
    "            \n",
    "            tb_logger = TensorBoardLogger(save_dir=save_dir, name=save_dir_name)\n",
    "           \n",
    "            model_checkpoint = ModelCheckpoint(\n",
    "                save_top_k=1,  # get the 1 minimum val loss checkpoint\n",
    "                monitor=\"val_loss\",\n",
    "                mode=\"min\",\n",
    "                filename=\"val_loss_min-{epoch:02d}-{val_loss:.2f}-{val_acc:.2f}\"\n",
    "            )\n",
    "            \n",
    "            model_checkpoint_save_last = ModelCheckpoint(\n",
    "                save_top_k=1,  # get the 1 minimum val loss checkpoint\n",
    "                filename=\"last-{epoch:02d}-{val_loss:.2f}-{val_acc:.2f}\"\n",
    "            )\n",
    "            \n",
    "            trainer = pl.Trainer(\n",
    "                logger=tb_logger,\n",
    "                callbacks=[\n",
    "                    # EarlyStopping(monitor=\"val_loss\", patience=patience, mode=\"min\"),\n",
    "                    LearningRateMonitor(\"epoch\"),\n",
    "                    model_checkpoint,\n",
    "                    model_checkpoint_save_last\n",
    "                ],\n",
    "                precision=\"16-mixed\",\n",
    "                accumulate_grad_batches=5,\n",
    "                log_every_n_steps=10,\n",
    "                check_val_every_n_epoch=5,\n",
    "                max_epochs=300,\n",
    "            )\n",
    "        \n",
    "            trainer.fit(model, data_module)\n",
    "            trainer.test(model, data_module)\n",
    "    \n",
    "            end_timer = time.perf_counter()\n",
    "            exec_time = end_timer - start_timer\n",
    "\n",
    "            trainer_test_dict = trainer.logged_metrics\n",
    "            for key in trainer_test_dict.keys():\n",
    "                trainer_test_dict[key] = trainer_test_dict[key].item()\n",
    "            trainer_test_dict[\"exec_time\"] = int(exec_time)\n",
    "            \n",
    "            with open(os.path.join(trainer.log_dir, f\"result.json\"), \"w\") as f:\n",
    "                json.dump(trainer_test_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f3f15c77c882d8433ef1043b53db379ca3772938d44c39305f8b807ce25a312a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.17 ('compgan': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tran/miniconda3/envs/compgan/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchinfo import summary\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "import lightning as L\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import tracemalloc \n",
    "\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "from itertools import combinations\n",
    "import gc\n",
    "import time\n",
    "import random\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, os.path.join(os.path.abspath(''), \"..\"))\n",
    "from model.builder import Classifier1DMaxPoolBNModel\n",
    "from datamodule.datamodule import DataModule, FFTDataModule_1_sensor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20000000\n",
    "patience = n_epochs//10000\n",
    "missing = 6\n",
    "user = 0\n",
    "\n",
    "batch_size = 512\n",
    "log_save_dir = os.path.join(\"../data/compgan_dataset/\", \"results\", \"84_classify_1_sensor\")\n",
    "log_save_name = f\"{missing}_missing/user{user}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = FFTDataModule_1_sensor(\n",
    "    test_user=user, \n",
    "    missing_sensor_numbers=missing,\n",
    "    batch_size=512,\n",
    "    test_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   | Name      | Type        | Params | In sizes      | Out sizes    \n",
      "---------------------------------------------------------------------------\n",
      "0  | cnn       | Sequential  | 87.6 K | [10, 42, 256] | [10, 128, 26]\n",
      "1  | cnn.0     | Conv1d      | 21.6 K | [10, 42, 256] | [10, 64, 83] \n",
      "2  | cnn.1     | BatchNorm1d | 128    | [10, 64, 83]  | [10, 64, 83] \n",
      "3  | cnn.2     | ReLU        | 0      | [10, 64, 83]  | [10, 64, 83] \n",
      "4  | cnn.3     | Conv1d      | 65.7 K | [10, 64, 83]  | [10, 128, 26]\n",
      "5  | cnn.4     | BatchNorm1d | 256    | [10, 128, 26] | [10, 128, 26]\n",
      "6  | cnn.5     | ReLU        | 0      | [10, 128, 26] | [10, 128, 26]\n",
      "7  | linear    | Sequential  | 9.2 M  | [10, 3328]    | [10, 10]     \n",
      "8  | linear.0  | Linear      | 6.8 M  | [10, 3328]    | [10, 2048]   \n",
      "9  | linear.1  | BatchNorm1d | 4.1 K  | [10, 2048]    | [10, 2048]   \n",
      "10 | linear.2  | ReLU        | 0      | [10, 2048]    | [10, 2048]   \n",
      "11 | linear.3  | Linear      | 2.1 M  | [10, 2048]    | [10, 1024]   \n",
      "12 | linear.4  | BatchNorm1d | 2.0 K  | [10, 1024]    | [10, 1024]   \n",
      "13 | linear.5  | ReLU        | 0      | [10, 1024]    | [10, 1024]   \n",
      "14 | linear.6  | Linear      | 262 K  | [10, 1024]    | [10, 256]    \n",
      "15 | linear.7  | BatchNorm1d | 512    | [10, 256]     | [10, 256]    \n",
      "16 | linear.8  | ReLU        | 0      | [10, 256]     | [10, 256]    \n",
      "17 | linear.9  | Linear      | 32.9 K | [10, 256]     | [10, 128]    \n",
      "18 | linear.10 | BatchNorm1d | 256    | [10, 128]     | [10, 128]    \n",
      "19 | linear.11 | ReLU        | 0      | [10, 128]     | [10, 128]    \n",
      "20 | linear.12 | Linear      | 1.3 K  | [10, 128]     | [10, 10]     \n",
      "---------------------------------------------------------------------------\n",
      "9.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "9.3 M     Total params\n",
      "37.228    Total estimated model params size (MB)\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch.utilities.model_summary import ModelSummary\n",
    "\n",
    "net = Classifier1DMaxPoolBNModel(\n",
    "    cnn_channel_param = [\n",
    "        (42, 64, 8, 0, 3),\n",
    "        (64, 128, 8, 0, 3)\n",
    "    ],\n",
    "    pool_channel_param = [\n",
    "        None, None,\n",
    "    ],\n",
    "    linear_channel_param = [\n",
    "        1024, 256, 128\n",
    "    ],\n",
    "    out_class_num=10,\n",
    "    in_feature_shape=129)\n",
    "\n",
    "model_summary = ModelSummary(net, max_depth=6)\n",
    "print(model_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ----------------------start training---------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type       | Params | In sizes      | Out sizes    \n",
      "----------------------------------------------------------------------\n",
      "0 | cnn    | Sequential | 87.6 K | [10, 42, 256] | [10, 128, 26]\n",
      "1 | linear | Sequential | 9.2 M  | [10, 3328]    | [10, 10]     \n",
      "----------------------------------------------------------------------\n",
      "9.3 M     Trainable params\n",
      "0         Non-trainable params\n",
      "9.3 M     Total params\n",
      "37.228    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00,  4.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00,  4.68it/s]\n",
      "teardown\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 184.62it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.06542056053876877\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "teardown\n",
      "trainer.logger.log_dir None\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m trainer_test_dict\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m     33\u001b[0m     trainer_test_dict[key] \u001b[38;5;241m=\u001b[39m trainer_test_dict[key]\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresult.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     36\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(trainer_test_dict, f, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/compgan/lib/python3.8/posixpath.py:76\u001b[0m, in \u001b[0;36mjoin\u001b[0;34m(a, *p)\u001b[0m\n\u001b[1;32m     <a href='file:///home/tran/miniconda3/envs/compgan/lib/python3.8/posixpath.py?line=70'>71</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mjoin\u001b[39m(a, \u001b[39m*\u001b[39mp):\n\u001b[1;32m     <a href='file:///home/tran/miniconda3/envs/compgan/lib/python3.8/posixpath.py?line=71'>72</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Join two or more pathname components, inserting '/' as needed.\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/tran/miniconda3/envs/compgan/lib/python3.8/posixpath.py?line=72'>73</a>\u001b[0m \u001b[39m    If any component is an absolute path, all previous path components\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/tran/miniconda3/envs/compgan/lib/python3.8/posixpath.py?line=73'>74</a>\u001b[0m \u001b[39m    will be discarded.  An empty last part will result in a path that\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/tran/miniconda3/envs/compgan/lib/python3.8/posixpath.py?line=74'>75</a>\u001b[0m \u001b[39m    ends with a separator.\"\"\"\u001b[39;00m\n\u001b[0;32m---> <a href='file:///home/tran/miniconda3/envs/compgan/lib/python3.8/posixpath.py?line=75'>76</a>\u001b[0m     a \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mfspath(a)\n\u001b[1;32m     <a href='file:///home/tran/miniconda3/envs/compgan/lib/python3.8/posixpath.py?line=76'>77</a>\u001b[0m     sep \u001b[39m=\u001b[39m _get_sep(a)\n\u001b[1;32m     <a href='file:///home/tran/miniconda3/envs/compgan/lib/python3.8/posixpath.py?line=77'>78</a>\u001b[0m     path \u001b[39m=\u001b[39m a\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not NoneType"
     ]
    }
   ],
   "source": [
    "print(\" ----------------------start training---------------------------\")\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "\n",
    "tensorboard_logger = TensorBoardLogger(save_dir=log_save_dir, name=log_save_name,)\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=None,\n",
    "    save_top_k=1,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    filename=\"sample_{epoch:02d}-{step:02d}-{val_loss:02f}\"\n",
    ")\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    logger=[tensorboard_logger],\n",
    "    callbacks=[EarlyStopping(monitor=\"val_loss\", patience=patience), checkpoint_callback],\n",
    "    max_epochs=n_epochs,\n",
    "    check_val_every_n_epoch=10,\n",
    "    accelerator=\"gpu\", \n",
    "    )\n",
    "\n",
    "trainer.fit(model=net, datamodule=data_module)\n",
    "trainer_test_dict = trainer.logged_metrics\n",
    "\n",
    "trainer.test(model=net, datamodule=data_module)\n",
    "trainer_test_dict.update(trainer.logged_metrics)\n",
    "\n",
    "print(\"trainer.logger.log_dir\", trainer.logger.log_dir)\n",
    "\n",
    "for key in trainer_test_dict.keys():\n",
    "    trainer_test_dict[key] = trainer_test_dict[key].item()\n",
    "\n",
    "with open(os.path.join(trainer.logger.log_dir, \"result.json\"), \"w\") as f:\n",
    "    json.dump(trainer_test_dict, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f3f15c77c882d8433ef1043b53db379ca3772938d44c39305f8b807ce25a312a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.17 ('compgan': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

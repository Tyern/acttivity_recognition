{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df75ce92-d5e0-490f-940c-69cca04af9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchinfo import summary\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "from itertools import combinations\n",
    "import gc\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c378fcc-4593-49d6-8edc-7fbcf8b76c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = \"../data/compgan_dataset/\"\n",
    "\n",
    "train_data_file_name_ = \"train_data{}.npy\"\n",
    "train_label_file_name_ = \"train_label{}.npy\"\n",
    "test_data_file_name_ = \"test_data{}.npy\"\n",
    "test_label_file_name_ = \"test_label{}.npy\"\n",
    "\n",
    "TRAIN_FOLDER_PATH = os.path.join(DATA_ROOT, \"train\")\n",
    "TEST_FOLDER_PATH = os.path.join(DATA_ROOT, \"test\")\n",
    "RESULT_FOLDER_PATH = os.path.join(DATA_ROOT, \"results\")\n",
    "\n",
    "assert os.path.isdir(TRAIN_FOLDER_PATH) and os.path.isdir(TEST_FOLDER_PATH)\n",
    "os.makedirs(RESULT_FOLDER_PATH, exist_ok=True)\n",
    "\n",
    "data_files = sorted(glob.glob(os.path.join(TRAIN_FOLDER_PATH, train_data_file_name_.format(\"*\"))))\n",
    "print(data_files)\n",
    "print(len(data_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7213a894-b05b-4aed-919f-5095cc12a166",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_NUM = 16\n",
    "assert USER_NUM == len(data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c9aa360-ce49-4f39-a84e-31387e8229c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# important\n",
    "\n",
    "label_list = ['歩行(平地)',\n",
    " '歩行(階段)',\n",
    " 'ベッド上での起き上がり',\n",
    " 'ベッド椅子間の乗り移り(立つ)',\n",
    " 'ベッド椅子間の乗り移り(立たない)',\n",
    " '立ち座り',\n",
    " '座位保持・座位バランス',\n",
    " '立位保持・立位バランス',\n",
    " '関節可動域増大訓練(肩)',\n",
    " '関節可動域増大訓練(股関節)']\n",
    "\n",
    "label_dict = dict(enumerate(label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cea27346-8b63-431b-88cb-b8b4cb097701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# important\n",
    "eng_label_dict = dict(zip(\n",
    "    label_list,\n",
    "    ['Walking', 'Upstair', 'Bed_Standup', 'Change_Bed', 'Change_Bed_Standup', 'Sit_Down', 'Sit', 'Stand', 'Shoulder_Exercise', 'Hip_Exercise']\n",
    "))\n",
    "\n",
    "eng_label_list = [eng_label_dict[i] for i in label_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5740cda6-230f-45e5-a48d-7c14f2f5d33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb081853-0634-4f3e-ab7e-004edf6d3992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_test(test_user):\n",
    "    train_data_file_name = train_data_file_name_.format(test_user)\n",
    "    train_label_file_name = train_label_file_name_.format(test_user)\n",
    "    test_data_file_name = test_data_file_name_.format(test_user)\n",
    "    test_label_file_name = test_label_file_name_.format(test_user)\n",
    "\n",
    "    train_data_file_path = os.path.join(TRAIN_FOLDER_PATH, train_data_file_name)\n",
    "    train_label_file_path = os.path.join(TRAIN_FOLDER_PATH, train_label_file_name)\n",
    "    test_data_file_path = os.path.join(TEST_FOLDER_PATH, test_data_file_name)\n",
    "    test_label_file_path = os.path.join(TEST_FOLDER_PATH, test_label_file_name)\n",
    "\n",
    "    train_data, train_label = np.load(train_data_file_path), np.load(train_label_file_path)\n",
    "    test_data, test_label = np.load(test_data_file_path), np.load(test_label_file_path)\n",
    "\n",
    "    l, s, d, w = train_data.shape\n",
    "    train_data_reshape = train_data.reshape(l, s * d, w).transpose(0,2,1).reshape(-1, s * d)\n",
    "\n",
    "    l_t, s_t, d_t, w_t = test_data.shape\n",
    "    test_data_reshape = test_data.reshape(l_t, s_t * d_t, w_t).transpose(0,2,1).reshape(-1, s_t * d_t)\n",
    "\n",
    "    sc = StandardScaler()\n",
    "    train_data_reshape_norm = sc.fit_transform(train_data_reshape)\n",
    "    test_data_reshape_norm = sc.transform(test_data_reshape)\n",
    "\n",
    "    train_data_reshape_back = train_data_reshape_norm.reshape(l, w, s * d)\n",
    "    test_data_reshape_back = test_data_reshape_norm.reshape(l_t, w_t, s_t * d_t)\n",
    "\n",
    "    return train_data_reshape_back, train_label, test_data_reshape_back, test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd428f4b-3fc6-4ec4-b4fe-c96164304249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "train_data, train_label, test_data, test_label = load_train_test(test_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0ffc0b1-b9a0-4493-a4ec-28a3be124eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6361, 256, 42)\n",
      "(6361,)\n",
      "(214, 256, 42)\n",
      "(214,)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(train_label.shape)\n",
    "print(test_data.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54e8cca7-8c92-4a08-bc03-38f06bf24a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_num = train_data.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6a68c6-d3e1-43fe-a32a-4e7e8c055714",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a51fa7e1-0d0a-4168-a60f-3f0c8beaedac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, feature_data, label_data, missing_sensor_id_list=None):\n",
    "        self.features = feature_data\n",
    "        self.label = label_data\n",
    "        \n",
    "        if missing_sensor_id_list is not None:\n",
    "            for missing_sensor_id in missing_sensor_id_list:\n",
    "                self.features[:, :, missing_sensor_id*6:(missing_sensor_id+1)*6] = 0\n",
    "\n",
    "        assert len(self.features) == len(self.label), \"features len is not equal to label len\"\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.features[idx]\n",
    "        label = self.label[idx]\n",
    "        return x, int(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4dafaa88-cf0f-4144-91d5-71b28e148c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_dataset(test_user, missing_sensor_id_list, echo=0):\n",
    "    if echo: \n",
    "        print(\"***********Start get_train_test_dataset***********\")\n",
    "        print(\"missing_sensor_id_list:\", missing_sensor_id_list)\n",
    "    \n",
    "    train_dataset_concat_list = []\n",
    "    for user in range(USER_NUM):\n",
    "        if user == test_user:\n",
    "            if echo: print(\"test_user\", user)\n",
    "            train_data, train_label, test_data, test_label = load_train_test(user)\n",
    "            test_dataset = CustomDataset(test_data, test_label, missing_sensor_id_list=missing_sensor_id_list)\n",
    "    \n",
    "        else:\n",
    "            if echo: print(\"train_user\", user)\n",
    "            train_data, train_label, test_data, test_label = load_train_test(user)\n",
    "            train_dataset = CustomDataset(train_data, train_label, missing_sensor_id_list=missing_sensor_id_list)\n",
    "            train_dataset_concat_list.append(train_dataset)\n",
    "\n",
    "    concat_train_dataset = torch.utils.data.ConcatDataset(train_dataset_concat_list)\n",
    "    if not echo: print(\"***********get_train_test_dataset completed***********\")\n",
    "    return concat_train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24ead38d-3779-4fe5-93e5-4815710795ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_for_missing_sensor_number(test_user, missing_sensor_numbers, echo=0):\n",
    "    if echo: print(\"****************Start create_dataset_for_missing_sensor_number\", test_user, missing_sensor_numbers, \"****************\")\n",
    "    train_dataset_list = []\n",
    "    val_dataset_list = []\n",
    "    test_dataset_list = []\n",
    "    \n",
    "    for missing_count in range(missing_sensor_numbers + 1):\n",
    "        for missing_index in combinations(range(7), missing_count):\n",
    "\n",
    "            dataset, test_dataset = get_train_test_dataset(test_user=test_user, missing_sensor_id_list=missing_index, echo=echo)\n",
    "            train_size = int(0.8 * len(dataset))\n",
    "            val_size = len(dataset) - train_size\n",
    "            train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "            train_dataset_list.append(train_dataset)\n",
    "            val_dataset_list.append(val_dataset)\n",
    "            test_dataset_list.append(test_dataset)\n",
    "\n",
    "    del dataset, test_dataset, train_dataset, val_dataset\n",
    "    gc.collect()\n",
    "    \n",
    "    train_dataset = torch.utils.data.ConcatDataset(train_dataset_list)\n",
    "    val_dataset = torch.utils.data.ConcatDataset(val_dataset_list)\n",
    "    test_dataset = torch.utils.data.ConcatDataset(test_dataset_list)\n",
    "    if echo: print(\"****************Completed create_dataset_for_missing_sensor_number****************\")\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6fc8ea-9181-46e3-bec8-e114695add57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************Start create_dataset_for_missing_sensor_number 0 1 ****************\n",
      "***********Start get_train_test_dataset***********\n",
      "missing_sensor_id_list: ()\n",
      "test_user 0\n",
      "train_user 1\n",
      "train_user 2\n",
      "train_user 3\n",
      "train_user 4\n",
      "train_user 5\n",
      "train_user 6\n",
      "train_user 7\n",
      "train_user 8\n",
      "train_user 9\n",
      "train_user 10\n",
      "train_user 11\n",
      "train_user 12\n",
      "train_user 13\n",
      "train_user 14\n",
      "train_user 15\n",
      "***********Start get_train_test_dataset***********\n",
      "missing_sensor_id_list: (0,)\n",
      "test_user 0\n",
      "train_user 1\n",
      "train_user 2\n",
      "train_user 3\n",
      "train_user 4\n",
      "train_user 5\n",
      "train_user 6\n",
      "train_user 7\n",
      "train_user 8\n",
      "train_user 9\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "# train_dataset, val_dataset, test_dataset = create_dataset_for_missing_sensor_number(test_user=0, missing_sensor_numbers=0, echo=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "152c67ba-250d-43a7-9253-8f273b6847e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "# train_dataloader = DataLoader(\n",
    "#     train_dataset, \n",
    "#     batch_size=8,\n",
    "#     num_workers=0, # number of subprocesses to use for data loading\n",
    "#     shuffle=True)\n",
    "\n",
    "# val_dataloader = DataLoader(\n",
    "#     train_dataset, \n",
    "#     batch_size=8,\n",
    "#     num_workers=0, # number of subprocesses to use for data loading\n",
    "#     shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ee9b96f-a6bb-4906-ad7c-7bdd16d18f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 256, 42])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# next(train_dataloader.__iter__())[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362325df-ae83-45a6-8586-64cfaace85fc",
   "metadata": {},
   "source": [
    "## model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a402c05-8df2-4986-a0e7-aa1015dd9137",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.query = nn.Linear(input_dim, input_dim)\n",
    "        self.key = nn.Linear(input_dim, input_dim)\n",
    "        self.value = nn.Linear(input_dim, input_dim)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        queries = self.query(x)\n",
    "        keys = self.key(x)\n",
    "        values = self.value(x)\n",
    "        scores = torch.bmm(queries, keys.transpose(1, 2)) / (self.input_dim ** 0.5)\n",
    "        attention = self.softmax(scores)\n",
    "        weighted = torch.bmm(attention, values)\n",
    "        return weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57fda4c5-7c60-40e5-9a4e-729ac2d4d862",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Attention_Model(pl.LightningModule):\n",
    "    model_name = \"LSTM_Attention_Model\"\n",
    "    def __init__(self, hidden_size=128, input_size=30, output_size=6):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.example_input_array = torch.Tensor(1024, 200, input_size)\n",
    "        \n",
    "        self.rnn1 = nn.LSTM(input_size=input_size, \n",
    "                          hidden_size=hidden_size,\n",
    "                          num_layers=1,\n",
    "                          batch_first=True)\n",
    "        \n",
    "        self.attention1 = SelfAttention(\n",
    "            input_dim=hidden_size)\n",
    "\n",
    "        self.rnn2 = nn.LSTM(input_size=hidden_size, \n",
    "                          hidden_size=hidden_size,\n",
    "                          num_layers=1,\n",
    "                          batch_first=True)\n",
    "        \n",
    "        self.attention2 = SelfAttention(\n",
    "            input_dim=hidden_size\n",
    "        )\n",
    "        \n",
    "        self.seq_1 = nn.Sequential(\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.seq_2 = nn.Sequential(\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Linear(in_features=3 * hidden_size, out_features=output_size)\n",
    "        \n",
    "        self.all_test = []\n",
    "        self.all_pred = []\n",
    "        \n",
    "    def forward(self, x):\n",
    "        activation, _ = self.rnn1(x)\n",
    "        activation = self.attention1(activation)\n",
    "        activation, _ = self.rnn2(activation)\n",
    "        activation = self.attention2(activation)\n",
    "\n",
    "        b, _, _ = activation.size()\n",
    "        \n",
    "        lstm_output = activation[:,-1,:].view(b,-1)\n",
    "        \n",
    "        seq_1_output = self.seq_1(lstm_output)\n",
    "        seq_2_output = self.seq_2(lstm_output)\n",
    "        \n",
    "        output = torch.concat([lstm_output, seq_1_output, seq_2_output], dim=1)\n",
    "        output = self.classifier(output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(params=self.parameters(), lr=0.0005)\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        # 1. Forward pass\n",
    "        y_pred = self.forward(X)\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        \n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the test loop\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        y = y\n",
    "    \n",
    "        # 1. Forward pass\n",
    "        test_pred_logits = self.forward(X)\n",
    "\n",
    "        # Calculate and accumulate accuracy\n",
    "        test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "        test_acc = ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "        self.log(\"test_acc\", test_acc)\n",
    "        \n",
    "        self.all_pred = test_pred_labels\n",
    "        self.all_test = y\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # this is the validation loop\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        y = y\n",
    "        \n",
    "        y_pred = self.forward(X)\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        \n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7153d6a2-d187-473e-ab8e-516b2426792f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LSTMModel(pl.LightningModule):\n",
    "    model_name = \"LSTMModel\"\n",
    "    def __init__(self, hidden_size=128, input_size=30, output_size=6):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.LSTM(input_size=input_size, \n",
    "                          hidden_size=hidden_size,\n",
    "                          num_layers=2,\n",
    "                          batch_first=True)\n",
    "        \n",
    "        self.seq_1 = nn.Sequential(\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.seq_2 = nn.Sequential(\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Linear(in_features=3 * hidden_size, out_features=output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        activation, _ = self.rnn(x)\n",
    "        \n",
    "        b, _, _ = activation.size()\n",
    "        lstm_output = activation[:,-1,:].view(b,-1)\n",
    "        seq_1_output = self.seq_1(lstm_output)\n",
    "        seq_2_output = self.seq_2(lstm_output)\n",
    "        \n",
    "        output = torch.concat([lstm_output, seq_1_output, seq_2_output], dim=1)\n",
    "        output = self.classifier(output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(params=self.parameters(), lr=0.0005)\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        # 1. Forward pass\n",
    "        y_pred = self.forward(X)\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        \n",
    "        self.log(\"train_loss\", loss)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the test loop\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "    \n",
    "        # 1. Forward pass\n",
    "        test_pred_logits = self.forward(X)\n",
    "\n",
    "        # Calculate and accumulate accuracy\n",
    "        test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "        test_acc = ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "        self.log(\"test_acc\", test_acc)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # this is the validation loop\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        \n",
    "        y_pred = self.forward(X)\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        \n",
    "        self.log(\"val_loss\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ddbd855c-2ac7-44ac-80e0-b908fda58eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LSTMModel'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_model = LSTMModel\n",
    "use_model.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd27b8cd-e870-4c73-a356-210aa1d8c2bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "LSTMModel                                --\n",
       "├─LSTM: 1-1                              214,016\n",
       "├─Sequential: 1-2                        --\n",
       "│    └─Linear: 2-1                       16,512\n",
       "│    └─BatchNorm1d: 2-2                  256\n",
       "│    └─Dropout1d: 2-3                    --\n",
       "│    └─ReLU: 2-4                         --\n",
       "│    └─Linear: 2-5                       16,512\n",
       "│    └─BatchNorm1d: 2-6                  256\n",
       "│    └─Dropout1d: 2-7                    --\n",
       "│    └─ReLU: 2-8                         --\n",
       "├─Sequential: 1-3                        --\n",
       "│    └─Linear: 2-9                       16,512\n",
       "│    └─BatchNorm1d: 2-10                 256\n",
       "│    └─Dropout1d: 2-11                   --\n",
       "│    └─ReLU: 2-12                        --\n",
       "│    └─Linear: 2-13                      16,512\n",
       "│    └─BatchNorm1d: 2-14                 256\n",
       "│    └─Dropout1d: 2-15                   --\n",
       "│    └─ReLU: 2-16                        --\n",
       "├─Linear: 1-4                            2,310\n",
       "=================================================================\n",
       "Total params: 283,398\n",
       "Trainable params: 283,398\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = use_model()\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e2386328-0a31-4586-8c4a-ebe495def323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,), (1,), (2,), (3,), (4,), (5,), (6,)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(combinations(range(7),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2b4f34-cd31-47fe-940c-3fd3f12d817f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start learning missing_sensor_numbers = 1\n",
      "\n",
      "*************training on User0*************\n",
      "***********get_train_test_dataset completed***********\n",
      "***********get_train_test_dataset completed***********\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "patience = 20\n",
    "# missing_sensor_numbers = 0\n",
    "all_test_pred = {}\n",
    "start_timer = time.perf_counter()\n",
    "# missing sensors number is the number of missing sensor, we loop it through 7 sensors\n",
    "for missing_sensor_numbers in [1,2,3,4,5,6]:\n",
    "    print(f\"start learning missing_sensor_numbers = {missing_sensor_numbers}\")\n",
    "    \n",
    "    all_test = []\n",
    "    all_pred = []\n",
    "\n",
    "    # kfold_train_test_index_list = [kfold_train_test_index_list[0]]\n",
    "\n",
    "    for i in range(len(data_files)):\n",
    "        print(f\"\\n*************training on User{i}*************\")\n",
    "\n",
    "        train_dataset, val_dataset, test_dataset = create_dataset_for_missing_sensor_number(i, missing_sensor_numbers)\n",
    "        \n",
    "        train_dataloader = DataLoader(\n",
    "            train_dataset, \n",
    "            batch_size=batch_size,\n",
    "            num_workers=4, # number of subprocesses to use for data loading\n",
    "            shuffle=True)\n",
    "\n",
    "        val_dataloader = DataLoader(\n",
    "            val_dataset, \n",
    "            batch_size=batch_size,\n",
    "            num_workers=2, # number of subprocesses to use for data loading\n",
    "            shuffle=False)\n",
    "\n",
    "        test_dataloader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=batch_size,\n",
    "            num_workers=2, # number of subprocesses to use for data loading\n",
    "            shuffle=False)\n",
    "\n",
    "        model = use_model(hidden_size=128, input_size=feature_num, output_size=len(label_list))\n",
    "\n",
    "        tb_logger = TensorBoardLogger(\".\")\n",
    "\n",
    "        trainer = pl.Trainer(\n",
    "            logger=tb_logger,\n",
    "            callbacks=[EarlyStopping(monitor=\"val_loss\", patience=patience, mode=\"min\")],\n",
    "        )\n",
    "        trainer.fit(model, train_dataloader, val_dataloader)\n",
    "        trainer.test(model, test_dataloader)\n",
    "\n",
    "        all_test.extend(model.all_test)\n",
    "        all_pred.extend(model.all_pred)\n",
    "            \n",
    "        all_test_pred[missing_index] = (all_test, all_pred)\n",
    "    \n",
    "    os.makedirs(RESULT_FOLDER_PATH, exist_ok=True)\n",
    "    with open(os.path.join(RESULT_FOLDER_PATH, f\"00_all_test_pred_{missing_sensor_numbers}_{model.model_name}.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(all_test_pred, f)\n",
    "\n",
    "print(\"Executed Time:\", time.perf_counter() - start_timer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "779bd072-9b6d-4804-8936-ab6ea58962ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Axes' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m         all_pred_with_label \u001b[38;5;241m=\u001b[39m [label_list[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m all_pred]\n\u001b[1;32m     27\u001b[0m         cf \u001b[38;5;241m=\u001b[39m confusion_matrix(all_test_with_label, all_pred_with_label, labels\u001b[38;5;241m=\u001b[39mlabel_list)\n\u001b[0;32m---> 28\u001b[0m         sns\u001b[38;5;241m.\u001b[39mheatmap(cf, ax\u001b[38;5;241m=\u001b[39m\u001b[43max\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mrow_item\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43mrow_item\u001b[49m\u001b[43m]\u001b[49m, annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, xticklabels\u001b[38;5;241m=\u001b[39meng_label_list, yticklabels\u001b[38;5;241m=\u001b[39meng_label_list, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     29\u001b[0m         ax[idx\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mrow_item][idx\u001b[38;5;241m%\u001b[39mrow_item]\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmissing_index \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m confusion matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m plt\u001b[38;5;241m.\u001b[39msavefig(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(RESULT_FOLDER_PATH, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall_test_pred_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_sensor_numbers\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Axes' object is not subscriptable"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1300x2800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for missing_sensor_numbers in range(1):\n",
    "#     with open(os.path.join(RESULT_FOLDER_PATH, f\"00_all_test_pred_{missing_sensor_numbers}_{use_model.model_name}.pkl\"), \"rb\") as f:\n",
    "#         all_test_pred = pickle.load(f)\n",
    "\n",
    "#     if all_test_pred == 0:\n",
    "#         missing_index = list(all_test_pred.keys())[0]\n",
    "        \n",
    "#         all_tall_test, all_pred = all_test_pred[missing_index]\n",
    "        \n",
    "#         # print(\"missing index\", missing_index)\n",
    "#         all_test_with_label = [label_list[i] for i in all_test]\n",
    "#         all_pred_with_label = [label_list[i] for i in all_pred]\n",
    "        \n",
    "#         cf = confusion_matrix(all_test_with_label, all_pred_with_label, labels=label_list)\n",
    "#         sns.heatmap(cf, annot=True, xticklabels=eng_label_list, yticklabels=eng_label_list, fmt='g')\n",
    "#     else:\n",
    "#         row_item = 2\n",
    "#         fig, ax = plt.subplots(len(all_test_pred.keys()) // row_item + len(all_test_pred.keys()) % row_item, row_item, figsize=(13,28))\n",
    "        \n",
    "#         for idx, missing_index in enumerate(all_test_pred.keys()):\n",
    "#             all_test, all_pred = all_test_pred[missing_index]\n",
    "            \n",
    "#             # print(\"missing index\", missing_index)\n",
    "#             all_test_with_label = [label_list[i] for i in all_test]\n",
    "#             all_pred_with_label = [label_list[i] for i in all_pred]\n",
    "            \n",
    "#             cf = confusion_matrix(all_test_with_label, all_pred_with_label, labels=label_list)\n",
    "#             sns.heatmap(cf, ax=ax[idx//row_item][idx%row_item], annot=True, xticklabels=eng_label_list, yticklabels=eng_label_list, fmt='g')\n",
    "#             ax[idx//row_item][idx%row_item].set_title(f\"missing_index {missing_index} confusion matrix\")\n",
    "            \n",
    "#     plt.savefig(os.path.join(RESULT_FOLDER_PATH, f\"00_all_test_pred_{missing_sensor_numbers}_{use_model.model_name}.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6fc90823-f196-4393-a37f-0cffe23e4c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.434828897338403"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.metrics import accuracy_score\n",
    "# all_test = list(map(lambda x: x.cpu().item(), all_tall_test))\n",
    "# all_pred = list(map(lambda x: x.cpu().item(), all_pred))\n",
    "# accuracy_score(all_test, all_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c861afc9-a211-4468-a6b4-6d159d9c3dce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

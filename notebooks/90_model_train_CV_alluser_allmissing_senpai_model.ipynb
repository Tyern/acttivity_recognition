{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4ce6502-93ec-4660-8864-7ff3019c6084",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tran/miniconda3/envs/compgan/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchinfo import summary\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import tracemalloc \n",
    "\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "from itertools import combinations\n",
    "import gc\n",
    "import time\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afe087b5-0c7e-47da-8725-354729b83319",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c153c485-8474-4042-a29b-31ea8978c7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../data/compgan_dataset/train/train_data0.npy', '../data/compgan_dataset/train/train_data1.npy', '../data/compgan_dataset/train/train_data10.npy', '../data/compgan_dataset/train/train_data11.npy', '../data/compgan_dataset/train/train_data12.npy', '../data/compgan_dataset/train/train_data13.npy', '../data/compgan_dataset/train/train_data14.npy', '../data/compgan_dataset/train/train_data15.npy', '../data/compgan_dataset/train/train_data2.npy', '../data/compgan_dataset/train/train_data3.npy', '../data/compgan_dataset/train/train_data4.npy', '../data/compgan_dataset/train/train_data5.npy', '../data/compgan_dataset/train/train_data6.npy', '../data/compgan_dataset/train/train_data7.npy', '../data/compgan_dataset/train/train_data8.npy', '../data/compgan_dataset/train/train_data9.npy']\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "DATA_ROOT = \"../data/compgan_dataset/\"\n",
    "\n",
    "train_data_file_name_ = \"train_data{}.npy\"\n",
    "train_label_file_name_ = \"train_label{}.npy\"\n",
    "test_data_file_name_ = \"test_data{}.npy\"\n",
    "test_label_file_name_ = \"test_label{}.npy\"\n",
    "\n",
    "TRAIN_FOLDER_PATH = os.path.join(DATA_ROOT, \"train\")\n",
    "TEST_FOLDER_PATH = os.path.join(DATA_ROOT, \"test\")\n",
    "RESULT_FOLDER_PATH = os.path.join(DATA_ROOT, \"results\")\n",
    "PREV_CHECKPOINT_FOLDER_PATH = os.path.join(DATA_ROOT, \"prev_checkpoint\")\n",
    "\n",
    "assert os.path.isdir(TRAIN_FOLDER_PATH) and os.path.isdir(TEST_FOLDER_PATH)\n",
    "os.makedirs(RESULT_FOLDER_PATH, exist_ok=True)\n",
    "\n",
    "data_files = sorted(glob.glob(os.path.join(TRAIN_FOLDER_PATH, train_data_file_name_.format(\"*\"))))\n",
    "print(data_files)\n",
    "print(len(data_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "878427cd-91fa-4b99-94c8-399378c81dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_NUM = 16\n",
    "SENSOR_NUM = 7\n",
    "EACH_SENSOR_CHANNEL = 6\n",
    "assert USER_NUM == len(data_files)\n",
    "feature_num = SENSOR_NUM * EACH_SENSOR_CHANNEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee7a344b-73b9-4310-a650-c06bea9f68da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# important\n",
    "\n",
    "label_list = ['歩行(平地)',\n",
    " '歩行(階段)',\n",
    " 'ベッド上での起き上がり',\n",
    " 'ベッド椅子間の乗り移り(立つ)',\n",
    " 'ベッド椅子間の乗り移り(立たない)',\n",
    " '立ち座り',\n",
    " '座位保持・座位バランス',\n",
    " '立位保持・立位バランス',\n",
    " '関節可動域増大訓練(肩)',\n",
    " '関節可動域増大訓練(股関節)']\n",
    "\n",
    "label_dict = dict(enumerate(label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45f45c18-d2c9-46e9-89bf-75b68dbd12da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# important\n",
    "eng_label_dict = dict(zip(\n",
    "    label_list,\n",
    "    ['Walking', 'Upstair', 'Bed_Standup', 'Change_Bed', 'Change_Bed_Standup', 'Sit_Down', 'Sit', 'Stand', 'Shoulder_Exercise', 'Hip_Exercise']\n",
    "))\n",
    "\n",
    "eng_label_list = [eng_label_dict[i] for i in label_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02513f37-d192-4fae-a376-af38807bf29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update after 2023/11/11 houkoku\n",
    "class CustomTrainDataset(Dataset):\n",
    "    TRAIN_MODE = \"train\"\n",
    "    TEST_MODE = \"test\"\n",
    "    \n",
    "    def __init__(self, mode, feature_data, label_data, missing_sensor_numbers=0):\n",
    "        self.mode = mode\n",
    "        assert mode in [self.TRAIN_MODE, self.TEST_MODE]\n",
    "        \n",
    "        self.features = feature_data\n",
    "        self.label = label_data\n",
    "        assert len(self.features) == len(self.label), \"features len is not equal to label len\"\n",
    "        self.missing_sensor_numbers = missing_sensor_numbers\n",
    "\n",
    "        self.missing_index_list = []\n",
    "        for missing_count in range(missing_sensor_numbers + 1):\n",
    "            for missing_index in combinations(range(SENSOR_NUM), missing_count):\n",
    "                self.missing_index_list.append(missing_index)\n",
    "\n",
    "    def transform(self, one_feature, missing_sensor_id_list):\n",
    "        # Make one sensor data become 0\n",
    "        one_feature_cp = one_feature.copy()\n",
    "        \n",
    "        for missing_sensor_id in missing_sensor_id_list:\n",
    "            one_feature_cp[:, missing_sensor_id*6:(missing_sensor_id+1)*6] = 0\n",
    "        return one_feature_cp\n",
    "        \n",
    "    def __len__(self):\n",
    "\n",
    "        # take all available missing pattern * data number\n",
    "        return len(self.features) * len(self.missing_index_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # take all available missing pattern\n",
    "        missing_sensor_id_list = self.missing_index_list[ idx // len(self.features) ]\n",
    "        x = self.transform(self.features[ idx % len(self.features) ], missing_sensor_id_list)\n",
    "        label = self.label[idx % len(self.features)]\n",
    "        return x, int(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3225bf4a-954e-44ed-aee0-95672ed5fe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule(pl.LightningDataModule):\n",
    "    STANDARDIZE = False\n",
    "    \n",
    "    def __init__(self, test_user, missing_sensor_numbers, batch_size=2048):\n",
    "        super().__init__()\n",
    "        self.test_user = test_user\n",
    "        self.missing_sensor_numbers = missing_sensor_numbers\n",
    "        self.batch_size = batch_size\n",
    "        self.scaler = None\n",
    "\n",
    "    def load_data(self, mode):\n",
    "        if mode == \"train\":\n",
    "            folder_path = TRAIN_FOLDER_PATH\n",
    "            data_file_name = train_data_file_name_\n",
    "            label_file_name = train_label_file_name_\n",
    "\n",
    "            train_data_file_name = data_file_name.format(self.test_user)\n",
    "            train_label_file_name = label_file_name.format(self.test_user)\n",
    "    \n",
    "            train_data_file_path = os.path.join(folder_path, train_data_file_name)\n",
    "            train_label_file_path = os.path.join(folder_path, train_label_file_name)\n",
    "            train_val_data, train_val_label = np.load(train_data_file_path), np.load(train_label_file_path)\n",
    "            l, s, d, w = train_val_data.shape\n",
    "            self.scaler = StandardScaler()\n",
    "            # train_val_data = self.scaler.fit_transform(train_val_data.reshape(l, -1)).reshape(l, s, d, w)\n",
    "            train_val_data = train_val_data.reshape(l, s ,d, w).transpose(0, 3, 1, 2)\n",
    "            \n",
    "            # train_val_data_list = None\n",
    "            # train_val_label_list = None\n",
    "            # for user in range(USER_NUM):\n",
    "            #     if user == self.test_user: \n",
    "            #         continue\n",
    "                \n",
    "            #     print(\"train_user\", user)\n",
    "            #     train_data_file_name = data_file_name.format(user)\n",
    "            #     train_label_file_name = label_file_name.format(user)\n",
    "\n",
    "            #     train_data_file_path = os.path.join(folder_path, train_data_file_name)\n",
    "            #     train_label_file_path = os.path.join(folder_path, train_label_file_name)\n",
    "                \n",
    "            #     train_val_data, train_val_label = np.load(train_data_file_path), np.load(train_label_file_path)\n",
    "            #     l, s, d, w = train_val_data.shape\n",
    "            #     train_val_data = train_val_data.reshape(l, s ,d, w).transpose(0, 3, 1, 2)\n",
    "\n",
    "            #     if train_val_data_list is None:\n",
    "            #         train_val_data_list = train_val_data\n",
    "            #         train_val_label_list = train_val_label\n",
    "            #     else:\n",
    "            #         train_val_data_list = np.vstack((train_val_data_list, train_val_data))\n",
    "            #         train_val_label_list = np.concatenate((train_val_label_list, train_val_label))\n",
    "\n",
    "            # train_val_data = train_val_data_list\n",
    "            # train_val_label = train_val_label_list\n",
    "            \n",
    "        elif mode == \"test\":\n",
    "            folder_path = TEST_FOLDER_PATH\n",
    "            data_file_name = test_data_file_name_\n",
    "            label_file_name = test_label_file_name_\n",
    "    \n",
    "            train_data_file_name = data_file_name.format(self.test_user)\n",
    "            train_label_file_name = label_file_name.format(self.test_user)\n",
    "    \n",
    "            train_data_file_path = os.path.join(folder_path, train_data_file_name)\n",
    "            train_label_file_path = os.path.join(folder_path, train_label_file_name)\n",
    "            train_val_data, train_val_label = np.load(train_data_file_path), np.load(train_label_file_path)\n",
    "            l, s, d, w = train_val_data.shape\n",
    "            # train_val_data = self.scaler.transform(train_val_data.reshape(l, -1)).reshape(l, s, d, w)\n",
    "            train_val_data = train_val_data.reshape(l, s ,d, w).transpose(0, 3, 1, 2)\n",
    "    \n",
    "        return train_val_data, train_val_label\n",
    "\n",
    "    def setup(self, stage: str):\n",
    "        # Assign Train/val split(s) for use in Dataloaders\n",
    "        \n",
    "        if stage == \"validate\" or stage == \"fit\":\n",
    "            train_val_data, train_val_label = self.load_data(\"train\")\n",
    "            self.train_data, self.val_data, self.train_label, self.val_label = train_test_split(\n",
    "                train_val_data, train_val_label, test_size=0.2, train_size=0.8, random_state=42, shuffle=True)\n",
    "\n",
    "            self.train_dataset = CustomTrainDataset(\n",
    "                CustomTrainDataset.TRAIN_MODE, self.train_data, self.train_label, missing_sensor_numbers=self.missing_sensor_numbers)\n",
    "            self.val_dataset = CustomTrainDataset(\n",
    "                CustomTrainDataset.TEST_MODE, self.val_data, self.val_label, missing_sensor_numbers=self.missing_sensor_numbers)\n",
    "\n",
    "        elif stage == \"test\" or stage == \"predict\":\n",
    "            train_val_data, train_val_label = self.load_data(\"test\")\n",
    "            self.test_data = train_val_data\n",
    "            self.test_label = train_val_label\n",
    "\n",
    "            self.test_dataset = CustomTrainDataset(\n",
    "                CustomTrainDataset.TEST_MODE, self.test_data, self.test_label, missing_sensor_numbers=self.missing_sensor_numbers)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, num_workers=4, shuffle=True, pin_memory=True)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size,  num_workers=4, shuffle=False, pin_memory=True)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size,  num_workers=4, shuffle=False, pin_memory=True)\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size,  num_workers=4, shuffle=False, pin_memory=True)\n",
    "\n",
    "    def teardown(self, stage):\n",
    "        print(\"teardown\")\n",
    "        if stage == \"validate\" or stage == \"fit\":\n",
    "            del self.train_data, self.train_label\n",
    "            del self.val_data, self.val_label\n",
    "            del self.train_dataset\n",
    "            del self.val_dataset\n",
    "            \n",
    "        elif stage == \"test\" or stage == \"predict\":\n",
    "            del self.test_data, self.test_label\n",
    "            del self.test_dataset\n",
    "        gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a89352ec-f6dc-45a1-80d5-f52a59d38953",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TEST:\n",
    "    data_module = DataModule(test_user=0, missing_sensor_numbers=1)\n",
    "    data_module.setup(\"fit\")\n",
    "    print(data_module.train_data.shape)\n",
    "    print(data_module.val_data.shape)\n",
    "    # print(data_module.test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fded757e-a29f-47ad-addf-a8989028ec80",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TEST:\n",
    "    data = data_module.val_dataset[1273 * 2 + 1]\n",
    "    print(data[1], data[0][0])\n",
    "    print(len(data_module.val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e760566-e117-4fc6-b639-a2e2ec3c32da",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TEST:\n",
    "    del data_module, data\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdb0600-ebb2-4d73-94f2-d8e4729336bd",
   "metadata": {},
   "source": [
    "## MODEL DEFINITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7c60561",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ConvLSTMCell(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size, bias):\n",
    "        \"\"\"\n",
    "        Initialize ConvLSTM cell.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_dim: int\n",
    "            Number of channels of input tensor.\n",
    "        hidden_dim: int\n",
    "            Number of channels of hidden state.\n",
    "        kernel_size: (int, int)\n",
    "            Size of the convolutional kernel.\n",
    "        bias: bool\n",
    "            Whether or not to add the bias.\n",
    "            \n",
    "        Input: ()\n",
    "        \"\"\"\n",
    "\n",
    "        super(ConvLSTMCell, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = kernel_size[0] // 2, kernel_size[1] // 2\n",
    "        self.bias = bias\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels=self.input_dim + self.hidden_dim,\n",
    "                              out_channels=4 * self.hidden_dim,\n",
    "                              kernel_size=self.kernel_size,\n",
    "                              padding=self.padding,\n",
    "                              bias=self.bias)\n",
    "\n",
    "    def forward(self, input_tensor, cur_state):\n",
    "        h_cur, c_cur = cur_state\n",
    "\n",
    "        combined = torch.cat([input_tensor, h_cur], dim=1)  # concatenate along channel axis\n",
    "\n",
    "        combined_conv = self.conv(combined)\n",
    "        cc_i, cc_f, cc_o, cc_g = torch.split(combined_conv, self.hidden_dim, dim=1)\n",
    "        i = torch.sigmoid(cc_i)\n",
    "        f = torch.sigmoid(cc_f)\n",
    "        o = torch.sigmoid(cc_o)\n",
    "        g = torch.tanh(cc_g)\n",
    "\n",
    "        c_next = f * c_cur + i * g\n",
    "        h_next = o * torch.tanh(c_next)\n",
    "\n",
    "        return h_next, c_next\n",
    "\n",
    "    def init_hidden(self, batch_size, image_size):\n",
    "        height, width = image_size\n",
    "        return (torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device),\n",
    "                torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40c15c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ConvLSTM(nn.Module):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters:\n",
    "        input_dim: Number of channels in input\n",
    "        hidden_dim: Number of hidden channels\n",
    "        kernel_size: Size of kernel in convolutions\n",
    "        num_layers: Number of LSTM layers stacked on each other\n",
    "        batch_first: Whether or not dimension 0 is the batch or not\n",
    "        bias: Bias or no bias in Convolution\n",
    "        return_all_layers: Return the list of computations for all layers\n",
    "        Note: Will do same padding.\n",
    "\n",
    "    Input:\n",
    "        A tensor of size B, T, C, H, W or T, B, C, H, W\n",
    "    Output:\n",
    "        A tuple of two lists of length num_layers (or length 1 if return_all_layers is False).\n",
    "            0 - layer_output_list is the list of lists of length T of each output\n",
    "            1 - last_state_list is the list of last states\n",
    "                    each element of the list is a tuple (h, c) for hidden state and memory\n",
    "    Example:\n",
    "        >> x = torch.rand((32, 10, 64, 128, 128))\n",
    "        >> convlstm = ConvLSTM(64, 16, 3, 1, True, True, False)\n",
    "        >> _, last_states = convlstm(x)\n",
    "        >> h = last_states[0][0]  # 0 for layer index, 0 for h index\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size, num_layers,\n",
    "                 batch_first=False, bias=True, return_all_layers=False):\n",
    "        super(ConvLSTM, self).__init__()\n",
    "\n",
    "        self._check_kernel_size_consistency(kernel_size)\n",
    "\n",
    "        # Make sure that both `kernel_size` and `hidden_dim` are lists having len == num_layers\n",
    "        kernel_size = self._extend_for_multilayer(kernel_size, num_layers)\n",
    "        hidden_dim = self._extend_for_multilayer(hidden_dim, num_layers)\n",
    "        \n",
    "        if not len(kernel_size) == len(hidden_dim) == num_layers:\n",
    "            raise ValueError('Inconsistent list length.')\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_first = batch_first\n",
    "        self.bias = bias\n",
    "        self.return_all_layers = return_all_layers\n",
    "\n",
    "        cell_list = []\n",
    "        for i in range(0, self.num_layers):\n",
    "            cur_input_dim = self.input_dim if i == 0 else self.hidden_dim[i - 1]\n",
    "\n",
    "            cell_list.append(ConvLSTMCell(input_dim=cur_input_dim,\n",
    "                                          hidden_dim=self.hidden_dim[i],\n",
    "                                          kernel_size=self.kernel_size[i],\n",
    "                                          bias=self.bias))\n",
    "\n",
    "        self.cell_list = nn.ModuleList(cell_list)\n",
    "\n",
    "    def forward(self, input_tensor, hidden_state=None):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_tensor: todo\n",
    "            5-D Tensor either of shape (t, b, c, h, w) or (b, t, c, h, w)\n",
    "        hidden_state: todo\n",
    "            None. todo implement stateful\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        last_state_list, layer_output\n",
    "        \"\"\"\n",
    "        if not self.batch_first:\n",
    "            # (t, b, c, h, w) -> (b, t, c, h, w)\n",
    "            input_tensor = input_tensor.permute(1, 0, 2, 3, 4)\n",
    "\n",
    "        b, _, _, h, w = input_tensor.size()\n",
    "\n",
    "        # Implement stateful ConvLSTM\n",
    "        if hidden_state is not None:\n",
    "            raise NotImplementedError()\n",
    "        else:\n",
    "            # Since the init is done in forward. Can send image size here\n",
    "            hidden_state = self._init_hidden(batch_size=b,\n",
    "                                             image_size=(h, w))\n",
    "\n",
    "        layer_output_list = []\n",
    "        last_state_list = []\n",
    "\n",
    "        seq_len = input_tensor.size(1)\n",
    "        cur_layer_input = input_tensor\n",
    "\n",
    "        for layer_idx in range(self.num_layers):\n",
    "\n",
    "            h, c = hidden_state[layer_idx]\n",
    "            output_inner = []\n",
    "            for t in range(seq_len):\n",
    "                h, c = self.cell_list[layer_idx](input_tensor=cur_layer_input[:, t, :, :, :],\n",
    "                                                 cur_state=[h, c])\n",
    "                output_inner.append(h)\n",
    "\n",
    "            layer_output = torch.stack(output_inner, dim=1)\n",
    "            cur_layer_input = layer_output\n",
    "\n",
    "            layer_output_list.append(layer_output)\n",
    "            last_state_list.append([h, c])\n",
    "\n",
    "        if not self.return_all_layers:\n",
    "            layer_output_list = layer_output_list[-1:]\n",
    "            last_state_list = last_state_list[-1:]\n",
    "\n",
    "        return layer_output_list, last_state_list\n",
    "\n",
    "    def _init_hidden(self, batch_size, image_size):\n",
    "        init_states = []\n",
    "        for i in range(self.num_layers):\n",
    "            init_states.append(self.cell_list[i].init_hidden(batch_size, image_size))\n",
    "        return init_states\n",
    "\n",
    "    @staticmethod\n",
    "    def _check_kernel_size_consistency(kernel_size):\n",
    "        if not (isinstance(kernel_size, tuple) or\n",
    "                (isinstance(kernel_size, list) and all([isinstance(elem, tuple) for elem in kernel_size]))):\n",
    "            raise ValueError('`kernel_size` must be tuple or list of tuples')\n",
    "\n",
    "    @staticmethod\n",
    "    def _extend_for_multilayer(param, num_layers):\n",
    "        if not isinstance(param, list):\n",
    "            param = [param] * num_layers\n",
    "        return param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e25c4ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLSTMModel(pl.LightningModule):\n",
    "    def __init__(self, hidden_size=64, sequence_length=256, cnn_filter_size=64, output_size=10, **kwargs):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.example_input_array = torch.Tensor(10, sequence_length, SENSOR_NUM, EACH_SENSOR_CHANNEL)\n",
    "        \n",
    "        self.conv_lstm = ConvLSTM(input_dim=1, hidden_dim=[cnn_filter_size], kernel_size=(1,3), num_layers=1, batch_first=True,)\n",
    "        self.dropout = nn.Dropout2d(p=0.5)\n",
    "        self.linear1 = nn.Linear(in_features=sequence_length * cnn_filter_size * SENSOR_NUM* EACH_SENSOR_CHANNEL, out_features=hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(in_features=hidden_size, out_features=output_size)\n",
    "        self.softmax = nn.Softmax()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = torch.unsqueeze(x, dim=2)\n",
    "        h, _ = self.conv_lstm(out)\n",
    "        out = self.dropout(h[0])\n",
    "        out = out.view(out.shape[0], self.hparams.sequence_length * self.hparams.cnn_filter_size * SENSOR_NUM * EACH_SENSOR_CHANNEL)\n",
    "        out = self.linear1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.softmax(out)\n",
    "        return out        \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(params=self.parameters(), lr=0.0005)\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        # 1. Forward pass\n",
    "        y_pred = self.forward(X)\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        \n",
    "        self.log(\"train_loss\", loss)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the test loop\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "    \n",
    "        # 1. Forward pass\n",
    "        test_pred_logits = self.forward(X)\n",
    "\n",
    "        # Calculate and accumulate accuracy\n",
    "        test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "        test_acc = ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "        self.log(\"test_acc\", test_acc)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # this is the validation loop\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        \n",
    "        y_pred = self.forward(X)\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        \n",
    "        self.log(\"val_loss\", loss)\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        \n",
    "        test_pred_logits = self.forward(X)\n",
    "        test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "        \n",
    "        return test_pred_labels\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "163ad44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TEST:\n",
    "    from pytorch_lightning.utilities.model_summary import ModelSummary\n",
    "    model = ConvLSTMModel()\n",
    "    model_summary = ModelSummary(model, max_depth=2)\n",
    "    print(model_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac8e4547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.rand(10, 256, 7, 6)\n",
    "# conv_lstm = ConvLSTM(input_dim=1, hidden_dim=[64], kernel_size=(1,3), num_layers=1, batch_first=True)\n",
    "# x = torch.unsqueeze(x, dim=2)\n",
    "# print(conv_lstm(x)[0][0].shape)\n",
    "# out = conv_lstm(x)[0][0].view(-1, 256, 64 * 42)\n",
    "\n",
    "# attention1 = nn.MultiheadAttention(\n",
    "#             embed_dim=42*64,\n",
    "#             num_heads=1,\n",
    "#             batch_first=True\n",
    "#         )\n",
    "# print(attention1(out, out, out)[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9497cec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden_size=64\n",
    "# sequence_length=256\n",
    "# cnn_filter_size=64\n",
    "# output_size=10\n",
    "\n",
    "# x = torch.Tensor(10, sequence_length, SENSOR_NUM, EACH_SENSOR_CHANNEL)\n",
    "# conv_lstm = ConvLSTM(input_dim=1, hidden_dim=[cnn_filter_size], kernel_size=(1,3), num_layers=1, batch_first=True,)\n",
    "# dropout = nn.Dropout2d(p=0.5)\n",
    "# attention1 = nn.MultiheadAttention(\n",
    "#             embed_dim=cnn_filter_size * SENSOR_NUM * EACH_SENSOR_CHANNEL,\n",
    "#             num_heads=1,\n",
    "#             batch_first=True\n",
    "#         )\n",
    "# linear1 = nn.Linear(in_features=sequence_length * cnn_filter_size * SENSOR_NUM* EACH_SENSOR_CHANNEL, out_features=hidden_size)\n",
    "# relu = nn.ReLU()\n",
    "# linear2 = nn.Linear(in_features=hidden_size, out_features=output_size)\n",
    "# softmax = nn.Softmax()\n",
    "\n",
    "# out = torch.unsqueeze(x, dim=2)\n",
    "# h, _ = conv_lstm(out)\n",
    "# out = dropout(h[0])\n",
    "# out = out.view(out.shape[0], sequence_length, cnn_filter_size * SENSOR_NUM* EACH_SENSOR_CHANNEL)\n",
    "# out, _ = attention1(out, out, out)\n",
    "# out = out.reshape(-1, sequence_length * cnn_filter_size * SENSOR_NUM* EACH_SENSOR_CHANNEL)\n",
    "# out = linear1(out)\n",
    "# out = relu(out)\n",
    "# out = linear2(out)\n",
    "# out = softmax(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "390fef45-0469-4afd-9829-f22f6e9c0b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLSTMAttentionModel(pl.LightningModule):\n",
    "    def __init__(self, hidden_size=64, sequence_length=256, cnn_filter_size=64, output_size=10, **kwargs):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.example_input_array = torch.Tensor(10, sequence_length, SENSOR_NUM, EACH_SENSOR_CHANNEL)\n",
    "        \n",
    "        self.conv_lstm = ConvLSTM(input_dim=1, hidden_dim=[cnn_filter_size], kernel_size=(1,3), num_layers=1, batch_first=True,)\n",
    "        self.dropout = nn.Dropout2d(p=0.5)\n",
    "        self.attention1 = nn.MultiheadAttention(\n",
    "            embed_dim=cnn_filter_size * SENSOR_NUM * EACH_SENSOR_CHANNEL,\n",
    "            num_heads=1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.linear1 = nn.Linear(in_features=sequence_length * cnn_filter_size * SENSOR_NUM* EACH_SENSOR_CHANNEL, out_features=hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(in_features=hidden_size, out_features=output_size)\n",
    "        self.softmax = nn.Softmax()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = torch.unsqueeze(x, dim=2)\n",
    "        h, _ = self.conv_lstm(out)\n",
    "        out = self.dropout(h[0])\n",
    "        out = out.view(out.shape[0], self.hparams.sequence_length, self.hparams.cnn_filter_size * SENSOR_NUM* EACH_SENSOR_CHANNEL)\n",
    "        out, _ = self.attention1(out, out, out)\n",
    "        out = out.reshape(-1, self.hparams.sequence_length * self.hparams.cnn_filter_size * SENSOR_NUM* EACH_SENSOR_CHANNEL)\n",
    "        out = self.linear1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.softmax(out)\n",
    "        return out        \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(params=self.parameters(), lr=0.0005)\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        # 1. Forward pass\n",
    "        y_pred = self.forward(X)\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        \n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the test loop\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        y = y\n",
    "    \n",
    "        # 1. Forward pass\n",
    "        test_pred_logits = self.forward(X)\n",
    "\n",
    "        # Calculate and accumulate accuracy\n",
    "        test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "        test_acc = ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "        self.log(\"test_acc\", test_acc)\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # this is the validation loop\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        y = y\n",
    "        \n",
    "        y_pred = self.forward(X)\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        \n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        \n",
    "        test_pred_logits = self.forward(X)\n",
    "        test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "        \n",
    "        return test_pred_labels\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6a9ef2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  | Name                | Type                            | Params | In sizes                                            | Out sizes                                                  \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0 | conv_lstm           | ConvLSTM                        | 50.2 K | [10, 256, 1, 7, 6]                                  | [[[10, 256, 64, 7, 6]], [[[10, 64, 7, 6], [10, 64, 7, 6]]]]\n",
      "1 | conv_lstm.cell_list | ModuleList                      | 50.2 K | ?                                                   | ?                                                          \n",
      "2 | dropout             | Dropout2d                       | 0      | [10, 256, 64, 7, 6]                                 | [10, 256, 64, 7, 6]                                        \n",
      "3 | attention1          | MultiheadAttention              | 28.9 M | [[10, 256, 2688], [10, 256, 2688], [10, 256, 2688]] | [[10, 256, 2688], [10, 256, 256]]                          \n",
      "4 | attention1.out_proj | NonDynamicallyQuantizableLinear | 7.2 M  | ?                                                   | ?                                                          \n",
      "5 | linear1             | Linear                          | 44.0 M | [10, 688128]                                        | [10, 64]                                                   \n",
      "6 | relu                | ReLU                            | 0      | [10, 64]                                            | [10, 64]                                                   \n",
      "7 | linear2             | Linear                          | 650    | [10, 64]                                            | [10, 10]                                                   \n",
      "8 | softmax             | Softmax                         | 0      | [10, 10]                                            | [10, 10]                                                   \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "73.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "73.0 M    Total params\n",
      "292.013   Total estimated model params size (MB)\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.utilities.model_summary import ModelSummary\n",
    "model = ConvLSTMAttentionModel()\n",
    "model_summary = ModelSummary(model, max_depth=2)\n",
    "print(model_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af66ab22-cfe6-4062-a1b0-2102fad90c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user 0: tran\n",
    "# user 1: hachix\n",
    "# train_model_class = [CNNLSTMAttentionModel, CNNAttentionModel, LSTMAttentionModel, CNNModel, LSTMModel, CNNLSTMModel]\n",
    "# train_model_class = [ConvLSTMModel, ConvLSTMAttentionModel]\n",
    "train_model_class = [ConvLSTMModel]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c91c8883-6918-4a9d-a5a9-0ed54a6970d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for model ConvLSTMAttentionModel\n",
      "summary(model) ===========================================================================\n",
      "Layer (type:depth-idx)                             Param #\n",
      "===========================================================================\n",
      "ConvLSTMAttentionModel                             --\n",
      "├─ConvLSTM: 1-1                                    --\n",
      "│    └─ModuleList: 2-1                             --\n",
      "│    │    └─ConvLSTMCell: 3-1                      50,176\n",
      "├─Dropout2d: 1-2                                   --\n",
      "├─MultiheadAttention: 1-3                          21,684,096\n",
      "│    └─NonDynamicallyQuantizableLinear: 2-2        7,228,032\n",
      "├─Linear: 1-4                                      44,040,256\n",
      "├─ReLU: 1-5                                        --\n",
      "├─Linear: 1-6                                      650\n",
      "├─Softmax: 1-7                                     --\n",
      "===========================================================================\n",
      "Total params: 73,003,210\n",
      "Trainable params: 73,003,210\n",
      "Non-trainable params: 0\n",
      "===========================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type               | Params | In sizes                                            | Out sizes                                                  \n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0 | conv_lstm  | ConvLSTM           | 50.2 K | [10, 256, 1, 7, 6]                                  | [[[10, 256, 64, 7, 6]], [[[10, 64, 7, 6], [10, 64, 7, 6]]]]\n",
      "1 | dropout    | Dropout2d          | 0      | [10, 256, 64, 7, 6]                                 | [10, 256, 64, 7, 6]                                        \n",
      "2 | attention1 | MultiheadAttention | 28.9 M | [[10, 256, 2688], [10, 256, 2688], [10, 256, 2688]] | [[10, 256, 2688], [10, 256, 256]]                          \n",
      "3 | linear1    | Linear             | 44.0 M | [10, 688128]                                        | [10, 64]                                                   \n",
      "4 | relu       | ReLU               | 0      | [10, 64]                                            | [10, 64]                                                   \n",
      "5 | linear2    | Linear             | 650    | [10, 64]                                            | [10, 10]                                                   \n",
      "6 | softmax    | Softmax            | 0      | [10, 10]                                            | [10, 10]                                                   \n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "73.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "73.0 M    Total params\n",
      "292.013   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:01<00:00,  1.20s/it, train_loss=2.300, val_loss=2.300]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:01<00:00,  1.20s/it, train_loss=2.300, val_loss=2.300]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teardown\n",
      "Testing DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  4.02it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc                    0.0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "teardown\n"
     ]
    }
   ],
   "source": [
    "# only for test\n",
    "\n",
    "def test():\n",
    "    patience = 20\n",
    "    missing_sensor_numbers = 4 # no missing sensor\n",
    "    user = 2 # use user2 to test\n",
    "    batch_size_dict = {ConvLSTMAttentionModel:128, ConvLSTMModel:256}\n",
    "    for model_class in train_model_class:\n",
    "        data_module = DataModule(test_user=user, \n",
    "                                 missing_sensor_numbers=missing_sensor_numbers, \n",
    "                                 batch_size=batch_size_dict.get(model_class, 1024))\n",
    "        \n",
    "        model = model_class(input_size=42, output_size=10)\n",
    "        \n",
    "        model_name = model.__class__.__name__\n",
    "        print(\"Running for model\", model_name)\n",
    "        print(\"summary(model)\", summary(model))\n",
    "\n",
    "        tb_logger = TensorBoardLogger(f\"./loggers/{model_name}\")\n",
    "        \n",
    "        trainer = pl.Trainer(\n",
    "            logger=tb_logger,\n",
    "            callbacks=[EarlyStopping(monitor=\"val_loss\", patience=patience, mode=\"min\")],\n",
    "            fast_dev_run = True,\n",
    "            precision=\"16-mixed\"\n",
    "        )\n",
    "        trainer.fit(model, data_module)\n",
    "        trainer.test(model, data_module)\n",
    "if TEST:\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e3b7fc04-f150-4f23-a0db-d2ef89609792",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type               | Params | In sizes                                         | Out sizes                                                      \n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0 | conv_lstm  | ConvLSTM           | 246 K  | [1024, 1, 256, 7, 6]                             | [[[1024, 1, 64, 7, 6]], [[[1024, 64, 7, 6], [1024, 64, 7, 6]]]]\n",
      "1 | dropout    | Dropout2d          | 0      | [1024, 1, 64, 7, 6]                              | [1024, 1, 64, 7, 6]                                            \n",
      "2 | attention1 | MultiheadAttention | 7.2 K  | [[1024, 64, 42], [1024, 64, 42], [1024, 64, 42]] | [[1024, 64, 42], [1024, 64, 64]]                               \n",
      "3 | linear1    | Linear             | 172 K  | [1024, 2688]                                     | [1024, 64]                                                     \n",
      "4 | relu       | ReLU               | 0      | [1024, 64]                                       | [1024, 64]                                                     \n",
      "5 | linear2    | Linear             | 650    | [1024, 64]                                       | [1024, 10]                                                     \n",
      "6 | softmax    | Softmax            | 0      | [1024, 10]                                       | [1024, 10]                                                     \n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "425 K     Trainable params\n",
      "0         Non-trainable params\n",
      "425 K     Total params\n",
      "1.704     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for model ConvLSTMAttentionModel\n",
      "loaded ConvLSTMAttentionModel 6 0\n",
      "\n",
      "*************training on User0*************\n",
      "Epoch 2:  63%|██████▎   | 398/632 [00:08<00:04, 48.89it/s, v_num=10, train_loss=2.150]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 27/27 [00:00<00:00, 67.34it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.30443739891052246\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "teardown\n"
     ]
    }
   ],
   "source": [
    "# patience = 100\n",
    "# missing_sensor_numbers = 0\n",
    "# all_test_pred = {}\n",
    "batch_size_dict = {ConvLSTMAttentionModel:128, ConvLSTMModel:256}\n",
    "for model_class in train_model_class: \n",
    "    \n",
    "    model = model_class(output_size=10)\n",
    "    model_name = model.__class__.__name__\n",
    "    print(\"Running for model\", model_name)\n",
    "    \n",
    "    for missing_sensor_numbers in [0]: ## Changed for 1 missing sensor\n",
    "        for user in [0]: ## Changed for user 2 only\n",
    "\n",
    "            # Load from exist previous training cpkt for continuous learning & testing\n",
    "            # previous_checkpoint_file = os.path.join(PREV_CHECKPOINT_FOLDER_PATH, f\"{model_name}_{missing_sensor_numbers}missing_user{user}.ckpt\")\n",
    "            previous_checkpoint_file = \"/home/tran/acttivity_recognition/data/compgan_dataset/results/logger90_0missing/ConvLSTMModel/user0/version_3/checkpoints/last-epoch=199-val_loss=1.54-val_acc=0.00.ckpt\"\n",
    "            \n",
    "            if os.path.isfile(previous_checkpoint_file):\n",
    "                model = model_class.load_from_checkpoint(previous_checkpoint_file)\n",
    "                print(\"loaded\", model_name, missing_sensor_numbers, user)\n",
    "                \n",
    "            start_timer = time.perf_counter()\n",
    "            print(f\"\\n*************training on User{user}*************\")\n",
    "            \n",
    "            data_module = DataModule(test_user=user, \n",
    "                                     missing_sensor_numbers=missing_sensor_numbers,\n",
    "                                     batch_size=batch_size_dict.get(model_class, 2048))\n",
    "\n",
    "            save_dir = os.path.join(RESULT_FOLDER_PATH, f\"./logger90_{missing_sensor_numbers}missing/{model_name}\")\n",
    "            save_dir_name = f\"user{user}\"\n",
    "            \n",
    "            tb_logger = TensorBoardLogger(save_dir=save_dir, name=save_dir_name)\n",
    "           \n",
    "            model_checkpoint = ModelCheckpoint(\n",
    "                save_top_k=1,  # get the 1 minimum val loss checkpoint\n",
    "                monitor=\"val_loss\",\n",
    "                mode=\"min\",\n",
    "                filename=\"val_loss_min-{epoch:02d}-{val_loss:.2f}-{val_acc:.2f}\"\n",
    "            )\n",
    "            \n",
    "            model_checkpoint_save_last = ModelCheckpoint(\n",
    "                save_top_k=1,  # get the 1 minimum val loss checkpoint\n",
    "                filename=\"last-{epoch:02d}-{val_loss:.2f}-{val_acc:.2f}\"\n",
    "            )\n",
    "            \n",
    "            trainer = pl.Trainer(\n",
    "                logger=tb_logger,\n",
    "                callbacks=[\n",
    "                    # EarlyStopping(monitor=\"val_loss\", patience=patience, mode=\"min\"),\n",
    "                    LearningRateMonitor(\"epoch\"),\n",
    "                    model_checkpoint,\n",
    "                    model_checkpoint_save_last\n",
    "                ],\n",
    "                precision=\"16-mixed\",\n",
    "                accumulate_grad_batches=1,\n",
    "                log_every_n_steps=10,\n",
    "                check_val_every_n_epoch=5,\n",
    "                max_epochs=500,\n",
    "            )\n",
    "        \n",
    "            trainer.fit(model, data_module)\n",
    "            trainer.test(model, data_module)\n",
    "    \n",
    "            end_timer = time.perf_counter()\n",
    "            exec_time = end_timer - start_timer\n",
    "\n",
    "            trainer_test_dict = trainer.logged_metrics\n",
    "            for key in trainer_test_dict.keys():\n",
    "                trainer_test_dict[key] = trainer_test_dict[key].item()\n",
    "            trainer_test_dict[\"exec_time\"] = int(exec_time)\n",
    "            \n",
    "            with open(os.path.join(trainer.log_dir, f\"result.json\"), \"w\") as f:\n",
    "                json.dump(trainer_test_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7967b65-3625-4474-a8c6-4ddd429adb2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0efc2082-9a3c-45ce-8967-8e3b09e394e0",
   "metadata": {},
   "source": [
    "## Predict full length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc37caa7-a743-462e-b48b-f5321634078b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Update after 2023/11/11 houkoku\n",
    "# class CustomTestDataset(Dataset):\n",
    "#     def __init__(self, feature_data, label_data, missing_sensor_numbers=0):\n",
    "        \n",
    "#         self.features = feature_data\n",
    "#         self.label = label_data\n",
    "#         assert len(self.features) == len(self.label), \"features len is not equal to label len\"\n",
    "#         self.missing_sensor_numbers = missing_sensor_numbers\n",
    "\n",
    "#         self.missing_index_list = []\n",
    "        \n",
    "#         for missing_index in combinations(range(SENSOR_NUM), missing_sensor_numbers):\n",
    "#             self.missing_index_list.append(missing_index)\n",
    "\n",
    "#     def transform(self, one_feature, missing_sensor_id_list):\n",
    "#         # Make one sensor data become 0\n",
    "#         one_feature_cp = one_feature.copy()\n",
    "        \n",
    "#         for missing_sensor_id in missing_sensor_id_list:\n",
    "#             one_feature_cp[:, missing_sensor_id*6:(missing_sensor_id+1)*6] = 0\n",
    "#         return one_feature_cp\n",
    "        \n",
    "#     def __len__(self):\n",
    "\n",
    "#         # take all available missing pattern * data number\n",
    "#         return len(self.features) * len(self.missing_index_list)\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         # take all available missing pattern\n",
    "#         missing_sensor_id_list = self.missing_index_list[ idx // len(self.features) ]\n",
    "#         x = self.transform(self.features[ idx % len(self.features) ], missing_sensor_id_list)\n",
    "#         label = self.label[idx % len(self.features)]\n",
    "#         return x, int(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b08fce61-6fe2-4a0f-9a59-91d300c1b73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DataModule(pl.LightningDataModule):\n",
    "#     STANDARDIZE = False\n",
    "    \n",
    "#     def __init__(self, test_user, missing_sensor_numbers, batch_size=2048):\n",
    "#         super().__init__()\n",
    "#         self.test_user = test_user\n",
    "#         self.missing_sensor_numbers = missing_sensor_numbers\n",
    "#         self.batch_size = batch_size\n",
    "#         self.scaler = None\n",
    "\n",
    "#     def load_data(self, mode):\n",
    "#         if mode == \"train\":\n",
    "#             folder_path = TRAIN_FOLDER_PATH\n",
    "#             data_file_name = train_data_file_name_\n",
    "#             label_file_name = train_label_file_name_\n",
    "\n",
    "#             train_data_file_name = data_file_name.format(self.test_user)\n",
    "#             train_label_file_name = label_file_name.format(self.test_user)\n",
    "    \n",
    "#             train_data_file_path = os.path.join(folder_path, train_data_file_name)\n",
    "#             train_label_file_path = os.path.join(folder_path, train_label_file_name)\n",
    "#             train_val_data, train_val_label = np.load(train_data_file_path), np.load(train_label_file_path)\n",
    "#             l, s, d, w = train_val_data.shape\n",
    "#             self.scaler = StandardScaler()\n",
    "#             # train_val_data = self.scaler.fit_transform(train_val_data.reshape(l, -1)).reshape(l, s, d, w)\n",
    "#             train_val_data = train_val_data.reshape(l, s ,d, w).transpose(0, 3, 1, 2)\n",
    "            \n",
    "#         elif mode == \"test\":\n",
    "#             folder_path = TEST_FOLDER_PATH\n",
    "#             data_file_name = test_data_file_name_\n",
    "#             label_file_name = test_label_file_name_\n",
    "    \n",
    "#             train_data_file_name = data_file_name.format(self.test_user)\n",
    "#             train_label_file_name = label_file_name.format(self.test_user)\n",
    "    \n",
    "#             train_data_file_path = os.path.join(folder_path, train_data_file_name)\n",
    "#             train_label_file_path = os.path.join(folder_path, train_label_file_name)\n",
    "#             train_val_data, train_val_label = np.load(train_data_file_path), np.load(train_label_file_path)\n",
    "#             l, s, d, w = train_val_data.shape\n",
    "#             # train_val_data = self.scaler.transform(train_val_data.reshape(l, -1)).reshape(l, s, d, w)\n",
    "#             train_val_data = train_val_data.reshape(l, s ,d, w).transpose(0, 3, 1, 2)\n",
    "    \n",
    "#         return train_val_data, train_val_label\n",
    "\n",
    "#     def setup(self, stage: str):\n",
    "#         # Assign Train/val split(s) for use in Dataloaders\n",
    "        \n",
    "#         if stage == \"validate\" or stage == \"fit\":\n",
    "#             train_val_data, train_val_label = self.load_data(\"train\")\n",
    "#             self.train_data, self.val_data, self.train_label, self.val_label = train_test_split(\n",
    "#                 train_val_data, train_val_label, test_size=0.2, train_size=0.8, random_state=42, shuffle=True)\n",
    "\n",
    "#             self.train_dataset = CustomTrainDataset(\n",
    "#                 CustomTrainDataset.TRAIN_MODE, self.train_data, self.train_label, missing_sensor_numbers=self.missing_sensor_numbers)\n",
    "#             self.val_dataset = CustomTrainDataset(\n",
    "#                 CustomTrainDataset.TEST_MODE, self.val_data, self.val_label, missing_sensor_numbers=self.missing_sensor_numbers)\n",
    "\n",
    "#         elif stage == \"test\" or stage == \"predict\":\n",
    "#             train_val_data, train_val_label = self.load_data(\"test\")\n",
    "#             self.test_data = train_val_data\n",
    "#             self.test_label = train_val_label\n",
    "\n",
    "#             self.test_dataset = CustomTrainDataset(\n",
    "#                 CustomTrainDataset.TEST_MODE, self.test_data, self.test_label, missing_sensor_numbers=self.missing_sensor_numbers)\n",
    "    \n",
    "#     def train_dataloader(self):\n",
    "#         return DataLoader(self.train_dataset, batch_size=self.batch_size, num_workers=4, shuffle=True, pin_memory=True)\n",
    "    \n",
    "#     def val_dataloader(self):\n",
    "#         return DataLoader(self.val_dataset, batch_size=self.batch_size,  num_workers=4, shuffle=False, pin_memory=True)\n",
    "    \n",
    "#     def test_dataloader(self):\n",
    "#         return DataLoader(self.test_dataset, batch_size=self.batch_size,  num_workers=4, shuffle=False, pin_memory=True)\n",
    "\n",
    "#     def predict_dataloader(self):\n",
    "#         return DataLoader(self.test_dataset, batch_size=self.batch_size,  num_workers=4, shuffle=False, pin_memory=True)\n",
    "\n",
    "#     def teardown(self, stage):\n",
    "#         print(\"teardown\")\n",
    "#         if stage == \"validate\" or stage == \"fit\":\n",
    "#             del self.train_data, self.train_label\n",
    "#             del self.val_data, self.val_label\n",
    "#             del self.train_dataset\n",
    "#             del self.val_dataset\n",
    "            \n",
    "#         elif stage == \"test\" or stage == \"predict\":\n",
    "#             del self.test_data, self.test_label\n",
    "#             del self.test_dataset\n",
    "#         gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2228f034-f56b-42e4-9892-8c2bdfe4ebf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Missing logger folder: ../data/compgan_dataset/results/./logger90_6missing/ConvLSTMAttentionModel/user0/version_7/result_test/lightning_logs\n",
      "2023-12-14 17:24:41.243362: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-14 17:24:41.276700: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-14 17:24:41.859996: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name ConvLSTMAttentionModel\n",
      "accuracy 0.5233644859813084\n",
      "Predicting DataLoader 0: 100%|██████████| 4/4 [00:00<00:00, 95.50it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name ConvLSTMAttentionModel\n",
      "accuracy 0.4953271028037383\n",
      "Predicting DataLoader 0: 100%|██████████| 13/13 [00:00<00:00, 116.63it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name ConvLSTMAttentionModel\n",
      "accuracy 0.4666451820818563\n",
      "Predicting DataLoader 0: 100%|██████████| 27/27 [00:00<00:00, 116.74it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name ConvLSTMAttentionModel\n",
      "accuracy 0.4392523364485981\n",
      "Predicting DataLoader 0: 100%|██████████| 42/42 [00:00<00:00, 106.76it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name ConvLSTMAttentionModel\n",
      "accuracy 0.41612385537619184\n",
      "Predicting DataLoader 0: 100%|██████████| 51/51 [00:00<00:00, 124.88it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name ConvLSTMAttentionModel\n",
      "accuracy 0.40062305295950157\n",
      "Predicting DataLoader 0: 100%|██████████| 54/54 [00:00<00:00, 119.62it/s]\n",
      "model_name ConvLSTMAttentionModel\n",
      "accuracy 0.393847965266024\n"
     ]
    }
   ],
   "source": [
    "# all_test_pred = {}\n",
    "\n",
    "# for missing_sensor_numbers in range(7): ## Changed for 1 missing sensor\n",
    "#     all_test_pred[missing_sensor_numbers] = {}\n",
    "    \n",
    "#     for model_class in train_model_class: \n",
    "#         all_user_y_true = []\n",
    "#         all_user_y_pred = []\n",
    "        \n",
    "#         for user in range(1): ## Changed for user 2 only\n",
    "#             model_name = model_class.__name__\n",
    "#             checkpoint_path = os.path.join(RESULT_FOLDER_PATH, f\"./logger90_6missing/{model_name}\", f\"user{user}\", \"version_10\", \"checkpoints\", \"last*.ckpt\")\n",
    "#             checkpoint_glob = glob.glob(checkpoint_path)\n",
    "#             assert len(checkpoint_glob) == 1, checkpoint_path\n",
    "#             checkpoint_file = checkpoint_glob[0]\n",
    "\n",
    "#             assert os.path.exists(checkpoint_file), checkpoint_file\n",
    "#             model = model_class.load_from_checkpoint(checkpoint_file)\n",
    "\n",
    "#             data_module = DataModule(test_user=user, missing_sensor_numbers=missing_sensor_numbers, batch_size=512)\n",
    "#             data_module.setup(\"test\")\n",
    "#             test_loader = data_module.test_dataloader()\n",
    "            \n",
    "#             tb_logger = TensorBoardLogger(os.path.join(RESULT_FOLDER_PATH, f\"./logger90_6missing/{model_name}\", f\"user{user}\", \"version_10\", f\"result_test\"))\n",
    "#             trainer = pl.Trainer(logger=tb_logger)\n",
    "\n",
    "#             pred = trainer.predict(model, test_loader)\n",
    "\n",
    "#             y_true_list = []\n",
    "#             for batch_idx, test_data in enumerate(test_loader):\n",
    "#                 _, y_true = test_data\n",
    "#                 y_true_list.append(y_true)\n",
    "\n",
    "#             all_user_y_true.append(torch.cat(y_true_list))\n",
    "#             all_user_y_pred.append(torch.cat(pred))\n",
    "        \n",
    "#         print(\"model_name\", model_name)\n",
    "#         all_test_cpu = list(map(lambda x: x.cpu().item(), torch.cat(all_user_y_true)))\n",
    "#         all_pred_cpu = list(map(lambda x: x.cpu().item(), torch.cat(all_user_y_pred)))\n",
    "        \n",
    "#         all_test_pred[missing_sensor_numbers][model_name] = (all_test_cpu, all_pred_cpu)\n",
    "        \n",
    "#         print(\"accuracy\", accuracy_score(all_test_cpu, all_pred_cpu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5a19ccb-eccd-4f8b-84e9-9ae354bfe086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ConvLSTMAttentionModel\n",
      "missing_0                0.278775\n",
      "missing_1                0.257344\n",
      "missing_2                0.236514\n",
      "missing_3                0.217152\n",
      "missing_4                0.201297\n",
      "missing_5                0.190957\n",
      "missing_6                0.186530\n"
     ]
    }
   ],
   "source": [
    "# df = pd.DataFrame(index=[f\"missing_{x}\" for x in range(SENSOR_NUM)])\n",
    "\n",
    "# for model_class in train_model_class: \n",
    "#     acc_list = []\n",
    "#     for missing_sensor_numbers in range(7): ## Changed for 1 missing sensor\n",
    "#         for user in range(1):\n",
    "#             all_test_cpu, all_pred_cpu = all_test_pred[missing_sensor_numbers][model_class.__name__]\n",
    "#             acc = f1_score(all_test_cpu, all_pred_cpu, average=\"macro\")\n",
    "#             acc_list.append(acc)\n",
    "            \n",
    "#     df[model_class.__name__] = acc_list\n",
    "# print(df)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91f577f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f3f15c77c882d8433ef1043b53db379ca3772938d44c39305f8b807ce25a312a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

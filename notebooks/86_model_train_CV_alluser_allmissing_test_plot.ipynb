{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4ce6502-93ec-4660-8864-7ff3019c6084",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tran/miniconda3/envs/compgan/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchinfo import summary\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import tracemalloc \n",
    "\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "from itertools import combinations\n",
    "import gc\n",
    "import time\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afe087b5-0c7e-47da-8725-354729b83319",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c153c485-8474-4042-a29b-31ea8978c7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../data/compgan_dataset/train/train_data0.npy', '../data/compgan_dataset/train/train_data1.npy', '../data/compgan_dataset/train/train_data10.npy', '../data/compgan_dataset/train/train_data11.npy', '../data/compgan_dataset/train/train_data12.npy', '../data/compgan_dataset/train/train_data13.npy', '../data/compgan_dataset/train/train_data14.npy', '../data/compgan_dataset/train/train_data15.npy', '../data/compgan_dataset/train/train_data2.npy', '../data/compgan_dataset/train/train_data3.npy', '../data/compgan_dataset/train/train_data4.npy', '../data/compgan_dataset/train/train_data5.npy', '../data/compgan_dataset/train/train_data6.npy', '../data/compgan_dataset/train/train_data7.npy', '../data/compgan_dataset/train/train_data8.npy', '../data/compgan_dataset/train/train_data9.npy']\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "DATA_ROOT = \"../data/compgan_dataset/\"\n",
    "\n",
    "train_data_file_name_ = \"train_data{}.npy\"\n",
    "train_label_file_name_ = \"train_label{}.npy\"\n",
    "test_data_file_name_ = \"test_data{}.npy\"\n",
    "test_label_file_name_ = \"test_label{}.npy\"\n",
    "\n",
    "TRAIN_FOLDER_PATH = os.path.join(DATA_ROOT, \"train\")\n",
    "TEST_FOLDER_PATH = os.path.join(DATA_ROOT, \"test\")\n",
    "RESULT_FOLDER_PATH = os.path.join(DATA_ROOT, \"results\")\n",
    "PREV_CHECKPOINT_FOLDER_PATH = os.path.join(DATA_ROOT, \"prev_checkpoint\")\n",
    "\n",
    "assert os.path.isdir(TRAIN_FOLDER_PATH) and os.path.isdir(TEST_FOLDER_PATH)\n",
    "os.makedirs(RESULT_FOLDER_PATH, exist_ok=True)\n",
    "\n",
    "data_files = sorted(glob.glob(os.path.join(TRAIN_FOLDER_PATH, train_data_file_name_.format(\"*\"))))\n",
    "print(data_files)\n",
    "print(len(data_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "878427cd-91fa-4b99-94c8-399378c81dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_NUM = 16\n",
    "SENSOR_NUM = 7\n",
    "EACH_SENSOR_CHANNEL = 6\n",
    "assert USER_NUM == len(data_files)\n",
    "feature_num = SENSOR_NUM * EACH_SENSOR_CHANNEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee7a344b-73b9-4310-a650-c06bea9f68da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# important\n",
    "\n",
    "label_list = ['歩行(平地)',\n",
    " '歩行(階段)',\n",
    " 'ベッド上での起き上がり',\n",
    " 'ベッド椅子間の乗り移り(立つ)',\n",
    " 'ベッド椅子間の乗り移り(立たない)',\n",
    " '立ち座り',\n",
    " '座位保持・座位バランス',\n",
    " '立位保持・立位バランス',\n",
    " '関節可動域増大訓練(肩)',\n",
    " '関節可動域増大訓練(股関節)']\n",
    "\n",
    "label_dict = dict(enumerate(label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45f45c18-d2c9-46e9-89bf-75b68dbd12da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# important\n",
    "eng_label_dict = dict(zip(\n",
    "    label_list,\n",
    "    ['Walking', 'Upstair', 'Bed_Standup', 'Change_Bed', 'Change_Bed_Standup', 'Sit_Down', 'Sit', 'Stand', 'Shoulder_Exercise', 'Hip_Exercise']\n",
    "))\n",
    "\n",
    "eng_label_list = [eng_label_dict[i] for i in label_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02513f37-d192-4fae-a376-af38807bf29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update after 2023/11/11 houkoku\n",
    "class CustomTrainDataset(Dataset):\n",
    "    TRAIN_MODE = \"train\"\n",
    "    TEST_MODE = \"test\"\n",
    "    \n",
    "    def __init__(self, mode, feature_data, label_data, missing_sensor_numbers=0):\n",
    "        self.mode = mode\n",
    "        assert mode in [self.TRAIN_MODE, self.TEST_MODE]\n",
    "        \n",
    "        self.features = feature_data\n",
    "        self.label = label_data\n",
    "        assert len(self.features) == len(self.label), \"features len is not equal to label len\"\n",
    "        self.missing_sensor_numbers = missing_sensor_numbers\n",
    "\n",
    "        self.missing_index_list = []\n",
    "        for missing_count in range(missing_sensor_numbers + 1):\n",
    "            for missing_index in combinations(range(SENSOR_NUM), missing_count):\n",
    "                self.missing_index_list.append(missing_index)\n",
    "\n",
    "    def transform(self, one_feature, missing_sensor_id_list):\n",
    "        # Make one sensor data become 0\n",
    "        one_feature_cp = one_feature.copy()\n",
    "        \n",
    "        for missing_sensor_id in missing_sensor_id_list:\n",
    "            one_feature_cp[:, missing_sensor_id*6:(missing_sensor_id+1)*6] = 0\n",
    "        return one_feature_cp\n",
    "        \n",
    "    def __len__(self):\n",
    "\n",
    "        # take all available missing pattern * data number\n",
    "        return len(self.features) * len(self.missing_index_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # take all available missing pattern\n",
    "        missing_sensor_id_list = self.missing_index_list[ idx // len(self.features) ]\n",
    "        x = self.transform(self.features[ idx % len(self.features) ], missing_sensor_id_list)\n",
    "        label = self.label[idx % len(self.features)]\n",
    "        return x, int(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3225bf4a-954e-44ed-aee0-95672ed5fe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule(pl.LightningDataModule):\n",
    "    STANDARDIZE = False\n",
    "    \n",
    "    def __init__(self, test_user, missing_sensor_numbers, batch_size=2048):\n",
    "        super().__init__()\n",
    "        self.test_user = test_user\n",
    "        self.missing_sensor_numbers = missing_sensor_numbers\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def load_data(self, mode):\n",
    "        if mode == \"train\":\n",
    "            folder_path = TRAIN_FOLDER_PATH\n",
    "            data_file_name = train_data_file_name_\n",
    "            label_file_name = train_label_file_name_\n",
    "\n",
    "            train_data_file_name = data_file_name.format(self.test_user)\n",
    "            train_label_file_name = label_file_name.format(self.test_user)\n",
    "    \n",
    "            train_data_file_path = os.path.join(folder_path, train_data_file_name)\n",
    "            train_label_file_path = os.path.join(folder_path, train_label_file_name)\n",
    "            train_val_data, train_val_label = np.load(train_data_file_path), np.load(train_label_file_path)\n",
    "            l, s, d, w = train_val_data.shape\n",
    "            train_val_data = train_val_data.reshape(l, s * d, w).transpose(0,2,1)\n",
    "            \n",
    "        elif mode == \"test\":\n",
    "            folder_path = TEST_FOLDER_PATH\n",
    "            data_file_name = test_data_file_name_\n",
    "            label_file_name = test_label_file_name_\n",
    "    \n",
    "            train_data_file_name = data_file_name.format(self.test_user)\n",
    "            train_label_file_name = label_file_name.format(self.test_user)\n",
    "    \n",
    "            train_data_file_path = os.path.join(folder_path, train_data_file_name)\n",
    "            train_label_file_path = os.path.join(folder_path, train_label_file_name)\n",
    "            train_val_data, train_val_label = np.load(train_data_file_path), np.load(train_label_file_path)\n",
    "            l, s, d, w = train_val_data.shape\n",
    "            train_val_data = train_val_data.reshape(l, s * d, w).transpose(0,2,1)\n",
    "    \n",
    "        return train_val_data, train_val_label\n",
    "\n",
    "    def setup(self, stage: str):\n",
    "        # Assign Train/val split(s) for use in Dataloaders\n",
    "        \n",
    "        if stage == \"validate\" or stage == \"fit\":\n",
    "            self.train_data, self.train_label = self.load_data(\"train\")\n",
    "            self.train_dataset = CustomTrainDataset(\n",
    "                CustomTrainDataset.TRAIN_MODE, self.train_data, self.train_label, missing_sensor_numbers=self.missing_sensor_numbers)\n",
    "            \n",
    "            self.val_data, self.val_label = self.load_data(\"test\")\n",
    "            self.val_dataset = CustomTrainDataset(\n",
    "                CustomTrainDataset.TEST_MODE, self.val_data, self.val_label, missing_sensor_numbers=self.missing_sensor_numbers)\n",
    "\n",
    "        elif stage == \"test\" or stage == \"predict\":\n",
    "            self.test_data, self.test_label = self.load_data(\"test\")\n",
    "            self.test_dataset = CustomTrainDataset(\n",
    "                CustomTrainDataset.TEST_MODE, self.test_data, self.test_label, missing_sensor_numbers=self.missing_sensor_numbers)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, num_workers=4, shuffle=True, pin_memory=True)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size,  num_workers=4, shuffle=False, pin_memory=True)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size,  num_workers=4, shuffle=False, pin_memory=True)\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size,  num_workers=4, shuffle=False, pin_memory=True)\n",
    "\n",
    "    def teardown(self, stage):\n",
    "        print(\"teardown\")\n",
    "        if stage == \"validate\" or stage == \"fit\":\n",
    "            del self.train_data, self.train_label\n",
    "            del self.val_data, self.val_label\n",
    "            del self.train_dataset\n",
    "            del self.val_dataset\n",
    "            \n",
    "        elif stage == \"test\" or stage == \"predict\":\n",
    "            del self.test_data, self.test_label\n",
    "            del self.test_dataset\n",
    "        gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a89352ec-f6dc-45a1-80d5-f52a59d38953",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TEST:\n",
    "    data_module = DataModule(test_user=0, missing_sensor_numbers=1)\n",
    "    data_module.setup(\"fit\")\n",
    "    print(data_module.train_data.shape)\n",
    "    print(data_module.val_data.shape)\n",
    "    # print(data_module.test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fded757e-a29f-47ad-addf-a8989028ec80",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TEST:\n",
    "    data = data_module.val_dataset[1273 * 2 + 1]\n",
    "    print(data[1], data[0][0])\n",
    "    print(len(data_module.val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e760566-e117-4fc6-b639-a2e2ec3c32da",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TEST:\n",
    "    del data_module, data\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdb0600-ebb2-4d73-94f2-d8e4729336bd",
   "metadata": {},
   "source": [
    "## MODEL DEFINITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c97b4ec5-f1bf-49ec-bc3d-266a58f4099d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LSTMModel(pl.LightningModule):\n",
    "    def __init__(self, hidden_size=128, input_size=42, output_size=10, **kwargs):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.example_input_array = torch.Tensor(1024, 256, input_size)\n",
    "        \n",
    "        self.rnn = nn.LSTM(input_size=input_size, \n",
    "                          hidden_size=hidden_size,\n",
    "                          num_layers=3,\n",
    "                          batch_first=True)\n",
    "        \n",
    "        self.seq_1 = nn.Sequential(\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.seq_2 = nn.Sequential(\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Linear(in_features=3 * hidden_size, out_features=output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        activation, _ = self.rnn(x)\n",
    "        \n",
    "        b, _, _ = activation.size()\n",
    "        lstm_output = activation[:,-1,:].view(b,-1)\n",
    "        seq_1_output = self.seq_1(lstm_output)\n",
    "        seq_2_output = self.seq_2(lstm_output)\n",
    "        \n",
    "        output = torch.concat([lstm_output, seq_1_output, seq_2_output], dim=1)\n",
    "        output = self.classifier(output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(params=self.parameters(), lr=0.0005)\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        # 1. Forward pass\n",
    "        y_pred = self.forward(X)\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        \n",
    "        self.log(\"train_loss\", loss)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the test loop\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "    \n",
    "        # 1. Forward pass\n",
    "        test_pred_logits = self.forward(X)\n",
    "\n",
    "        # Calculate and accumulate accuracy\n",
    "        test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "        test_acc = ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "        self.log(\"test_acc\", test_acc)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # this is the validation loop\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        \n",
    "        y_pred = self.forward(X)\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        \n",
    "        self.log(\"val_loss\", loss)\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        \n",
    "        test_pred_logits = self.forward(X)\n",
    "        test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "        \n",
    "        return test_pred_labels\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0f1c7eb-386b-4f8a-96fa-30afd4245ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMBiModel(pl.LightningModule):\n",
    "    def __init__(self, hidden_size=128, input_size=42, output_size=10, **kwargs):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.example_input_array = torch.Tensor(1024, 256, input_size)\n",
    "        \n",
    "        self.rnn = nn.LSTM(input_size=input_size, \n",
    "                          hidden_size=hidden_size,\n",
    "                          num_layers=3,\n",
    "                          batch_first=True,\n",
    "                          bidirectional=True)\n",
    "\n",
    "        double_hidden_size = hidden_size * 2\n",
    "        \n",
    "        self.seq_1 = nn.Sequential(\n",
    "            nn.Linear(in_features=double_hidden_size, out_features=double_hidden_size),\n",
    "            nn.BatchNorm1d(num_features=double_hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=double_hidden_size, out_features=double_hidden_size),\n",
    "            nn.BatchNorm1d(num_features=double_hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.seq_2 = nn.Sequential(\n",
    "            nn.Linear(in_features=double_hidden_size, out_features=double_hidden_size),\n",
    "            nn.BatchNorm1d(num_features=double_hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=double_hidden_size, out_features=double_hidden_size),\n",
    "            nn.BatchNorm1d(num_features=double_hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Linear(in_features=3 * double_hidden_size, out_features=output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        activation, (h, _) = self.rnn(x)\n",
    "        b, _, _ = activation.size()\n",
    "        \n",
    "        lstm_output = h[-2:].permute(1,0,2).reshape(b, -1)\n",
    "        seq_1_output = self.seq_1(lstm_output)\n",
    "        seq_2_output = self.seq_2(lstm_output)\n",
    "        \n",
    "        output = torch.concat([lstm_output, seq_1_output, seq_2_output], dim=1)\n",
    "        output = self.classifier(output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(params=self.parameters(), lr=0.0005)\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        # 1. Forward pass\n",
    "        y_pred = self.forward(X)\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        \n",
    "        self.log(\"train_loss\", loss)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the test loop\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "    \n",
    "        # 1. Forward pass\n",
    "        test_pred_logits = self.forward(X)\n",
    "\n",
    "        # Calculate and accumulate accuracy\n",
    "        test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "        test_acc = ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "        self.log(\"test_acc\", test_acc)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # this is the validation loop\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        \n",
    "        y_pred = self.forward(X)\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        \n",
    "        self.log(\"val_loss\", loss)\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        \n",
    "        test_pred_logits = self.forward(X)\n",
    "        test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "        \n",
    "        return test_pred_labels\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05745f4a-c9d2-44ff-9cc7-ba34e61937e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMAttentionModel(pl.LightningModule):\n",
    "    def __init__(self, hidden_size=128, input_size=42, output_size=10, **kwargs):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.example_input_array = torch.Tensor(1024, 256, input_size)\n",
    "        \n",
    "        self.rnn1 = nn.LSTM(input_size=input_size, \n",
    "                          hidden_size=hidden_size,\n",
    "                          num_layers=1,\n",
    "                          batch_first=True)\n",
    "        \n",
    "        self.attention1 = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_size,\n",
    "            num_heads=8,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.rnn2 = nn.LSTM(input_size=hidden_size, \n",
    "                          hidden_size=hidden_size,\n",
    "                          num_layers=1,\n",
    "                          batch_first=True)\n",
    "        \n",
    "        self.attention2 = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_size,\n",
    "            num_heads=8,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.rnn3 = nn.LSTM(input_size=hidden_size, \n",
    "                  hidden_size=hidden_size,\n",
    "                  num_layers=1,\n",
    "                  batch_first=True)\n",
    "        \n",
    "        self.seq_1 = nn.Sequential(\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.seq_2 = nn.Sequential(\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Linear(in_features=3 * hidden_size, out_features=output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        activation, _ = self.rnn1(x)\n",
    "        activation, _ = self.attention1(activation, activation, activation)\n",
    "        activation, _ = self.rnn2(activation)\n",
    "        activation, _ = self.attention2(activation, activation, activation)\n",
    "        activation, (h, _) = self.rnn3(activation)\n",
    "\n",
    "        b, _, _ = activation.size()\n",
    "        \n",
    "        lstm_output = activation[:,-1,:].view(b,-1)\n",
    "        \n",
    "        seq_1_output = self.seq_1(lstm_output)\n",
    "        seq_2_output = self.seq_2(lstm_output)\n",
    "        \n",
    "        output = torch.concat([lstm_output, seq_1_output, seq_2_output], dim=1)\n",
    "        output = self.classifier(output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(params=self.parameters(), lr=0.0005)\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        # 1. Forward pass\n",
    "        y_pred = self.forward(X)\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        \n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the test loop\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        y = y\n",
    "    \n",
    "        # 1. Forward pass\n",
    "        test_pred_logits = self.forward(X)\n",
    "\n",
    "        # Calculate and accumulate accuracy\n",
    "        test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "        test_acc = ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "        self.log(\"test_acc\", test_acc)\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # this is the validation loop\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        y = y\n",
    "        \n",
    "        y_pred = self.forward(X)\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        \n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        \n",
    "        test_pred_logits = self.forward(X)\n",
    "        test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "        \n",
    "        return test_pred_labels\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fd7f246-f58c-4a18-8195-bead57c332ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CNNLSTMModel(pl.LightningModule):\n",
    "    def __init__(self, hidden_size=128, sequence_length=256, input_size=42, cnn_filter_size=64, output_size=10, **kwargs):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.example_input_array = torch.Tensor(1024, sequence_length, input_size)\n",
    "        \n",
    "        self.cnn = nn.Conv1d(sequence_length, cnn_filter_size, kernel_size=5, padding=\"same\")\n",
    "        \n",
    "        self.rnn = nn.LSTM(input_size=input_size, \n",
    "                          hidden_size=hidden_size,\n",
    "                          num_layers=3,\n",
    "                          batch_first=True)\n",
    " \n",
    "        self.seq_1 = nn.Sequential(\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.seq_2 = nn.Sequential(\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Linear(in_features=3 * hidden_size, out_features=output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.cnn(x)\n",
    "        activation, _ = self.rnn(output)\n",
    "        \n",
    "        b, _, _ = activation.size()\n",
    "        lstm_output = activation[:,-1,:].view(b,-1)\n",
    "        seq_1_output = self.seq_1(lstm_output)\n",
    "        seq_2_output = self.seq_2(lstm_output)\n",
    "        \n",
    "        output = torch.concat([lstm_output, seq_1_output, seq_2_output], dim=1)\n",
    "        output = self.classifier(output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(params=self.parameters(), lr=0.0005)\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        # 1. Forward pass\n",
    "        y_pred = self.forward(X)\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        \n",
    "        self.log(\"train_loss\", loss)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the test loop\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "    \n",
    "        # 1. Forward pass\n",
    "        test_pred_logits = self.forward(X)\n",
    "\n",
    "        # Calculate and accumulate accuracy\n",
    "        test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "        test_acc = ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "        self.log(\"test_acc\", test_acc)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # this is the validation loop\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        \n",
    "        y_pred = self.forward(X)\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        \n",
    "        self.log(\"val_loss\", loss)\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        \n",
    "        test_pred_logits = self.forward(X)\n",
    "        test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "        \n",
    "        return test_pred_labels\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "390fef45-0469-4afd-9829-f22f6e9c0b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNLSTMAttentionModel(pl.LightningModule):\n",
    "    def __init__(self, hidden_size=128, sequence_length=256, input_size=42, cnn_filter_size=64, output_size=10, **kwargs):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.example_input_array = torch.Tensor(1024, sequence_length, input_size)\n",
    "        \n",
    "        self.cnn = nn.Conv1d(sequence_length, cnn_filter_size, kernel_size=5, padding=\"same\")\n",
    "        \n",
    "        self.rnn1 = nn.LSTM(input_size=input_size, \n",
    "                          hidden_size=hidden_size,\n",
    "                          num_layers=1,\n",
    "                          batch_first=True)\n",
    "        \n",
    "        self.attention1 = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_size,\n",
    "            num_heads=8,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.rnn2 = nn.LSTM(input_size=hidden_size, \n",
    "                          hidden_size=hidden_size,\n",
    "                          num_layers=1,\n",
    "                          batch_first=True)\n",
    "        \n",
    "        self.attention2 = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_size,\n",
    "            num_heads=8,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.rnn3 = nn.LSTM(input_size=hidden_size, \n",
    "                  hidden_size=hidden_size,\n",
    "                  num_layers=1,\n",
    "                  batch_first=True)\n",
    "        \n",
    "        self.seq_1 = nn.Sequential(\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.seq_2 = nn.Sequential(\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Linear(in_features=3 * hidden_size, out_features=output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.cnn(x)\n",
    "        activation, _ = self.rnn1(output)\n",
    "        activation, _ = self.attention1(activation, activation, activation)\n",
    "        activation, _ = self.rnn2(activation)\n",
    "        activation, _ = self.attention2(activation, activation, activation)\n",
    "        activation, _ = self.rnn3(activation)\n",
    "\n",
    "        b, _, _ = activation.size()\n",
    "        \n",
    "        lstm_output = activation[:,-1,:].view(b,-1)\n",
    "        \n",
    "        seq_1_output = self.seq_1(lstm_output)\n",
    "        seq_2_output = self.seq_2(lstm_output)\n",
    "        \n",
    "        output = torch.concat([lstm_output, seq_1_output, seq_2_output], dim=1)\n",
    "        output = self.classifier(output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(params=self.parameters(), lr=0.0005)\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        # 1. Forward pass\n",
    "        y_pred = self.forward(X)\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        \n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the test loop\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        y = y\n",
    "    \n",
    "        # 1. Forward pass\n",
    "        test_pred_logits = self.forward(X)\n",
    "\n",
    "        # Calculate and accumulate accuracy\n",
    "        test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "        test_acc = ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "        self.log(\"test_acc\", test_acc)\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # this is the validation loop\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        y = y\n",
    "        \n",
    "        y_pred = self.forward(X)\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        \n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        \n",
    "        test_pred_logits = self.forward(X)\n",
    "        test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "        \n",
    "        return test_pred_labels\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb9983f1-04aa-411b-9e72-1909be472484",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(pl.LightningModule):\n",
    "    def __init__(self, hidden_size=128, sequence_length=256, input_size=42, cnn_filter_size=64, output_size=10, **kwargs):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.example_input_array = torch.Tensor(1024, sequence_length, input_size)\n",
    "\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Conv1d(sequence_length, cnn_filter_size, kernel_size=5, padding=\"same\"),\n",
    "            nn.BatchNorm1d(num_features=cnn_filter_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.cnn2 = nn.Sequential(\n",
    "            nn.Conv1d(cnn_filter_size, hidden_size, kernel_size=5, padding=\"same\"),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.gap = nn.AdaptiveAvgPool1d(1)\n",
    "        \n",
    "        self.seq_1 = nn.Sequential(\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.seq_2 = nn.Sequential(\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Linear(in_features=3 * hidden_size, out_features=output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.cnn1(x)\n",
    "        output = self.cnn2(output)\n",
    "        b, _, _ = output.shape\n",
    "        \n",
    "        output = self.gap(output).view(b, -1)\n",
    "\n",
    "        seq_1_output = self.seq_1(output)\n",
    "        seq_2_output = self.seq_2(output)\n",
    "        \n",
    "        output = torch.concat([output, seq_1_output, seq_2_output], dim=1)\n",
    "        output = self.classifier(output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(params=self.parameters(), lr=0.0005)\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        # 1. Forward pass\n",
    "        y_pred = self.forward(X)\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        \n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the test loop\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        y = y\n",
    "    \n",
    "        # 1. Forward pass\n",
    "        test_pred_logits = self.forward(X)\n",
    "\n",
    "        # Calculate and accumulate accuracy\n",
    "        test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "        test_acc = ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "        self.log(\"test_acc\", test_acc)\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # this is the validation loop\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        y = y\n",
    "        \n",
    "        y_pred = self.forward(X)\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        \n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        \n",
    "        test_pred_logits = self.forward(X)\n",
    "        test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "        \n",
    "        return test_pred_labels\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fdddd1a1-495d-4e5b-95cd-1984aa934277",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNAttentionModel(pl.LightningModule):\n",
    "    def __init__(self, hidden_size=128, sequence_length=256, input_size=42, cnn_filter_size=64, output_size=10, **kwargs):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.example_input_array = torch.Tensor(1024, sequence_length, input_size)\n",
    "\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Conv1d(sequence_length, cnn_filter_size, kernel_size=5, padding=\"same\"),\n",
    "            nn.BatchNorm1d(num_features=cnn_filter_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.attention1 =  nn.MultiheadAttention(\n",
    "            embed_dim=input_size,\n",
    "            num_heads=6,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.cnn2 = nn.Sequential(\n",
    "            nn.Conv1d(cnn_filter_size, hidden_size, kernel_size=5, padding=\"same\"),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.attention2 =  nn.MultiheadAttention(\n",
    "            embed_dim=input_size,\n",
    "            num_heads=6,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.gap = nn.AdaptiveAvgPool1d(1)\n",
    "        \n",
    "        self.seq_1 = nn.Sequential(\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.seq_2 = nn.Sequential(\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Linear(in_features=3 * hidden_size, out_features=output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.cnn1(x)\n",
    "        output, _ = self.attention1(output, output, output)\n",
    "        output = self.cnn2(output)\n",
    "        output, _ = self.attention2(output, output, output)\n",
    "        b, _, _ = output.shape\n",
    "        \n",
    "        output = self.gap(output).view(b, -1)\n",
    "\n",
    "        seq_1_output = self.seq_1(output)\n",
    "        seq_2_output = self.seq_2(output)\n",
    "        \n",
    "        output = torch.concat([output, seq_1_output, seq_2_output], dim=1)\n",
    "        output = self.classifier(output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(params=self.parameters(), lr=0.0005)\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        # 1. Forward pass\n",
    "        y_pred = self.forward(X)\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        \n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the test loop\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        y = y\n",
    "    \n",
    "        # 1. Forward pass\n",
    "        test_pred_logits = self.forward(X)\n",
    "\n",
    "        # Calculate and accumulate accuracy\n",
    "        test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "        test_acc = ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "        self.log(\"test_acc\", test_acc)\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # this is the validation loop\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        y = y\n",
    "        \n",
    "        y_pred = self.forward(X)\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        \n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        \n",
    "        test_pred_logits = self.forward(X)\n",
    "        test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "        \n",
    "        return test_pred_labels\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af66ab22-cfe6-4062-a1b0-2102fad90c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model_class = [LSTMModel, LSTMAttentionModel, CNNLSTMModel, CNNLSTMAttentionModel, CNNAttentionModel, CNNModel]\n",
    "# train_model_class = [CNNModel, CNNAttentionModel]\n",
    "\n",
    "# user 0: tran\n",
    "# user 1: hachix\n",
    "train_model_class = [CNNLSTMAttentionModel, CNNAttentionModel, LSTMAttentionModel, CNNModel, LSTMModel, CNNLSTMModel]\n",
    "# train_model_class = [CNNLSTMAttentionModel]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91c8883-6918-4a9d-a5a9-0ed54a6970d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only for test\n",
    "\n",
    "def test():\n",
    "    patience = 20\n",
    "    missing_sensor_numbers = 4 # no missing sensor\n",
    "    user = 2 # use user2 to test\n",
    "    batch_size_dict = {LSTMAttentionModel:512}\n",
    "    for model_class in train_model_class:\n",
    "        data_module = DataModule(test_user=user, \n",
    "                                 missing_sensor_numbers=missing_sensor_numbers, \n",
    "                                 batch_size=batch_size_dict.get(model_class, 1024))\n",
    "        \n",
    "        model = model_class(input_size=42, output_size=10)\n",
    "        \n",
    "        model_name = model.__class__.__name__\n",
    "        print(\"Running for model\", model_name)\n",
    "        print(\"summary(model)\", summary(model))\n",
    "\n",
    "        tb_logger = TensorBoardLogger(f\"./loggers/{model_name}\")\n",
    "        \n",
    "        trainer = pl.Trainer(\n",
    "            logger=tb_logger,\n",
    "            callbacks=[EarlyStopping(monitor=\"val_loss\", patience=patience, mode=\"min\")],\n",
    "            fast_dev_run = True\n",
    "        )\n",
    "        trainer.fit(model, data_module)\n",
    "        trainer.test(model, data_module)\n",
    "if TEST:\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3b7fc04-f150-4f23-a0db-d2ef89609792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for model LSTMModel\n",
      "loaded LSTMModel 0 0\n",
      "loaded LSTMModel 0 1\n",
      "loaded LSTMModel 0 2\n",
      "loaded LSTMModel 0 3\n",
      "loaded LSTMModel 0 4\n",
      "loaded LSTMModel 0 5\n",
      "loaded LSTMModel 0 6\n",
      "loaded LSTMModel 0 7\n",
      "loaded LSTMModel 0 8\n",
      "loaded LSTMModel 0 9\n",
      "loaded LSTMModel 0 10\n",
      "loaded LSTMModel 0 11\n",
      "loaded LSTMModel 0 12\n",
      "loaded LSTMModel 0 13\n",
      "loaded LSTMModel 0 14\n",
      "loaded LSTMModel 0 15\n",
      "loaded LSTMModel 1 0\n",
      "loaded LSTMModel 1 1\n",
      "loaded LSTMModel 1 2\n",
      "loaded LSTMModel 1 3\n",
      "loaded LSTMModel 1 4\n",
      "loaded LSTMModel 1 5\n",
      "loaded LSTMModel 1 6\n",
      "loaded LSTMModel 1 7\n",
      "loaded LSTMModel 1 8\n",
      "loaded LSTMModel 1 9\n",
      "loaded LSTMModel 1 10\n",
      "loaded LSTMModel 1 11\n",
      "loaded LSTMModel 1 12\n",
      "loaded LSTMModel 1 13\n",
      "loaded LSTMModel 1 14\n",
      "loaded LSTMModel 1 15\n",
      "Running for model LSTMAttentionModel\n",
      "loaded LSTMAttentionModel 0 0\n",
      "loaded LSTMAttentionModel 0 1\n",
      "loaded LSTMAttentionModel 0 2\n",
      "loaded LSTMAttentionModel 0 3\n",
      "loaded LSTMAttentionModel 0 4\n",
      "loaded LSTMAttentionModel 0 5\n",
      "loaded LSTMAttentionModel 0 6\n",
      "loaded LSTMAttentionModel 0 7\n",
      "loaded LSTMAttentionModel 0 8\n",
      "loaded LSTMAttentionModel 0 9\n",
      "loaded LSTMAttentionModel 0 10\n",
      "loaded LSTMAttentionModel 0 11\n",
      "loaded LSTMAttentionModel 0 12\n",
      "loaded LSTMAttentionModel 0 13\n",
      "loaded LSTMAttentionModel 0 14\n",
      "loaded LSTMAttentionModel 0 15\n",
      "loaded LSTMAttentionModel 1 0\n",
      "loaded LSTMAttentionModel 1 1\n",
      "loaded LSTMAttentionModel 1 2\n",
      "loaded LSTMAttentionModel 1 3\n",
      "loaded LSTMAttentionModel 1 4\n",
      "loaded LSTMAttentionModel 1 5\n",
      "loaded LSTMAttentionModel 1 6\n",
      "loaded LSTMAttentionModel 1 7\n",
      "loaded LSTMAttentionModel 1 8\n",
      "loaded LSTMAttentionModel 1 9\n",
      "loaded LSTMAttentionModel 1 10\n",
      "loaded LSTMAttentionModel 1 11\n",
      "loaded LSTMAttentionModel 1 12\n",
      "loaded LSTMAttentionModel 1 13\n",
      "loaded LSTMAttentionModel 1 14\n",
      "loaded LSTMAttentionModel 1 15\n",
      "Running for model CNNLSTMModel\n",
      "loaded CNNLSTMModel 0 0\n",
      "loaded CNNLSTMModel 0 1\n",
      "loaded CNNLSTMModel 0 2\n",
      "loaded CNNLSTMModel 0 3\n",
      "loaded CNNLSTMModel 0 4\n",
      "loaded CNNLSTMModel 0 5\n",
      "loaded CNNLSTMModel 0 6\n",
      "loaded CNNLSTMModel 0 7\n",
      "loaded CNNLSTMModel 0 8\n",
      "loaded CNNLSTMModel 0 9\n",
      "loaded CNNLSTMModel 0 10\n",
      "loaded CNNLSTMModel 0 11\n",
      "loaded CNNLSTMModel 0 12\n",
      "loaded CNNLSTMModel 0 13\n",
      "loaded CNNLSTMModel 0 14\n",
      "loaded CNNLSTMModel 0 15\n",
      "loaded CNNLSTMModel 1 0\n",
      "loaded CNNLSTMModel 1 1\n",
      "loaded CNNLSTMModel 1 2\n",
      "loaded CNNLSTMModel 1 3\n",
      "loaded CNNLSTMModel 1 4\n",
      "loaded CNNLSTMModel 1 5\n",
      "loaded CNNLSTMModel 1 6\n",
      "loaded CNNLSTMModel 1 7\n",
      "loaded CNNLSTMModel 1 8\n",
      "loaded CNNLSTMModel 1 9\n",
      "loaded CNNLSTMModel 1 10\n",
      "loaded CNNLSTMModel 1 11\n",
      "loaded CNNLSTMModel 1 12\n",
      "loaded CNNLSTMModel 1 13\n",
      "loaded CNNLSTMModel 1 14\n",
      "loaded CNNLSTMModel 1 15\n",
      "loaded CNNLSTMModel 2 0\n",
      "loaded CNNLSTMModel 2 1\n",
      "loaded CNNLSTMModel 2 2\n",
      "loaded CNNLSTMModel 2 3\n",
      "loaded CNNLSTMModel 2 4\n",
      "loaded CNNLSTMModel 2 5\n",
      "loaded CNNLSTMModel 2 6\n",
      "loaded CNNLSTMModel 2 7\n",
      "loaded CNNLSTMModel 2 8\n",
      "loaded CNNLSTMModel 2 9\n",
      "loaded CNNLSTMModel 2 10\n",
      "loaded CNNLSTMModel 2 11\n",
      "loaded CNNLSTMModel 2 12\n",
      "loaded CNNLSTMModel 2 13\n",
      "loaded CNNLSTMModel 2 14\n",
      "loaded CNNLSTMModel 2 15\n",
      "loaded CNNLSTMModel 4 0\n",
      "loaded CNNLSTMModel 4 1\n",
      "loaded CNNLSTMModel 4 2\n",
      "Running for model CNNLSTMAttentionModel\n",
      "loaded CNNLSTMAttentionModel 0 0\n",
      "loaded CNNLSTMAttentionModel 0 1\n",
      "loaded CNNLSTMAttentionModel 0 2\n",
      "loaded CNNLSTMAttentionModel 0 3\n",
      "loaded CNNLSTMAttentionModel 0 4\n",
      "loaded CNNLSTMAttentionModel 0 5\n",
      "loaded CNNLSTMAttentionModel 0 6\n",
      "loaded CNNLSTMAttentionModel 0 7\n",
      "loaded CNNLSTMAttentionModel 0 8\n",
      "loaded CNNLSTMAttentionModel 0 9\n",
      "loaded CNNLSTMAttentionModel 0 10\n",
      "loaded CNNLSTMAttentionModel 0 11\n",
      "loaded CNNLSTMAttentionModel 0 12\n",
      "loaded CNNLSTMAttentionModel 0 13\n",
      "loaded CNNLSTMAttentionModel 0 14\n",
      "loaded CNNLSTMAttentionModel 0 15\n",
      "loaded CNNLSTMAttentionModel 1 0\n",
      "loaded CNNLSTMAttentionModel 1 1\n",
      "loaded CNNLSTMAttentionModel 1 2\n",
      "loaded CNNLSTMAttentionModel 1 3\n",
      "loaded CNNLSTMAttentionModel 1 4\n",
      "loaded CNNLSTMAttentionModel 1 5\n",
      "loaded CNNLSTMAttentionModel 1 6\n",
      "loaded CNNLSTMAttentionModel 1 7\n",
      "loaded CNNLSTMAttentionModel 1 8\n",
      "loaded CNNLSTMAttentionModel 1 9\n",
      "loaded CNNLSTMAttentionModel 1 10\n",
      "loaded CNNLSTMAttentionModel 1 11\n",
      "loaded CNNLSTMAttentionModel 1 12\n",
      "loaded CNNLSTMAttentionModel 1 13\n",
      "loaded CNNLSTMAttentionModel 1 14\n",
      "loaded CNNLSTMAttentionModel 1 15\n",
      "Running for model CNNModel\n",
      "loaded CNNModel 0 0\n",
      "loaded CNNModel 0 1\n",
      "loaded CNNModel 0 2\n",
      "loaded CNNModel 0 3\n",
      "loaded CNNModel 0 4\n",
      "loaded CNNModel 0 5\n",
      "loaded CNNModel 0 6\n",
      "loaded CNNModel 0 7\n",
      "loaded CNNModel 0 8\n",
      "loaded CNNModel 0 9\n",
      "loaded CNNModel 0 10\n",
      "loaded CNNModel 0 11\n",
      "loaded CNNModel 0 12\n",
      "loaded CNNModel 0 13\n",
      "loaded CNNModel 0 14\n",
      "loaded CNNModel 0 15\n",
      "loaded CNNModel 1 0\n",
      "loaded CNNModel 1 1\n",
      "loaded CNNModel 1 2\n",
      "loaded CNNModel 1 3\n",
      "loaded CNNModel 1 4\n",
      "loaded CNNModel 1 5\n",
      "loaded CNNModel 1 6\n",
      "loaded CNNModel 1 7\n",
      "loaded CNNModel 1 8\n",
      "loaded CNNModel 1 9\n",
      "loaded CNNModel 1 10\n",
      "loaded CNNModel 1 11\n",
      "loaded CNNModel 1 12\n",
      "loaded CNNModel 1 13\n",
      "loaded CNNModel 1 14\n",
      "loaded CNNModel 1 15\n",
      "Running for model CNNAttentionModel\n",
      "loaded CNNAttentionModel 0 0\n",
      "loaded CNNAttentionModel 0 1\n",
      "loaded CNNAttentionModel 0 2\n",
      "loaded CNNAttentionModel 0 3\n",
      "loaded CNNAttentionModel 0 4\n",
      "loaded CNNAttentionModel 0 5\n",
      "loaded CNNAttentionModel 0 6\n",
      "loaded CNNAttentionModel 0 7\n",
      "loaded CNNAttentionModel 0 8\n",
      "loaded CNNAttentionModel 0 9\n",
      "loaded CNNAttentionModel 0 10\n",
      "loaded CNNAttentionModel 0 11\n",
      "loaded CNNAttentionModel 0 12\n",
      "loaded CNNAttentionModel 0 13\n",
      "loaded CNNAttentionModel 0 14\n",
      "loaded CNNAttentionModel 0 15\n",
      "loaded CNNAttentionModel 1 0\n",
      "loaded CNNAttentionModel 1 1\n",
      "loaded CNNAttentionModel 1 2\n",
      "loaded CNNAttentionModel 1 3\n",
      "loaded CNNAttentionModel 1 4\n",
      "loaded CNNAttentionModel 1 5\n",
      "loaded CNNAttentionModel 1 6\n",
      "loaded CNNAttentionModel 1 7\n",
      "loaded CNNAttentionModel 1 8\n",
      "loaded CNNAttentionModel 1 9\n",
      "loaded CNNAttentionModel 1 10\n",
      "loaded CNNAttentionModel 1 11\n",
      "loaded CNNAttentionModel 1 12\n",
      "loaded CNNAttentionModel 1 13\n",
      "loaded CNNAttentionModel 1 14\n",
      "loaded CNNAttentionModel 1 15\n"
     ]
    }
   ],
   "source": [
    "patience = 200\n",
    "# missing_sensor_numbers = 0\n",
    "# all_test_pred = {}\n",
    "batch_size_dict = {LSTMAttentionModel:2048, LSTMModel:2048}\n",
    "for model_class in train_model_class: \n",
    "    \n",
    "    model = model_class(input_size=42, output_size=10)\n",
    "    model_name = model.__class__.__name__\n",
    "    print(\"Running for model\", model_name)\n",
    "    \n",
    "    for missing_sensor_numbers in [6]: ## Changed for 1 missing sensor\n",
    "        for user in [0]: ## Changed for user 2 only\n",
    "            # Load from exist previous training cpkt for continuous learning & testing\n",
    "            # previous_checkpoint_file = os.path.join(PREV_CHECKPOINT_FOLDER_PATH, f\"{model_name}_{missing_sensor_numbers}missing_user{user}.ckpt\")\n",
    "            # previous_checkpoint_file = \"/home/tran/acttivity_recognition/data/compgan_dataset/results/logger86_6missing/CNNLSTMAttentionModel/user0/bk/checkpoints/epoch=259-step=16640.ckpt\"\n",
    "            # if os.path.isfile(previous_checkpoint_file):\n",
    "            #     model = model_class.load_from_checkpoint(previous_checkpoint_file)\n",
    "            #     print(\"loaded\", model_name, missing_sensor_numbers, user)\n",
    "                \n",
    "            start_timer = time.perf_counter()\n",
    "            print(f\"\\n*************training on User{user}*************\")\n",
    "            \n",
    "            data_module = DataModule(test_user=user, \n",
    "                                     missing_sensor_numbers=missing_sensor_numbers,\n",
    "                                     batch_size=batch_size_dict.get(model_class, 4096))\n",
    "\n",
    "            save_dir = os.path.join(RESULT_FOLDER_PATH, f\"./logger86_{missing_sensor_numbers}missing/{model_name}\")\n",
    "            save_dir_name = f\"user{user}\"\n",
    "            \n",
    "            tb_logger = TensorBoardLogger(save_dir=save_dir, name=save_dir_name)\n",
    "            \n",
    "            # checkpoint_callback = ModelCheckpoint(\n",
    "            #     dirpath=None,\n",
    "            #     save_top_k=1,  # get the 2 minimum val loss checkpoint\n",
    "            #     monitor=\"val_loss\",\n",
    "            #     mode=\"min\",\n",
    "            #     filename=\"best-{epoch:02d}-{step:02d}-{val_loss:.2f}\"\n",
    "            # )\n",
    "            \n",
    "            trainer = pl.Trainer(\n",
    "                logger=tb_logger,\n",
    "                callbacks=[\n",
    "                    EarlyStopping(monitor=\"val_loss\", patience=patience, mode=\"min\"),\n",
    "                    LearningRateMonitor(\"epoch\"),\n",
    "                    # checkpoint_callback,\n",
    "                ],\n",
    "                precision=\"16-mixed\",\n",
    "                # precision=16,\n",
    "                accumulate_grad_batches=10,\n",
    "                log_every_n_steps=200,\n",
    "                check_val_every_n_epoch=5,\n",
    "                accelerator=\"auto\",\n",
    "                devices=1,\n",
    "                max_epochs=100000,\n",
    "            )\n",
    "        \n",
    "            trainer.fit(model, data_module)\n",
    "            trainer.test(model, data_module)\n",
    "    \n",
    "            end_timer = time.perf_counter()\n",
    "            exec_time = end_timer - start_timer\n",
    "\n",
    "            trainer_test_dict = trainer.logged_metrics\n",
    "            for key in trainer_test_dict.keys():\n",
    "                trainer_test_dict[key] = trainer_test_dict[key].item()\n",
    "            trainer_test_dict[\"exec_time\"] = int(exec_time)\n",
    "            \n",
    "            with open(os.path.join(trainer.log_dir, f\"result.json\"), \"w\") as f:\n",
    "                json.dump(trainer_test_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7967b65-3625-4474-a8c6-4ddd429adb2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0efc2082-9a3c-45ce-8967-8e3b09e394e0",
   "metadata": {},
   "source": [
    "## Predict full length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc37caa7-a743-462e-b48b-f5321634078b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update after 2023/11/11 houkoku\n",
    "class CustomTestDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, feature_data, label_data, missing_sensor_numbers=0):\n",
    "        self.features = feature_data\n",
    "        self.label = label_data\n",
    "        assert len(self.features) == len(self.label), \"features len is not equal to label len\"\n",
    "        self.missing_sensor_numbers = missing_sensor_numbers\n",
    "\n",
    "        self.missing_index_list = []\n",
    "        for missing_index in combinations(range(SENSOR_NUM), missing_sensor_numbers):\n",
    "            self.missing_index_list.append(missing_index)\n",
    "\n",
    "    def transform(self, one_feature, missing_sensor_id_list):\n",
    "        # Make one sensor data become 0\n",
    "        one_feature_cp = one_feature.copy()\n",
    "        \n",
    "        for missing_sensor_id in missing_sensor_id_list:\n",
    "            one_feature_cp[:, missing_sensor_id*6:(missing_sensor_id+1)*6] = 0\n",
    "        return one_feature_cp\n",
    "        \n",
    "    def __len__(self):\n",
    "\n",
    "        # take all available missing pattern * data number\n",
    "        return len(self.features) * len(self.missing_index_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # take all available missing pattern\n",
    "        missing_sensor_id_list = self.missing_index_list[ idx // len(self.features) ]\n",
    "        x = self.transform(self.features[ idx % len(self.features) ], missing_sensor_id_list)\n",
    "        label = self.label[idx % len(self.features)]\n",
    "        return x, int(label)\n",
    "    \n",
    "class DataModule(pl.LightningDataModule):\n",
    "    STANDARDIZE = False\n",
    "    \n",
    "    def __init__(self, test_user, missing_sensor_numbers, batch_size=2048):\n",
    "        super().__init__()\n",
    "        self.test_user = test_user\n",
    "        self.missing_sensor_numbers = missing_sensor_numbers\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def load_data(self, mode):\n",
    "        if mode == \"train\":\n",
    "            folder_path = TRAIN_FOLDER_PATH\n",
    "            data_file_name = train_data_file_name_\n",
    "            label_file_name = train_label_file_name_\n",
    "\n",
    "            train_data_file_name = data_file_name.format(self.test_user)\n",
    "            train_label_file_name = label_file_name.format(self.test_user)\n",
    "    \n",
    "            train_data_file_path = os.path.join(folder_path, train_data_file_name)\n",
    "            train_label_file_path = os.path.join(folder_path, train_label_file_name)\n",
    "            train_val_data, train_val_label = np.load(train_data_file_path), np.load(train_label_file_path)\n",
    "            l, s, d, w = train_val_data.shape\n",
    "            train_val_data = train_val_data.reshape(l, s * d, w).transpose(0,2,1)\n",
    "            \n",
    "        elif mode == \"test\":\n",
    "            folder_path = TEST_FOLDER_PATH\n",
    "            data_file_name = test_data_file_name_\n",
    "            label_file_name = test_label_file_name_\n",
    "    \n",
    "            train_data_file_name = data_file_name.format(self.test_user)\n",
    "            train_label_file_name = label_file_name.format(self.test_user)\n",
    "    \n",
    "            train_data_file_path = os.path.join(folder_path, train_data_file_name)\n",
    "            train_label_file_path = os.path.join(folder_path, train_label_file_name)\n",
    "            train_val_data, train_val_label = np.load(train_data_file_path), np.load(train_label_file_path)\n",
    "            l, s, d, w = train_val_data.shape\n",
    "            train_val_data = train_val_data.reshape(l, s * d, w).transpose(0,2,1)\n",
    "    \n",
    "        return train_val_data, train_val_label\n",
    "\n",
    "    def setup(self, stage: str):\n",
    "        # Assign Train/val split(s) for use in Dataloaders\n",
    "        \n",
    "        if stage == \"validate\" or stage == \"fit\":\n",
    "            train_val_data, train_val_label = self.load_data(\"train\")\n",
    "            self.train_data, self.val_data, self.train_label, self.val_label = train_test_split(\n",
    "                train_val_data, train_val_label, test_size=0.2, train_size=0.8, random_state=42, shuffle=True)\n",
    "\n",
    "            self.train_dataset = CustomTestDataset(\n",
    "                self.train_data, self.train_label, missing_sensor_numbers=self.missing_sensor_numbers)\n",
    "            self.val_dataset = CustomTestDataset(\n",
    "                self.val_data, self.val_label, missing_sensor_numbers=self.missing_sensor_numbers)\n",
    "\n",
    "        elif stage == \"test\" or stage == \"predict\":\n",
    "            train_val_data, train_val_label = self.load_data(\"test\")\n",
    "            self.test_data = train_val_data\n",
    "            self.test_label = train_val_label\n",
    "\n",
    "            self.test_dataset = CustomTestDataset(\n",
    "                self.test_data, self.test_label, missing_sensor_numbers=self.missing_sensor_numbers)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, num_workers=4, shuffle=True, pin_memory=True)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size,  num_workers=4, shuffle=False, pin_memory=True)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size,  num_workers=4, shuffle=False, pin_memory=True)\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size,  num_workers=4, shuffle=False, pin_memory=True)\n",
    "\n",
    "    def teardown(self, stage):\n",
    "        print(\"teardown\")\n",
    "        if stage == \"validate\" or stage == \"fit\":\n",
    "            del self.train_data, self.train_label\n",
    "            del self.val_data, self.val_label\n",
    "            del self.train_dataset\n",
    "            del self.val_dataset\n",
    "            \n",
    "        elif stage == \"test\" or stage == \"predict\":\n",
    "            del self.test_data, self.test_label\n",
    "            del self.test_dataset\n",
    "        gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b08fce61-6fe2-4a0f-9a59-91d300c1b73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.6.1 to v2.0.9.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../data/compgan_dataset/results/logger91_6missing/CNNLSTMAttentionModel/user0/version_0/checkpoints/val_loss_min-epoch=419-val_loss=0.24-val_acc=0.00.ckpt`\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 96.01it/s] \n",
      "model_name CNNLSTMAttentionModel\n",
      "accuracy 0.48598130841121495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 97.26it/s] \n",
      "model_name CNNAttentionModel\n",
      "accuracy 0.705607476635514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 23.68it/s] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name LSTMAttentionModel\n",
      "accuracy 0.8644859813084113\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 292.31it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name CNNModel\n",
      "accuracy 0.8785046728971962\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 52.34it/s] \n",
      "model_name LSTMModel\n",
      "accuracy 0.7570093457943925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 137.91it/s]\n",
      "model_name CNNLSTMModel\n",
      "accuracy 0.677570093457944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.6.1 to v2.0.9.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../data/compgan_dataset/results/logger91_6missing/CNNLSTMAttentionModel/user0/version_0/checkpoints/val_loss_min-epoch=419-val_loss=0.24-val_acc=0.00.ckpt`\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 3/3 [00:00<00:00, 45.38it/s] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name CNNLSTMAttentionModel\n",
      "accuracy 0.5367156208277704\n",
      "Predicting DataLoader 0: 100%|██████████| 3/3 [00:00<00:00, 73.79it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name CNNAttentionModel\n",
      "accuracy 0.6582109479305741\n",
      "Predicting DataLoader 0: 100%|██████████| 3/3 [00:00<00:00, 10.99it/s] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name LSTMAttentionModel\n",
      "accuracy 0.8444592790387183\n",
      "Predicting DataLoader 0: 100%|██████████| 3/3 [00:00<00:00, 240.26it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name CNNModel\n",
      "accuracy 0.8571428571428571\n",
      "Predicting DataLoader 0: 100%|██████████| 3/3 [00:00<00:00, 28.29it/s] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name LSTMModel\n",
      "accuracy 0.6869158878504673\n",
      "Predicting DataLoader 0: 100%|██████████| 3/3 [00:00<00:00, 78.72it/s] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.6.1 to v2.0.9.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../data/compgan_dataset/results/logger91_6missing/CNNLSTMAttentionModel/user0/version_0/checkpoints/val_loss_min-epoch=419-val_loss=0.24-val_acc=0.00.ckpt`\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name CNNLSTMModel\n",
      "accuracy 0.6588785046728972\n",
      "Predicting DataLoader 0: 100%|██████████| 9/9 [00:00<00:00, 45.04it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name CNNLSTMAttentionModel\n",
      "accuracy 0.5213618157543392\n",
      "Predicting DataLoader 0: 100%|██████████| 9/9 [00:00<00:00, 83.47it/s] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name CNNAttentionModel\n",
      "accuracy 0.6341789052069426\n",
      "Predicting DataLoader 0: 100%|██████████| 9/9 [00:00<00:00, 10.98it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name LSTMAttentionModel\n",
      "accuracy 0.8161993769470405\n",
      "Predicting DataLoader 0: 100%|██████████| 9/9 [00:00<00:00, 153.65it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name CNNModel\n",
      "accuracy 0.812194036493102\n",
      "Predicting DataLoader 0: 100%|██████████| 9/9 [00:00<00:00, 27.75it/s] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name LSTMModel\n",
      "accuracy 0.6477525589675123\n",
      "Predicting DataLoader 0: 100%|██████████| 9/9 [00:00<00:00, 74.22it/s] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.6.1 to v2.0.9.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../data/compgan_dataset/results/logger91_6missing/CNNLSTMAttentionModel/user0/version_0/checkpoints/val_loss_min-epoch=419-val_loss=0.24-val_acc=0.00.ckpt`\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name CNNLSTMModel\n",
      "accuracy 0.6299510458388963\n",
      "Predicting DataLoader 0: 100%|██████████| 15/15 [00:00<00:00, 49.13it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name CNNLSTMAttentionModel\n",
      "accuracy 0.505607476635514\n",
      "Predicting DataLoader 0: 100%|██████████| 15/15 [00:00<00:00, 88.79it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name CNNAttentionModel\n",
      "accuracy 0.6096128170894526\n",
      "Predicting DataLoader 0: 100%|██████████| 15/15 [00:01<00:00, 11.06it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name LSTMAttentionModel\n",
      "accuracy 0.7654205607476635\n",
      "Predicting DataLoader 0: 100%|██████████| 15/15 [00:00<00:00, 147.85it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name CNNModel\n",
      "accuracy 0.7504672897196262\n",
      "Predicting DataLoader 0: 100%|██████████| 15/15 [00:00<00:00, 28.54it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name LSTMModel\n",
      "accuracy 0.6420560747663552\n",
      "Predicting DataLoader 0: 100%|██████████| 15/15 [00:00<00:00, 79.27it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.6.1 to v2.0.9.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../data/compgan_dataset/results/logger91_6missing/CNNLSTMAttentionModel/user0/version_0/checkpoints/val_loss_min-epoch=419-val_loss=0.24-val_acc=0.00.ckpt`\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name CNNLSTMModel\n",
      "accuracy 0.5874499332443258\n",
      "Predicting DataLoader 0: 100%|██████████| 15/15 [00:00<00:00, 50.64it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name CNNLSTMAttentionModel\n",
      "accuracy 0.4666221628838451\n",
      "Predicting DataLoader 0: 100%|██████████| 15/15 [00:00<00:00, 95.83it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name CNNAttentionModel\n",
      "accuracy 0.5961281708945261\n",
      "Predicting DataLoader 0: 100%|██████████| 15/15 [00:01<00:00, 11.28it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name LSTMAttentionModel\n",
      "accuracy 0.713351134846462\n",
      "Predicting DataLoader 0: 100%|██████████| 15/15 [00:00<00:00, 128.07it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name CNNModel\n",
      "accuracy 0.677570093457944\n",
      "Predicting DataLoader 0: 100%|██████████| 15/15 [00:00<00:00, 28.57it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name LSTMModel\n",
      "accuracy 0.6456608811748998\n",
      "Predicting DataLoader 0: 100%|██████████| 15/15 [00:00<00:00, 79.16it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.6.1 to v2.0.9.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../data/compgan_dataset/results/logger91_6missing/CNNLSTMAttentionModel/user0/version_0/checkpoints/val_loss_min-epoch=419-val_loss=0.24-val_acc=0.00.ckpt`\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name CNNLSTMModel\n",
      "accuracy 0.5686248331108145\n",
      "Predicting DataLoader 0: 100%|██████████| 9/9 [00:00<00:00, 50.13it/s] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name CNNLSTMAttentionModel\n",
      "accuracy 0.4161103693813974\n",
      "Predicting DataLoader 0: 100%|██████████| 9/9 [00:00<00:00, 99.84it/s] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name CNNAttentionModel\n",
      "accuracy 0.5640854472630173\n",
      "Predicting DataLoader 0: 100%|██████████| 9/9 [00:00<00:00, 11.26it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name LSTMAttentionModel\n",
      "accuracy 0.6809078771695594\n",
      "Predicting DataLoader 0: 100%|██████████| 9/9 [00:00<00:00, 147.09it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name CNNModel\n",
      "accuracy 0.5867823765020027\n",
      "Predicting DataLoader 0: 100%|██████████| 9/9 [00:00<00:00, 28.75it/s] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name LSTMModel\n",
      "accuracy 0.6395193591455274\n",
      "Predicting DataLoader 0: 100%|██████████| 9/9 [00:00<00:00, 81.88it/s] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.6.1 to v2.0.9.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../data/compgan_dataset/results/logger91_6missing/CNNLSTMAttentionModel/user0/version_0/checkpoints/val_loss_min-epoch=419-val_loss=0.24-val_acc=0.00.ckpt`\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name CNNLSTMModel\n",
      "accuracy 0.5149087672452158\n",
      "Predicting DataLoader 0: 100%|██████████| 3/3 [00:00<00:00, 51.48it/s] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name CNNLSTMAttentionModel\n",
      "accuracy 0.3464619492656876\n",
      "Predicting DataLoader 0: 100%|██████████| 3/3 [00:00<00:00, 98.48it/s] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name CNNAttentionModel\n",
      "accuracy 0.5106809078771696\n",
      "Predicting DataLoader 0: 100%|██████████| 3/3 [00:00<00:00, 11.07it/s] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name LSTMAttentionModel\n",
      "accuracy 0.6361815754339119\n",
      "Predicting DataLoader 0: 100%|██████████| 3/3 [00:00<00:00, 336.32it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name CNNModel\n",
      "accuracy 0.4459279038718291\n",
      "Predicting DataLoader 0: 100%|██████████| 3/3 [00:00<00:00, 28.20it/s] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name LSTMModel\n",
      "accuracy 0.5694259012016022\n",
      "Predicting DataLoader 0: 100%|██████████| 3/3 [00:00<00:00, 78.31it/s] \n",
      "model_name CNNLSTMModel\n",
      "accuracy 0.44659546061415223\n"
     ]
    }
   ],
   "source": [
    "all_test_pred = {}\n",
    "\n",
    "for missing_sensor_numbers in range(SENSOR_NUM): ## Changed for 1 missing sensor\n",
    "    all_test_pred[missing_sensor_numbers] = {}\n",
    "    \n",
    "    for model_class in train_model_class: \n",
    "        all_user_y_true = []\n",
    "        all_user_y_pred = []\n",
    "        \n",
    "        for user in range(1): ## Changed for user 2 only\n",
    "            model_name = model_class.__name__\n",
    "            checkpoint_path = os.path.join(RESULT_FOLDER_PATH, f\"logger86_6missing\", f\"{model_name}\", f\"user{user}\", \"version_0\", \"checkpoints\", \"*.ckpt\")\n",
    "            checkpoint_glob = glob.glob(checkpoint_path)\n",
    "            assert len(checkpoint_glob) == 1, checkpoint_path\n",
    "            checkpoint_file = checkpoint_glob[0]\n",
    "\n",
    "            assert os.path.exists(checkpoint_file), checkpoint_file\n",
    "            model = model_class.load_from_checkpoint(checkpoint_file)\n",
    "\n",
    "            data_module = DataModule(test_user=user, missing_sensor_numbers=missing_sensor_numbers, batch_size=512)\n",
    "            data_module.setup(\"test\")\n",
    "            test_loader = data_module.test_dataloader()\n",
    "            \n",
    "            tb_logger = TensorBoardLogger(os.path.join(RESULT_FOLDER_PATH, f\"logger86_6missing\", f\"{model_name}\", f\"user{user}\", \"version_0\", f\"result_test\"))\n",
    "            trainer = pl.Trainer(logger=tb_logger)\n",
    "\n",
    "            pred = trainer.predict(model, test_loader)\n",
    "\n",
    "            y_true_list = []\n",
    "            for batch_idx, test_data in enumerate(test_loader):\n",
    "                _, y_true = test_data\n",
    "                y_true_list.append(y_true)\n",
    "\n",
    "            all_user_y_true.append(torch.cat(y_true_list))\n",
    "            all_user_y_pred.append(torch.cat(pred))\n",
    "        \n",
    "        print(\"model_name\", model_name)\n",
    "        all_test_cpu = list(map(lambda x: x.cpu().item(), torch.cat(all_user_y_true)))\n",
    "        all_pred_cpu = list(map(lambda x: x.cpu().item(), torch.cat(all_user_y_pred)))\n",
    "        \n",
    "        all_test_pred[missing_sensor_numbers][model_name] = (all_test_cpu, all_pred_cpu)\n",
    "        \n",
    "        print(\"accuracy\", accuracy_score(all_test_cpu, all_pred_cpu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "353cbf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(index=[f\"missing_{x}\" for x in range(SENSOR_NUM)])\n",
    "\n",
    "for model_class in train_model_class: \n",
    "    acc_list = []\n",
    "    for missing_sensor_numbers in range(7): ## Changed for 1 missing sensor\n",
    "        for user in range(1):\n",
    "            all_test_cpu, all_pred_cpu = all_test_pred[missing_sensor_numbers][model_class.__name__]\n",
    "            acc = f1_score(all_test_cpu, all_pred_cpu, average=\"macro\")\n",
    "            acc_list.append(acc)\n",
    "            \n",
    "    df[model_class.__name__] = acc_list\n",
    "df\n",
    "df.to_csv(\"model_result_f1_score.csv\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2228f034-f56b-42e4-9892-8c2bdfe4ebf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CNNLSTMAttentionModel</th>\n",
       "      <th>CNNAttentionModel</th>\n",
       "      <th>LSTMAttentionModel</th>\n",
       "      <th>CNNModel</th>\n",
       "      <th>LSTMModel</th>\n",
       "      <th>CNNLSTMModel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>missing_0</th>\n",
       "      <td>0.359813</td>\n",
       "      <td>0.705607</td>\n",
       "      <td>0.864486</td>\n",
       "      <td>0.878505</td>\n",
       "      <td>0.757009</td>\n",
       "      <td>0.677570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_1</th>\n",
       "      <td>0.434579</td>\n",
       "      <td>0.658211</td>\n",
       "      <td>0.844459</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.686916</td>\n",
       "      <td>0.658879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_2</th>\n",
       "      <td>0.443703</td>\n",
       "      <td>0.634179</td>\n",
       "      <td>0.816199</td>\n",
       "      <td>0.812194</td>\n",
       "      <td>0.647753</td>\n",
       "      <td>0.629951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_3</th>\n",
       "      <td>0.449132</td>\n",
       "      <td>0.609613</td>\n",
       "      <td>0.765421</td>\n",
       "      <td>0.750467</td>\n",
       "      <td>0.642056</td>\n",
       "      <td>0.587450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_4</th>\n",
       "      <td>0.450868</td>\n",
       "      <td>0.596128</td>\n",
       "      <td>0.713351</td>\n",
       "      <td>0.677570</td>\n",
       "      <td>0.645661</td>\n",
       "      <td>0.568625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_5</th>\n",
       "      <td>0.431019</td>\n",
       "      <td>0.564085</td>\n",
       "      <td>0.680908</td>\n",
       "      <td>0.586782</td>\n",
       "      <td>0.639519</td>\n",
       "      <td>0.514909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_6</th>\n",
       "      <td>0.347130</td>\n",
       "      <td>0.510681</td>\n",
       "      <td>0.636182</td>\n",
       "      <td>0.445928</td>\n",
       "      <td>0.569426</td>\n",
       "      <td>0.446595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           CNNLSTMAttentionModel  CNNAttentionModel  LSTMAttentionModel  \\\n",
       "missing_0               0.359813           0.705607            0.864486   \n",
       "missing_1               0.434579           0.658211            0.844459   \n",
       "missing_2               0.443703           0.634179            0.816199   \n",
       "missing_3               0.449132           0.609613            0.765421   \n",
       "missing_4               0.450868           0.596128            0.713351   \n",
       "missing_5               0.431019           0.564085            0.680908   \n",
       "missing_6               0.347130           0.510681            0.636182   \n",
       "\n",
       "           CNNModel  LSTMModel  CNNLSTMModel  \n",
       "missing_0  0.878505   0.757009      0.677570  \n",
       "missing_1  0.857143   0.686916      0.658879  \n",
       "missing_2  0.812194   0.647753      0.629951  \n",
       "missing_3  0.750467   0.642056      0.587450  \n",
       "missing_4  0.677570   0.645661      0.568625  \n",
       "missing_5  0.586782   0.639519      0.514909  \n",
       "missing_6  0.445928   0.569426      0.446595  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(index=[f\"missing_{x}\" for x in range(SENSOR_NUM)])\n",
    "\n",
    "for model_class in train_model_class: \n",
    "    acc_list = []\n",
    "    for missing_sensor_numbers in range(7): ## Changed for 1 missing sensor\n",
    "        for user in range(1):\n",
    "            all_test_cpu, all_pred_cpu = all_test_pred[missing_sensor_numbers][model_class.__name__]\n",
    "            acc = accuracy_score(all_test_cpu, all_pred_cpu)\n",
    "            acc_list.append(acc)\n",
    "            \n",
    "    df[model_class.__name__] = acc_list\n",
    "df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a19ccb-eccd-4f8b-84e9-9ae354bfe086",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f3f15c77c882d8433ef1043b53db379ca3772938d44c39305f8b807ce25a312a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.17 ('compgan': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

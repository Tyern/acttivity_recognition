{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4ce6502-93ec-4660-8864-7ff3019c6084",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tran/miniconda3/envs/compgan/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchinfo import summary\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import tracemalloc \n",
    "\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "from itertools import combinations\n",
    "import gc\n",
    "import time\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c153c485-8474-4042-a29b-31ea8978c7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../data/compgan_dataset/train/train_data0.npy', '../data/compgan_dataset/train/train_data1.npy', '../data/compgan_dataset/train/train_data10.npy', '../data/compgan_dataset/train/train_data11.npy', '../data/compgan_dataset/train/train_data12.npy', '../data/compgan_dataset/train/train_data13.npy', '../data/compgan_dataset/train/train_data14.npy', '../data/compgan_dataset/train/train_data15.npy', '../data/compgan_dataset/train/train_data2.npy', '../data/compgan_dataset/train/train_data3.npy', '../data/compgan_dataset/train/train_data4.npy', '../data/compgan_dataset/train/train_data5.npy', '../data/compgan_dataset/train/train_data6.npy', '../data/compgan_dataset/train/train_data7.npy', '../data/compgan_dataset/train/train_data8.npy', '../data/compgan_dataset/train/train_data9.npy']\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "DATA_ROOT = \"../data/compgan_dataset/\"\n",
    "\n",
    "train_data_file_name_ = \"train_data{}.npy\"\n",
    "train_label_file_name_ = \"train_label{}.npy\"\n",
    "test_data_file_name_ = \"test_data{}.npy\"\n",
    "test_label_file_name_ = \"test_label{}.npy\"\n",
    "\n",
    "TRAIN_FOLDER_PATH = os.path.join(DATA_ROOT, \"train\")\n",
    "TEST_FOLDER_PATH = os.path.join(DATA_ROOT, \"test\")\n",
    "RESULT_FOLDER_PATH = os.path.join(DATA_ROOT, \"results\")\n",
    "\n",
    "assert os.path.isdir(TRAIN_FOLDER_PATH) and os.path.isdir(TEST_FOLDER_PATH)\n",
    "os.makedirs(RESULT_FOLDER_PATH, exist_ok=True)\n",
    "\n",
    "data_files = sorted(glob.glob(os.path.join(TRAIN_FOLDER_PATH, train_data_file_name_.format(\"*\"))))\n",
    "print(data_files)\n",
    "print(len(data_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "878427cd-91fa-4b99-94c8-399378c81dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_NUM = 16\n",
    "SENSOR_NUM = 7\n",
    "EACH_SENSOR_CHANNEL = 6\n",
    "assert USER_NUM == len(data_files)\n",
    "feature_num = SENSOR_NUM * EACH_SENSOR_CHANNEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee7a344b-73b9-4310-a650-c06bea9f68da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# important\n",
    "\n",
    "label_list = ['歩行(平地)',\n",
    " '歩行(階段)',\n",
    " 'ベッド上での起き上がり',\n",
    " 'ベッド椅子間の乗り移り(立つ)',\n",
    " 'ベッド椅子間の乗り移り(立たない)',\n",
    " '立ち座り',\n",
    " '座位保持・座位バランス',\n",
    " '立位保持・立位バランス',\n",
    " '関節可動域増大訓練(肩)',\n",
    " '関節可動域増大訓練(股関節)']\n",
    "\n",
    "label_dict = dict(enumerate(label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45f45c18-d2c9-46e9-89bf-75b68dbd12da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# important\n",
    "eng_label_dict = dict(zip(\n",
    "    label_list,\n",
    "    ['Walking', 'Upstair', 'Bed_Standup', 'Change_Bed', 'Change_Bed_Standup', 'Sit_Down', 'Sit', 'Stand', 'Shoulder_Exercise', 'Hip_Exercise']\n",
    "))\n",
    "\n",
    "eng_label_list = [eng_label_dict[i] for i in label_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15253300-be5a-4855-a356-f565676ac443",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainDataset(Dataset):\n",
    "    TRAIN_MODE = \"train\"\n",
    "    TEST_MODE = \"test\"\n",
    "    \n",
    "    def __init__(self, mode, feature_data, label_data, missing_sensor_numbers=0):\n",
    "        self.mode = mode\n",
    "        assert mode in [self.TRAIN_MODE, self.TEST_MODE]\n",
    "        \n",
    "        self.features = feature_data\n",
    "        self.label = label_data\n",
    "        assert len(self.features) == len(self.label), \"features len is not equal to label len\"\n",
    "        self.missing_sensor_numbers = missing_sensor_numbers\n",
    "\n",
    "        self.missing_index_list = []\n",
    "        for missing_count in range(missing_sensor_numbers + 1):\n",
    "            for missing_index in combinations(range(SENSOR_NUM), missing_count):\n",
    "                self.missing_index_list.append(missing_index)\n",
    "\n",
    "    def transform(self, one_feature, missing_sensor_id_list):\n",
    "        # Make one sensor data become 0\n",
    "        one_feature_cp = one_feature.copy()\n",
    "        \n",
    "        for missing_sensor_id in missing_sensor_id_list:\n",
    "            one_feature_cp[:, missing_sensor_id*6:(missing_sensor_id+1)*6] = 0\n",
    "        return one_feature_cp\n",
    "        \n",
    "    def __len__(self):\n",
    "        if self.mode == self.TRAIN_MODE:\n",
    "            # although the transform generate more data, the index here is irrelevant\n",
    "            return len(self.features)\n",
    "        else:\n",
    "            # take all available missing pattern * data number\n",
    "            return len(self.features) * len(self.missing_index_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == self.TRAIN_MODE:\n",
    "            missing_sensor_id_list = random.choice(self.missing_index_list)\n",
    "            x = self.transform(self.features[idx], missing_sensor_id_list)\n",
    "            label = self.label[idx]\n",
    "\n",
    "        else:\n",
    "            # take all available missing pattern\n",
    "            missing_sensor_id_list = self.missing_index_list[ idx // len(self.features) ]\n",
    "            x = self.transform(self.features[ idx % len(self.features) ], missing_sensor_id_list)\n",
    "            label = self.label[idx % len(self.features)]\n",
    "        return x, int(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3225bf4a-954e-44ed-aee0-95672ed5fe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule(pl.LightningDataModule):\n",
    "    STANDARDIZE = False\n",
    "    BATCH_SIZE = 512\n",
    "    \n",
    "    def __init__(self, test_user, missing_sensor_numbers):\n",
    "        super().__init__()\n",
    "        self.test_user = test_user\n",
    "        self.missing_sensor_numbers = missing_sensor_numbers\n",
    "\n",
    "    def load_data(self, mode):\n",
    "        if mode == \"train\":\n",
    "            folder_path = TRAIN_FOLDER_PATH\n",
    "            data_file_name = train_data_file_name_\n",
    "            label_file_name = train_label_file_name_\n",
    "\n",
    "            train_val_data_list = None\n",
    "            train_val_label_list = None\n",
    "            \n",
    "            for user in range(USER_NUM):\n",
    "                if user == self.test_user: \n",
    "                    continue\n",
    "                \n",
    "                print(\"train_user\", user)\n",
    "                train_data_file_name = data_file_name.format(user)\n",
    "                train_label_file_name = label_file_name.format(user)\n",
    "\n",
    "                train_data_file_path = os.path.join(folder_path, train_data_file_name)\n",
    "                train_label_file_path = os.path.join(folder_path, train_label_file_name)\n",
    "                \n",
    "                train_val_data, train_val_label = np.load(train_data_file_path), np.load(train_label_file_path)\n",
    "                l, s, d, w = train_val_data.shape\n",
    "                train_val_data = train_val_data.reshape(l, s * d, w).transpose(0,2,1)\n",
    "\n",
    "                if train_val_data_list is None:\n",
    "                    train_val_data_list = train_val_data\n",
    "                    train_val_label_list = train_val_label\n",
    "                else:\n",
    "                    train_val_data_list = np.vstack((train_val_data_list, train_val_data))\n",
    "                    train_val_label_list = np.concatenate((train_val_label_list, train_val_label))\n",
    "\n",
    "            train_val_data = train_val_data_list\n",
    "            train_val_label = train_val_label_list\n",
    "            \n",
    "        elif mode == \"test\":\n",
    "            folder_path = TEST_FOLDER_PATH\n",
    "            data_file_name = test_data_file_name_\n",
    "            label_file_name = test_label_file_name_\n",
    "    \n",
    "            train_data_file_name = data_file_name.format(self.test_user)\n",
    "            train_label_file_name = label_file_name.format(self.test_user)\n",
    "    \n",
    "            train_data_file_path = os.path.join(folder_path, train_data_file_name)\n",
    "            train_label_file_path = os.path.join(folder_path, train_label_file_name)\n",
    "            train_val_data, train_val_label = np.load(train_data_file_path), np.load(train_label_file_path)\n",
    "            l, s, d, w = train_val_data.shape\n",
    "            train_val_data = train_val_data.reshape(l, s * d, w).transpose(0,2,1)\n",
    "    \n",
    "        return train_val_data, train_val_label\n",
    "\n",
    "    def setup(self, stage: str):\n",
    "        # Assign Train/val split(s) for use in Dataloaders\n",
    "        \n",
    "        if stage == \"validate\" or stage == \"fit\":\n",
    "            train_val_data, train_val_label = self.load_data(\"train\")\n",
    "            self.train_data, self.val_data, self.train_label, self.val_label = train_test_split(\n",
    "                train_val_data, train_val_label, test_size=0.2, train_size=0.8, random_state=42, shuffle=True)\n",
    "\n",
    "            self.train_dataset = CustomTrainDataset(\n",
    "                CustomTrainDataset.TRAIN_MODE, self.train_data, self.train_label, missing_sensor_numbers=self.missing_sensor_numbers)\n",
    "            self.val_dataset = CustomTrainDataset(\n",
    "                CustomTrainDataset.TEST_MODE, self.val_data, self.val_label, missing_sensor_numbers=self.missing_sensor_numbers)\n",
    "\n",
    "        elif stage == \"test\" :\n",
    "            train_val_data, train_val_label = self.load_data(\"test\")\n",
    "            self.test_data = train_val_data\n",
    "            self.test_label = train_val_label\n",
    "\n",
    "            self.test_dataset = CustomTrainDataset(\n",
    "                CustomTrainDataset.TEST_MODE, self.test_data, self.test_label, missing_sensor_numbers=self.missing_sensor_numbers)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.BATCH_SIZE, num_workers=0, shuffle=True)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.BATCH_SIZE,  num_workers=0, shuffle=False)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.BATCH_SIZE,  num_workers=0, shuffle=False)\n",
    "\n",
    "    def teardown(self, stage):\n",
    "        print(\"teardown\")\n",
    "        if stage == \"validate\" or stage == \"fit\":\n",
    "            del self.train_data, self.train_label\n",
    "            del self.val_data, self.val_label\n",
    "            del self.train_dataset\n",
    "            del self.val_dataset\n",
    "            \n",
    "        elif stage == \"test\" :\n",
    "            del self.test_data, self.test_label\n",
    "            del self.test_dataset\n",
    "        gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a89352ec-f6dc-45a1-80d5-f52a59d38953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_user 0\n",
      "train_user 2\n",
      "train_user 3\n",
      "train_user 4\n",
      "train_user 5\n",
      "train_user 6\n",
      "train_user 7\n",
      "train_user 8\n",
      "train_user 9\n",
      "train_user 10\n",
      "train_user 11\n",
      "train_user 12\n",
      "train_user 13\n",
      "train_user 14\n",
      "train_user 15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(73884, 256, 42)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_module = DataModule(1, 1)\n",
    "data_module.setup(\"fit\")\n",
    "data_module.train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fded757e-a29f-47ad-addf-a8989028ec80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,\n",
       " array([0.32876712, 0.36813223, 0.38270855, 0.23328531, 0.21495754,\n",
       "        0.22658242, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.31556886, 0.39839226, 0.34658355,\n",
       "        0.25972992, 0.24153638, 0.19600333, 0.4280699 , 0.34839636,\n",
       "        0.33220407, 0.22292672, 0.22038516, 0.2235621 , 0.4224018 ,\n",
       "        0.35157084, 0.30766958, 0.22106978, 0.21923521, 0.2231236 ,\n",
       "        0.4319908 , 0.3506275 , 0.3310721 , 0.22761604, 0.22643924,\n",
       "        0.2203628 , 0.4195144 , 0.34043145, 0.3387335 , 0.25530905,\n",
       "        0.23053345, 0.23562102], dtype=float32))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data_module.train_dataset[0]\n",
    "data[1], data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e760566-e117-4fc6-b639-a2e2ec3c32da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1399"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del data_module, data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdb0600-ebb2-4d73-94f2-d8e4729336bd",
   "metadata": {},
   "source": [
    "## MODEL DEFINITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecabfca0-2c1a-4485-974a-1acd2865ee5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.query = nn.Linear(input_dim, input_dim)\n",
    "        self.key = nn.Linear(input_dim, input_dim)\n",
    "        self.value = nn.Linear(input_dim, input_dim)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        queries = self.query(x)\n",
    "        keys = self.key(x)\n",
    "        values = self.value(x)\n",
    "        \n",
    "        scores = torch.bmm(queries, keys.transpose(1, 2)) / (self.input_dim ** 0.5)\n",
    "        attention = self.softmax(scores)\n",
    "        weighted = torch.bmm(attention, values)\n",
    "        return weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c97b4ec5-f1bf-49ec-bc3d-266a58f4099d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LSTMModel(pl.LightningModule):\n",
    "    def __init__(self, hidden_size=128, input_size=42, output_size=10, **kwargs):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.example_input_array = torch.Tensor(1024, 256, input_size)\n",
    "        \n",
    "        self.rnn = nn.LSTM(input_size=input_size, \n",
    "                          hidden_size=hidden_size,\n",
    "                          num_layers=3,\n",
    "                          batch_first=True)\n",
    "        \n",
    "        self.seq_1 = nn.Sequential(\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.seq_2 = nn.Sequential(\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Linear(in_features=3 * hidden_size, out_features=output_size)\n",
    "\n",
    "        self.all_test = []\n",
    "        self.all_pred = []\n",
    "        \n",
    "    def forward(self, x):\n",
    "        activation, _ = self.rnn(x)\n",
    "        \n",
    "        b, _, _ = activation.size()\n",
    "        lstm_output = activation[:,-1,:].view(b,-1)\n",
    "        seq_1_output = self.seq_1(lstm_output)\n",
    "        seq_2_output = self.seq_2(lstm_output)\n",
    "        \n",
    "        output = torch.concat([lstm_output, seq_1_output, seq_2_output], dim=1)\n",
    "        output = self.classifier(output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(params=self.parameters(), lr=0.0005)\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        # 1. Forward pass\n",
    "        y_pred = self.forward(X)\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        \n",
    "        self.log(\"train_loss\", loss)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the test loop\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "    \n",
    "        # 1. Forward pass\n",
    "        test_pred_logits = self.forward(X)\n",
    "\n",
    "        # Calculate and accumulate accuracy\n",
    "        test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "        test_acc = ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "        self.log(\"test_acc\", test_acc)\n",
    "\n",
    "        self.all_pred = test_pred_labels\n",
    "        self.all_test = y\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # this is the validation loop\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        \n",
    "        y_pred = self.forward(X)\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        \n",
    "        self.log(\"val_loss\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0f1c7eb-386b-4f8a-96fa-30afd4245ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMBiModel(pl.LightningModule):\n",
    "    def __init__(self, hidden_size=128, input_size=42, output_size=10, **kwargs):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.example_input_array = torch.Tensor(1024, 256, input_size)\n",
    "        \n",
    "        self.rnn = nn.LSTM(input_size=input_size, \n",
    "                          hidden_size=hidden_size,\n",
    "                          num_layers=3,\n",
    "                          batch_first=True,\n",
    "                          bidirectional=True)\n",
    "\n",
    "        double_hidden_size = hidden_size * 2\n",
    "        \n",
    "        self.seq_1 = nn.Sequential(\n",
    "            nn.Linear(in_features=double_hidden_size, out_features=double_hidden_size),\n",
    "            nn.BatchNorm1d(num_features=double_hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=double_hidden_size, out_features=double_hidden_size),\n",
    "            nn.BatchNorm1d(num_features=double_hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.seq_2 = nn.Sequential(\n",
    "            nn.Linear(in_features=double_hidden_size, out_features=double_hidden_size),\n",
    "            nn.BatchNorm1d(num_features=double_hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=double_hidden_size, out_features=double_hidden_size),\n",
    "            nn.BatchNorm1d(num_features=double_hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Linear(in_features=3 * double_hidden_size, out_features=output_size)\n",
    "\n",
    "        self.all_test = []\n",
    "        self.all_pred = []\n",
    "        \n",
    "    def forward(self, x):\n",
    "        activation, (h, _) = self.rnn(x)\n",
    "        b, _, _ = activation.size()\n",
    "        \n",
    "        lstm_output = h[-2:].permute(1,0,2).reshape(b, -1)\n",
    "        seq_1_output = self.seq_1(lstm_output)\n",
    "        seq_2_output = self.seq_2(lstm_output)\n",
    "        \n",
    "        output = torch.concat([lstm_output, seq_1_output, seq_2_output], dim=1)\n",
    "        output = self.classifier(output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(params=self.parameters(), lr=0.0005)\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        # 1. Forward pass\n",
    "        y_pred = self.forward(X)\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        \n",
    "        self.log(\"train_loss\", loss)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the test loop\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "    \n",
    "        # 1. Forward pass\n",
    "        test_pred_logits = self.forward(X)\n",
    "\n",
    "        # Calculate and accumulate accuracy\n",
    "        test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "        test_acc = ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "        self.log(\"test_acc\", test_acc)\n",
    "\n",
    "        self.all_pred = test_pred_labels\n",
    "        self.all_test = y\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # this is the validation loop\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        \n",
    "        y_pred = self.forward(X)\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        \n",
    "        self.log(\"val_loss\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05745f4a-c9d2-44ff-9cc7-ba34e61937e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMAttentionModel(pl.LightningModule):\n",
    "    def __init__(self, hidden_size=128, input_size=42, output_size=10, **kwargs):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.example_input_array = torch.Tensor(1024, 256, input_size)\n",
    "        \n",
    "        self.rnn1 = nn.LSTM(input_size=input_size, \n",
    "                          hidden_size=hidden_size,\n",
    "                          num_layers=1,\n",
    "                          batch_first=True)\n",
    "        \n",
    "        self.attention1 = SelfAttention(\n",
    "            input_dim=hidden_size)\n",
    "\n",
    "        self.rnn2 = nn.LSTM(input_size=hidden_size, \n",
    "                          hidden_size=hidden_size,\n",
    "                          num_layers=1,\n",
    "                          batch_first=True)\n",
    "        \n",
    "        self.attention2 = SelfAttention(\n",
    "            input_dim=hidden_size\n",
    "        )\n",
    "\n",
    "        self.rnn3 = nn.LSTM(input_size=hidden_size, \n",
    "                  hidden_size=hidden_size,\n",
    "                  num_layers=1,\n",
    "                  batch_first=True)\n",
    "        \n",
    "        self.seq_1 = nn.Sequential(\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.seq_2 = nn.Sequential(\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Linear(in_features=3 * hidden_size, out_features=output_size)\n",
    "        \n",
    "        self.all_test = []\n",
    "        self.all_pred = []\n",
    "        \n",
    "    def forward(self, x):\n",
    "        activation, _ = self.rnn1(x)\n",
    "        activation = self.attention1(activation)\n",
    "        activation, _ = self.rnn2(activation)\n",
    "        activation = self.attention2(activation)\n",
    "        activation, (h, _) = self.rnn3(activation)\n",
    "\n",
    "        b, _, _ = activation.size()\n",
    "        \n",
    "        lstm_output = activation[:,-1,:].view(b,-1)\n",
    "        \n",
    "        seq_1_output = self.seq_1(lstm_output)\n",
    "        seq_2_output = self.seq_2(lstm_output)\n",
    "        \n",
    "        output = torch.concat([lstm_output, seq_1_output, seq_2_output], dim=1)\n",
    "        output = self.classifier(output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(params=self.parameters(), lr=0.0005)\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        # 1. Forward pass\n",
    "        y_pred = self.forward(X)\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        \n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the test loop\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        y = y\n",
    "    \n",
    "        # 1. Forward pass\n",
    "        test_pred_logits = self.forward(X)\n",
    "\n",
    "        # Calculate and accumulate accuracy\n",
    "        test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "        test_acc = ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "        self.log(\"test_acc\", test_acc)\n",
    "        \n",
    "        self.all_pred = test_pred_labels\n",
    "        self.all_test = y\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # this is the validation loop\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        y = y\n",
    "        \n",
    "        y_pred = self.forward(X)\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        \n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fd7f246-f58c-4a18-8195-bead57c332ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CNNLSTMModel(pl.LightningModule):\n",
    "    def __init__(self, hidden_size=128, sequence_length=256, input_size=42, cnn_filter_size=64, output_size=10, **kwargs):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.example_input_array = torch.Tensor(1024, sequence_length, input_size)\n",
    "        \n",
    "        self.cnn = nn.Conv1d(sequence_length, cnn_filter_size, kernel_size=5, padding=\"same\")\n",
    "        \n",
    "        self.rnn = nn.LSTM(input_size=input_size, \n",
    "                          hidden_size=hidden_size,\n",
    "                          num_layers=3,\n",
    "                          batch_first=True)\n",
    " \n",
    "        self.seq_1 = nn.Sequential(\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.seq_2 = nn.Sequential(\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Linear(in_features=3 * hidden_size, out_features=output_size)\n",
    "\n",
    "        self.all_test = []\n",
    "        self.all_pred = []\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.cnn(x)\n",
    "        activation, _ = self.rnn(output)\n",
    "        \n",
    "        b, _, _ = activation.size()\n",
    "        lstm_output = activation[:,-1,:].view(b,-1)\n",
    "        seq_1_output = self.seq_1(lstm_output)\n",
    "        seq_2_output = self.seq_2(lstm_output)\n",
    "        \n",
    "        output = torch.concat([lstm_output, seq_1_output, seq_2_output], dim=1)\n",
    "        output = self.classifier(output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(params=self.parameters(), lr=0.0005)\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        # 1. Forward pass\n",
    "        y_pred = self.forward(X)\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        \n",
    "        self.log(\"train_loss\", loss)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the test loop\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "    \n",
    "        # 1. Forward pass\n",
    "        test_pred_logits = self.forward(X)\n",
    "\n",
    "        # Calculate and accumulate accuracy\n",
    "        test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "        test_acc = ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "        self.log(\"test_acc\", test_acc)\n",
    "\n",
    "        self.all_pred = test_pred_labels\n",
    "        self.all_test = y\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # this is the validation loop\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        \n",
    "        y_pred = self.forward(X)\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        \n",
    "        self.log(\"val_loss\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "390fef45-0469-4afd-9829-f22f6e9c0b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNLSTMAttentionModel(pl.LightningModule):\n",
    "    def __init__(self, hidden_size=128, sequence_length=256, input_size=42, cnn_filter_size=64, output_size=10, **kwargs):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.example_input_array = torch.Tensor(1024, sequence_length, input_size)\n",
    "        \n",
    "        self.cnn = nn.Conv1d(sequence_length, cnn_filter_size, kernel_size=5, padding=\"same\")\n",
    "        \n",
    "        self.rnn1 = nn.LSTM(input_size=input_size, \n",
    "                          hidden_size=hidden_size,\n",
    "                          num_layers=1,\n",
    "                          batch_first=True)\n",
    "        \n",
    "        self.attention1 = SelfAttention(\n",
    "            input_dim=hidden_size)\n",
    "\n",
    "        self.rnn2 = nn.LSTM(input_size=hidden_size, \n",
    "                          hidden_size=hidden_size,\n",
    "                          num_layers=1,\n",
    "                          batch_first=True)\n",
    "        \n",
    "        self.attention2 = SelfAttention(\n",
    "            input_dim=hidden_size\n",
    "        )\n",
    "\n",
    "        self.rnn3 = nn.LSTM(input_size=hidden_size, \n",
    "                  hidden_size=hidden_size,\n",
    "                  num_layers=1,\n",
    "                  batch_first=True)\n",
    "        \n",
    "        self.seq_1 = nn.Sequential(\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.seq_2 = nn.Sequential(\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_size, out_features=hidden_size),\n",
    "            nn.BatchNorm1d(num_features=hidden_size),\n",
    "            nn.Dropout1d(p=0.2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Linear(in_features=3 * hidden_size, out_features=output_size)\n",
    "        \n",
    "        self.all_test = []\n",
    "        self.all_pred = []\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.cnn(x)\n",
    "        activation, _ = self.rnn1(output)\n",
    "        activation = self.attention1(activation)\n",
    "        activation, _ = self.rnn2(activation)\n",
    "        activation = self.attention2(activation)\n",
    "        activation, _ = self.rnn3(activation)\n",
    "\n",
    "        b, _, _ = activation.size()\n",
    "        \n",
    "        lstm_output = activation[:,-1,:].view(b,-1)\n",
    "        \n",
    "        seq_1_output = self.seq_1(lstm_output)\n",
    "        seq_2_output = self.seq_2(lstm_output)\n",
    "        \n",
    "        output = torch.concat([lstm_output, seq_1_output, seq_2_output], dim=1)\n",
    "        output = self.classifier(output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(params=self.parameters(), lr=0.0005)\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        # 1. Forward pass\n",
    "        y_pred = self.forward(X)\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        \n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the test loop\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        y = y\n",
    "    \n",
    "        # 1. Forward pass\n",
    "        test_pred_logits = self.forward(X)\n",
    "\n",
    "        # Calculate and accumulate accuracy\n",
    "        test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "        test_acc = ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "        self.log(\"test_acc\", test_acc)\n",
    "        \n",
    "        self.all_pred = test_pred_labels\n",
    "        self.all_test = y\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # this is the validation loop\n",
    "        X, y = batch\n",
    "        X = X.float()\n",
    "        y = y\n",
    "        \n",
    "        y_pred = self.forward(X)\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        \n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af66ab22-cfe6-4062-a1b0-2102fad90c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model_class = [CNNLSTMModel, CNNLSTMAttentionModel, LSTMBiModel, LSTMAttentionModel, LSTMModel]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c91c8883-6918-4a9d-a5a9-0ed54a6970d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for model LSTMModel\n",
      "summary(model) =================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "LSTMModel                                --\n",
      "├─LSTM: 1-1                              352,256\n",
      "├─Sequential: 1-2                        --\n",
      "│    └─Linear: 2-1                       16,512\n",
      "│    └─BatchNorm1d: 2-2                  256\n",
      "│    └─Dropout1d: 2-3                    --\n",
      "│    └─ReLU: 2-4                         --\n",
      "│    └─Linear: 2-5                       16,512\n",
      "│    └─BatchNorm1d: 2-6                  256\n",
      "│    └─Dropout1d: 2-7                    --\n",
      "│    └─ReLU: 2-8                         --\n",
      "├─Sequential: 1-3                        --\n",
      "│    └─Linear: 2-9                       16,512\n",
      "│    └─BatchNorm1d: 2-10                 256\n",
      "│    └─Dropout1d: 2-11                   --\n",
      "│    └─ReLU: 2-12                        --\n",
      "│    └─Linear: 2-13                      16,512\n",
      "│    └─BatchNorm1d: 2-14                 256\n",
      "│    └─Dropout1d: 2-15                   --\n",
      "│    └─ReLU: 2-16                        --\n",
      "├─Linear: 1-4                            3,850\n",
      "=================================================================\n",
      "Total params: 423,178\n",
      "Trainable params: 423,178\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "train_user 0\n",
      "train_user 1\n",
      "train_user 3\n",
      "train_user 4\n",
      "train_user 5\n",
      "train_user 6\n",
      "train_user 7\n",
      "train_user 8\n",
      "train_user 9\n",
      "train_user 10\n",
      "train_user 11\n",
      "train_user 12\n",
      "train_user 13\n",
      "train_user 14\n",
      "train_user 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type       | Params | In sizes        | Out sizes                                           \n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "0 | rnn        | LSTM       | 352 K  | [1024, 256, 42] | [[1024, 256, 128], [[3, 1024, 128], [3, 1024, 128]]]\n",
      "1 | seq_1      | Sequential | 33.5 K | [1024, 128]     | [1024, 128]                                         \n",
      "2 | seq_2      | Sequential | 33.5 K | [1024, 128]     | [1024, 128]                                         \n",
      "3 | classifier | Linear     | 3.9 K  | [1024, 384]     | [1024, 10]                                          \n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "423 K     Trainable params\n",
      "0         Non-trainable params\n",
      "423 K     Total params\n",
      "1.693     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 15.63it/s]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                       | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|█████████████████████████████████████████████████| 1/1 [00:00<00:00, 257.78it/s]\u001b[A\n",
      "Epoch 0: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.83it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.80it/s]\n",
      "teardown\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|█████████████████████████████████████████████████████| 1/1 [00:00<00:00, 26.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc                0.275390625\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "teardown\n",
      "Running for model LSTMBiModel\n",
      "summary(model) =================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "LSTMBiModel                              --\n",
      "├─LSTM: 1-1                              966,656\n",
      "├─Sequential: 1-2                        --\n",
      "│    └─Linear: 2-1                       65,792\n",
      "│    └─BatchNorm1d: 2-2                  512\n",
      "│    └─Dropout1d: 2-3                    --\n",
      "│    └─ReLU: 2-4                         --\n",
      "│    └─Linear: 2-5                       65,792\n",
      "│    └─BatchNorm1d: 2-6                  512\n",
      "│    └─Dropout1d: 2-7                    --\n",
      "│    └─ReLU: 2-8                         --\n",
      "├─Sequential: 1-3                        --\n",
      "│    └─Linear: 2-9                       65,792\n",
      "│    └─BatchNorm1d: 2-10                 512\n",
      "│    └─Dropout1d: 2-11                   --\n",
      "│    └─ReLU: 2-12                        --\n",
      "│    └─Linear: 2-13                      65,792\n",
      "│    └─BatchNorm1d: 2-14                 512\n",
      "│    └─Dropout1d: 2-15                   --\n",
      "│    └─ReLU: 2-16                        --\n",
      "├─Linear: 1-4                            7,690\n",
      "=================================================================\n",
      "Total params: 1,239,562\n",
      "Trainable params: 1,239,562\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "train_user 0\n",
      "train_user 1\n",
      "train_user 3\n",
      "train_user 4\n",
      "train_user 5\n",
      "train_user 6\n",
      "train_user 7\n",
      "train_user 8\n",
      "train_user 9\n",
      "train_user 10\n",
      "train_user 11\n",
      "train_user 12\n",
      "train_user 13\n",
      "train_user 14\n",
      "train_user 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type       | Params | In sizes        | Out sizes                                           \n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "0 | rnn        | LSTM       | 966 K  | [1024, 256, 42] | [[1024, 256, 256], [[6, 1024, 128], [6, 1024, 128]]]\n",
      "1 | seq_1      | Sequential | 132 K  | [1024, 256]     | [1024, 256]                                         \n",
      "2 | seq_2      | Sequential | 132 K  | [1024, 256]     | [1024, 256]                                         \n",
      "3 | classifier | Linear     | 7.7 K  | [1024, 768]     | [1024, 10]                                          \n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "1.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 M     Total params\n",
      "4.958     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.48it/s]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                       | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|█████████████████████████████████████████████████| 1/1 [00:00<00:00, 218.73it/s]\u001b[A\n",
      "Epoch 0: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.21it/s]\n",
      "teardown\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|█████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.96it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc                0.185546875\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "teardown\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for model LSTMAttentionModel\n",
      "summary(model) =================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "LSTMAttentionModel                       --\n",
      "├─LSTM: 1-1                              88,064\n",
      "├─SelfAttention: 1-2                     --\n",
      "│    └─Linear: 2-1                       16,512\n",
      "│    └─Linear: 2-2                       16,512\n",
      "│    └─Linear: 2-3                       16,512\n",
      "│    └─Softmax: 2-4                      --\n",
      "├─LSTM: 1-3                              132,096\n",
      "├─SelfAttention: 1-4                     --\n",
      "│    └─Linear: 2-5                       16,512\n",
      "│    └─Linear: 2-6                       16,512\n",
      "│    └─Linear: 2-7                       16,512\n",
      "│    └─Softmax: 2-8                      --\n",
      "├─LSTM: 1-5                              132,096\n",
      "├─Sequential: 1-6                        --\n",
      "│    └─Linear: 2-9                       16,512\n",
      "│    └─BatchNorm1d: 2-10                 256\n",
      "│    └─Dropout1d: 2-11                   --\n",
      "│    └─ReLU: 2-12                        --\n",
      "│    └─Linear: 2-13                      16,512\n",
      "│    └─BatchNorm1d: 2-14                 256\n",
      "│    └─Dropout1d: 2-15                   --\n",
      "│    └─ReLU: 2-16                        --\n",
      "├─Sequential: 1-7                        --\n",
      "│    └─Linear: 2-17                      16,512\n",
      "│    └─BatchNorm1d: 2-18                 256\n",
      "│    └─Dropout1d: 2-19                   --\n",
      "│    └─ReLU: 2-20                        --\n",
      "│    └─Linear: 2-21                      16,512\n",
      "│    └─BatchNorm1d: 2-22                 256\n",
      "│    └─Dropout1d: 2-23                   --\n",
      "│    └─ReLU: 2-24                        --\n",
      "├─Linear: 1-8                            3,850\n",
      "=================================================================\n",
      "Total params: 522,250\n",
      "Trainable params: 522,250\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "train_user 0\n",
      "train_user 1\n",
      "train_user 3\n",
      "train_user 4\n",
      "train_user 5\n",
      "train_user 6\n",
      "train_user 7\n",
      "train_user 8\n",
      "train_user 9\n",
      "train_user 10\n",
      "train_user 11\n",
      "train_user 12\n",
      "train_user 13\n",
      "train_user 14\n",
      "train_user 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type          | Params | In sizes         | Out sizes                                           \n",
      "-----------------------------------------------------------------------------------------------------------------------\n",
      "0 | rnn1       | LSTM          | 88.1 K | [1024, 256, 42]  | [[1024, 256, 128], [[1, 1024, 128], [1, 1024, 128]]]\n",
      "1 | attention1 | SelfAttention | 49.5 K | [1024, 256, 128] | [1024, 256, 128]                                    \n",
      "2 | rnn2       | LSTM          | 132 K  | [1024, 256, 128] | [[1024, 256, 128], [[1, 1024, 128], [1, 1024, 128]]]\n",
      "3 | attention2 | SelfAttention | 49.5 K | [1024, 256, 128] | [1024, 256, 128]                                    \n",
      "4 | rnn3       | LSTM          | 132 K  | [1024, 256, 128] | [[1024, 256, 128], [[1, 1024, 128], [1, 1024, 128]]]\n",
      "5 | seq_1      | Sequential    | 33.5 K | [1024, 128]      | [1024, 128]                                         \n",
      "6 | seq_2      | Sequential    | 33.5 K | [1024, 128]      | [1024, 128]                                         \n",
      "7 | classifier | Linear        | 3.9 K  | [1024, 384]      | [1024, 10]                                          \n",
      "-----------------------------------------------------------------------------------------------------------------------\n",
      "522 K     Trainable params\n",
      "0         Non-trainable params\n",
      "522 K     Total params\n",
      "2.089     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.85it/s, train_loss=2.360]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                       | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|█████████████████████████████████████████████████| 1/1 [00:00<00:00, 186.66it/s]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████████| 1/1 [00:00<00:00,  4.13it/s, train_loss=2.360, val_loss=2.300]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|████████████████████████████████| 1/1 [00:00<00:00,  4.11it/s, train_loss=2.360, val_loss=2.300]\n",
      "teardown\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|█████████████████████████████████████████████████████| 1/1 [00:00<00:00, 18.31it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc                0.052734375\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "teardown\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for model CNNLSTMModel\n",
      "summary(model) =================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "CNNLSTMModel                             --\n",
      "├─Conv1d: 1-1                            81,984\n",
      "├─LSTM: 1-2                              352,256\n",
      "├─Sequential: 1-3                        --\n",
      "│    └─Linear: 2-1                       16,512\n",
      "│    └─BatchNorm1d: 2-2                  256\n",
      "│    └─Dropout1d: 2-3                    --\n",
      "│    └─ReLU: 2-4                         --\n",
      "│    └─Linear: 2-5                       16,512\n",
      "│    └─BatchNorm1d: 2-6                  256\n",
      "│    └─Dropout1d: 2-7                    --\n",
      "│    └─ReLU: 2-8                         --\n",
      "├─Sequential: 1-4                        --\n",
      "│    └─Linear: 2-9                       16,512\n",
      "│    └─BatchNorm1d: 2-10                 256\n",
      "│    └─Dropout1d: 2-11                   --\n",
      "│    └─ReLU: 2-12                        --\n",
      "│    └─Linear: 2-13                      16,512\n",
      "│    └─BatchNorm1d: 2-14                 256\n",
      "│    └─Dropout1d: 2-15                   --\n",
      "│    └─ReLU: 2-16                        --\n",
      "├─Linear: 1-5                            3,850\n",
      "=================================================================\n",
      "Total params: 505,162\n",
      "Trainable params: 505,162\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "train_user 0\n",
      "train_user 1\n",
      "train_user 3\n",
      "train_user 4\n",
      "train_user 5\n",
      "train_user 6\n",
      "train_user 7\n",
      "train_user 8\n",
      "train_user 9\n",
      "train_user 10\n",
      "train_user 11\n",
      "train_user 12\n",
      "train_user 13\n",
      "train_user 14\n",
      "train_user 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type       | Params | In sizes        | Out sizes                                          \n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "0 | cnn        | Conv1d     | 82.0 K | [1024, 256, 42] | [1024, 64, 42]                                     \n",
      "1 | rnn        | LSTM       | 352 K  | [1024, 64, 42]  | [[1024, 64, 128], [[3, 1024, 128], [3, 1024, 128]]]\n",
      "2 | seq_1      | Sequential | 33.5 K | [1024, 128]     | [1024, 128]                                        \n",
      "3 | seq_2      | Sequential | 33.5 K | [1024, 128]     | [1024, 128]                                        \n",
      "4 | classifier | Linear     | 3.9 K  | [1024, 384]     | [1024, 10]                                         \n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "505 K     Trainable params\n",
      "0         Non-trainable params\n",
      "505 K     Total params\n",
      "2.021     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 20.19it/s]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                       | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|█████████████████████████████████████████████████| 1/1 [00:00<00:00, 194.16it/s]\u001b[A\n",
      "Epoch 0: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.24it/s]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 12.06it/s]\n",
      "teardown\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|█████████████████████████████████████████████████████| 1/1 [00:00<00:00, 72.03it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc                    0.0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teardown\n",
      "Running for model CNNLSTMAttentionModel\n",
      "summary(model) =================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "CNNLSTMAttentionModel                    --\n",
      "├─Conv1d: 1-1                            81,984\n",
      "├─LSTM: 1-2                              88,064\n",
      "├─SelfAttention: 1-3                     --\n",
      "│    └─Linear: 2-1                       16,512\n",
      "│    └─Linear: 2-2                       16,512\n",
      "│    └─Linear: 2-3                       16,512\n",
      "│    └─Softmax: 2-4                      --\n",
      "├─LSTM: 1-4                              132,096\n",
      "├─SelfAttention: 1-5                     --\n",
      "│    └─Linear: 2-5                       16,512\n",
      "│    └─Linear: 2-6                       16,512\n",
      "│    └─Linear: 2-7                       16,512\n",
      "│    └─Softmax: 2-8                      --\n",
      "├─LSTM: 1-6                              132,096\n",
      "├─Sequential: 1-7                        --\n",
      "│    └─Linear: 2-9                       16,512\n",
      "│    └─BatchNorm1d: 2-10                 256\n",
      "│    └─Dropout1d: 2-11                   --\n",
      "│    └─ReLU: 2-12                        --\n",
      "│    └─Linear: 2-13                      16,512\n",
      "│    └─BatchNorm1d: 2-14                 256\n",
      "│    └─Dropout1d: 2-15                   --\n",
      "│    └─ReLU: 2-16                        --\n",
      "├─Sequential: 1-8                        --\n",
      "│    └─Linear: 2-17                      16,512\n",
      "│    └─BatchNorm1d: 2-18                 256\n",
      "│    └─Dropout1d: 2-19                   --\n",
      "│    └─ReLU: 2-20                        --\n",
      "│    └─Linear: 2-21                      16,512\n",
      "│    └─BatchNorm1d: 2-22                 256\n",
      "│    └─Dropout1d: 2-23                   --\n",
      "│    └─ReLU: 2-24                        --\n",
      "├─Linear: 1-9                            3,850\n",
      "=================================================================\n",
      "Total params: 604,234\n",
      "Trainable params: 604,234\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "train_user 0\n",
      "train_user 1\n",
      "train_user 3\n",
      "train_user 4\n",
      "train_user 5\n",
      "train_user 6\n",
      "train_user 7\n",
      "train_user 8\n",
      "train_user 9\n",
      "train_user 10\n",
      "train_user 11\n",
      "train_user 12\n",
      "train_user 13\n",
      "train_user 14\n",
      "train_user 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type          | Params | In sizes        | Out sizes                                          \n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "0 | cnn        | Conv1d        | 82.0 K | [1024, 256, 42] | [1024, 64, 42]                                     \n",
      "1 | rnn1       | LSTM          | 88.1 K | [1024, 64, 42]  | [[1024, 64, 128], [[1, 1024, 128], [1, 1024, 128]]]\n",
      "2 | attention1 | SelfAttention | 49.5 K | [1024, 64, 128] | [1024, 64, 128]                                    \n",
      "3 | rnn2       | LSTM          | 132 K  | [1024, 64, 128] | [[1024, 64, 128], [[1, 1024, 128], [1, 1024, 128]]]\n",
      "4 | attention2 | SelfAttention | 49.5 K | [1024, 64, 128] | [1024, 64, 128]                                    \n",
      "5 | rnn3       | LSTM          | 132 K  | [1024, 64, 128] | [[1024, 64, 128], [[1, 1024, 128], [1, 1024, 128]]]\n",
      "6 | seq_1      | Sequential    | 33.5 K | [1024, 128]     | [1024, 128]                                        \n",
      "7 | seq_2      | Sequential    | 33.5 K | [1024, 128]     | [1024, 128]                                        \n",
      "8 | classifier | Linear        | 3.9 K  | [1024, 384]     | [1024, 10]                                         \n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "604 K     Trainable params\n",
      "0         Non-trainable params\n",
      "604 K     Total params\n",
      "2.417     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|████████████████████████████████████████████████| 1/1 [00:00<00:00, 16.48it/s, train_loss=2.320]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|                                                                       | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|                                                          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0: 100%|█████████████████████████████████████████████████| 1/1 [00:00<00:00, 234.32it/s]\u001b[A\n",
      "Epoch 0: 100%|████████████████████████████████| 1/1 [00:00<00:00, 10.90it/s, train_loss=2.320, val_loss=2.300]\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|████████████████████████████████| 1/1 [00:00<00:00, 10.81it/s, train_loss=2.320, val_loss=2.300]\n",
      "teardown\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|█████████████████████████████████████████████████████| 1/1 [00:00<00:00, 58.32it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc                0.275390625\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "teardown\n"
     ]
    }
   ],
   "source": [
    "# only for test\n",
    "\n",
    "def test():\n",
    "    patience = 20\n",
    "    missing_sensor_numbers = 4 # no missing sensor\n",
    "    user = 2 # use user2 to test\n",
    "    for model_class in train_model_class:\n",
    "        data_module = DataModule(test_user=user, missing_sensor_numbers=missing_sensor_numbers)\n",
    "        \n",
    "        model = model_class(input_size=42, output_size=10)\n",
    "        \n",
    "        model_name = model.__class__.__name__\n",
    "        print(\"Running for model\", model_name)\n",
    "        print(\"summary(model)\", summary(model))\n",
    "\n",
    "        tb_logger = TensorBoardLogger(f\"./loggers/{model_name}\")\n",
    "        \n",
    "        trainer = pl.Trainer(\n",
    "            logger=tb_logger,\n",
    "            callbacks=[EarlyStopping(monitor=\"val_loss\", patience=patience, mode=\"min\")],\n",
    "            fast_dev_run = True\n",
    "        )\n",
    "        trainer.fit(model, data_module)\n",
    "        trainer.test(model, data_module)\n",
    "# test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b7fc04-f150-4f23-a0db-d2ef89609792",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "patience = 20\n",
    "# missing_sensor_numbers = 0\n",
    "# all_test_pred = {}\n",
    "\n",
    "missing_sensor_numbers = 0 ## Changed for no missing sensor\n",
    "\n",
    "for missing_sensor_numbers in [1]:\n",
    "    for user in range(USER_NUM): ## Changed for user 2 only\n",
    "        for model_class in train_model_class: \n",
    "            start_timer = time.perf_counter()\n",
    "            \n",
    "            all_test = []\n",
    "            all_pred = []\n",
    "            print(f\"\\n*************training on User{user}*************\")\n",
    "            \n",
    "            data_module = DataModule(test_user=user, missing_sensor_numbers=missing_sensor_numbers)\n",
    "            \n",
    "            model = model_class(input_size=42, output_size=10)\n",
    "            model_name = model.__class__.__name__\n",
    "            print(\"Running for model\", model_name)\n",
    "            \n",
    "            tb_logger = TensorBoardLogger(f\"./logger96_{missing_sensor_numbers}missing/{model_name}\")\n",
    "            \n",
    "            trainer = pl.Trainer(\n",
    "                logger=tb_logger,\n",
    "                callbacks=[EarlyStopping(monitor=\"val_loss\", patience=patience, mode=\"min\")],\n",
    "            )\n",
    "        \n",
    "            trainer.fit(model, data_module)\n",
    "            trainer.test(model, data_module)\n",
    "    \n",
    "            all_test.extend(model.all_test)\n",
    "            all_pred.extend(model.all_pred)\n",
    "    \n",
    "            test_target_pred = (all_test, all_pred)\n",
    "            \n",
    "            end_timer = time.perf_counter()\n",
    "            exec_time = end_timer - start_timer\n",
    "\n",
    "            save_dir = os.path.join(RESULT_FOLDER_PATH, f\"96_{missing_sensor_numbers}missing\")\n",
    "            os.makedirs(save_dir, exist_ok=True)\n",
    "            with open(os.path.join(save_dir, f\"test_pred_user_{user}_{missing_sensor_numbers}_{model_name}_{exec_time:.0f}s.pkl\"), \"wb\") as f:\n",
    "                pickle.dump(test_target_pred, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7967b65-3625-4474-a8c6-4ddd429adb2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25e8308d-3bb9-4fa3-9c3f-e7e44f25f228",
   "metadata": {},
   "source": [
    "## Calculate the performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d03a97-6d1e-4199-a1d2-8fc45f515896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing_sensor_numbers = 0\n",
    "# model_name = train_model_class[3].__name__\n",
    "# print(model_name)\n",
    "\n",
    "# all_test_pred = {}\n",
    "# for user in range(USER_NUM):\n",
    "#     with open(os.path.join(RESULT_FOLDER_PATH, \"96\", f\"test_pred_user_{user}_{missing_sensor_numbers}_{model_name}.pkl\"), \"rb\") as f:\n",
    "#         all_test_pred[user] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90aa959-94fd-4460-9295-3ffb3fdd8e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_test_pred_result = ([], [])\n",
    "# for user in range(USER_NUM):\n",
    "#     all_test_pred_result[0].extend(all_test_pred[user][0])\n",
    "#     all_test_pred_result[1].extend(all_test_pred[user][1])\n",
    "\n",
    "# print(len(all_test_pred_result[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2e1de0-09b0-4b43-92c7-a24ea5aa7c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_test, all_pred = all_test_pred_result\n",
    "\n",
    "# # print(\"missing index\", missing_index)\n",
    "# all_test_with_label = [label_list[i] for i in all_test]\n",
    "# all_pred_with_label = [label_list[i] for i in all_pred]\n",
    "\n",
    "# cf = confusion_matrix(all_test_with_label, all_pred_with_label, labels=label_list)\n",
    "# sns.heatmap(cf, annot=True, xticklabels=eng_label_list, yticklabels=eng_label_list, fmt='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9542e1f5-8400-4706-b50f-f64cec5ae2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 1.0\n",
      "F1 score: 1.0\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import accuracy_score, f1_score\n",
    "# all_test = list(map(lambda x: x.cpu().item(), all_test))\n",
    "# all_pred = list(map(lambda x: x.cpu().item(), all_pred))\n",
    "# print(\"accuracy:\", accuracy_score(all_test, all_pred))\n",
    "# print(\"F1 score:\", f1_score(all_test, all_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8a8224-5343-4314-a1db-ff378665e7ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec666bfb-979d-4928-a249-b0bf8422cfcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
